from typing import AsyncGenerator, Dict, Any, Optional, List

"""
è¯„åˆ†åˆ†æå·¥å…·æ™ºèƒ½ä½“ - æ”¯æŒAgent as Toolæœºåˆ¶

ä¸šåŠ¡å¤„ç†é€»è¾‘ï¼š
1. è¾“å…¥å¤„ç†ï¼šæ¥æ”¶å¤šè½®è¯„ä¼°ç»“æœå’Œè¯„åˆ†æ•°æ®
2. ç»Ÿè®¡åˆ†æï¼šå¯¹å¤šè½®è¯„åˆ†è¿›è¡Œç»Ÿè®¡åˆ†æï¼Œè®¡ç®—å¹³å‡å€¼ã€æ ‡å‡†å·®ç­‰
3. è¯„çº§è®¡ç®—ï¼šåŸºäºè¯„åˆ†æ ‡å‡†è¿›è¡Œè¯„çº§é€»è¾‘è®¡ç®—ï¼ˆA/B/C/Dç­‰çº§ï¼‰
4. è¶‹åŠ¿åˆ†æï¼šåˆ†æè¯„åˆ†è¶‹åŠ¿å’Œå˜åŒ–è§„å¾‹
5. å¼‚å¸¸æ£€æµ‹ï¼šè¯†åˆ«è¯„åˆ†å¼‚å¸¸å’Œå¼‚å¸¸å€¼
6. æŠ¥å‘Šç”Ÿæˆï¼šç”Ÿæˆç»¼åˆçš„è¯„åˆ†åˆ†ææŠ¥å‘Š
7. å»ºè®®è¾“å‡ºï¼šåŸºäºåˆ†æç»“æœæä¾›è¯„çº§å»ºè®®
8. è¾“å‡ºæ ¼å¼åŒ–ï¼šè¿”å›ç»“æ„åŒ–çš„è¯„åˆ†åˆ†ææ•°æ®
9. Agent as Toolï¼šæ”¯æŒè¢«å…¶ä»–æ™ºèƒ½ä½“è°ƒç”¨ï¼Œå®ç°ä¸Šä¸‹æ–‡éš”ç¦»

ä»£ç ä½œè€…ï¼šå®«çµç‘
åˆ›å»ºæ—¶é—´ï¼š2025å¹´10æœˆ19æ—¥
"""
from datetime import datetime
try:
    from .base_juben_agent import BaseJubenAgent
except ImportError:
    # å¤„ç†ç›¸å¯¹å¯¼å…¥é—®é¢˜
    import sys
    from pathlib import Path
    sys.path.insert(0, str(Path(__file__).parent.parent))

    from agents.base_juben_agent import BaseJubenAgent

class ScoreAnalyzerAgent(BaseJubenAgent):
    """
    è¯„åˆ†åˆ†æå·¥å…·æ™ºèƒ½ä½“
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. å¤šè½®è¯„åˆ†ç»Ÿè®¡åˆ†æ
    2. è¯„çº§é€»è¾‘è®¡ç®—
    3. è¯„åˆ†è¶‹åŠ¿åˆ†æ
    4. ç»¼åˆè¯„ä¼°æŠ¥å‘Šç”Ÿæˆ
    """
    
    def __init__(self, model_provider: str = "zhipu"):
        """åˆå§‹åŒ–è¯„åˆ†åˆ†æå·¥å…·æ™ºèƒ½ä½“"""
        super().__init__("score_analyzer", model_provider)
        
        # ç³»ç»Ÿæç¤ºè¯é…ç½®
        self.logger.info("è¯„åˆ†åˆ†æå·¥å…·æ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ")
    
    # ç³»ç»Ÿæç¤ºè¯ç”±åŸºç±»è‡ªåŠ¨åŠ è½½ï¼Œæ— éœ€é‡å†™
    
    async def process_request(
        self,
        request_data: Dict[str, Any],
        context: Optional[Dict[str, Any]] = None
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        å¤„ç†è¯·æ±‚ - æ”¯æŒAgent as Toolæœºåˆ¶

        Args:
            request_data: è¯·æ±‚æ•°æ®
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
                - user_id: ç”¨æˆ·ID
                - session_id: ä¼šè¯ID
                - parent_agent: çˆ¶æ™ºèƒ½ä½“åç§°ï¼ˆAgent as Toolæ¨¡å¼ï¼‰
                - tool_call: æ˜¯å¦ä¸ºå·¥å…·è°ƒç”¨

        Yields:
            Dict: æµå¼å“åº”äº‹ä»¶
        """
        try:
            # æå–è¯·æ±‚ä¿¡æ¯
            input_text = request_data.get("input", "")
            user_id = context.get("user_id", "unknown") if context else "unknown"
            session_id = context.get("session_id", "unknown") if context else "unknown"
            parent_agent = context.get("parent_agent", "") if context else ""
            tool_call = context.get("tool_call", False) if context else False

            if tool_call:
                self.logger.info(f"ğŸ”§ Agent as Toolæ¨¡å¼ï¼Œçˆ¶æ™ºèƒ½ä½“: {parent_agent}")

            # åˆå§‹åŒ–Tokenç´¯åŠ å™¨
            await self.initialize_token_accumulator(user_id, session_id)

            # å‘é€å¼€å§‹äº‹ä»¶
            yield {
                "event_type": "tool_start",
                "data": {
                    "tool_name": "score_analyzer",
                    "timestamp": datetime.now().isoformat()
                }
            }

            # è§£æè¾“å…¥å‚æ•°
            evaluation_results = request_data.get("evaluation_results", [])
            
            if not evaluation_results:
                yield {
                    "event_type": "error",
                    "data": {
                        "error": "è¯„ä¼°ç»“æœä¸ºç©º",
                        "message": "è¯·æä¾›æœ‰æ•ˆçš„è¯„ä¼°ç»“æœ"
                    }
                }
                return
            
            # å‘é€å¤„ç†å¼€å§‹äº‹ä»¶
            yield {
                "event_type": "tool_processing",
                "data": {
                    "message": "æ­£åœ¨è¿›è¡Œè¯„åˆ†åˆ†æ...",
                    "total_rounds": len(evaluation_results)
                }
            }
            
            # æ‰§è¡Œè¯„åˆ†åˆ†æ
            analysis_result = await self._analyze_scores(evaluation_results)
            
            # å‘é€æœ€ç»ˆç»“æœ
            yield {
                "event_type": "tool_complete",
                "data": {
                    "tool_name": "score_analyzer",
                    "result": analysis_result,
                    "timestamp": datetime.now().isoformat()
                }
            }
            
        except Exception as e:
            self.logger.error(f"å¤„ç†è¯„åˆ†åˆ†æè¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            yield {
                "event_type": "error",
                "data": {
                    "error": str(e),
                    "message": "è¯„åˆ†åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯"
                }
            }
    
    async def _analyze_scores(self, evaluation_results: List[str]) -> Dict[str, Any]:
        """
        åˆ†æè¯„åˆ†ç»“æœ
        
        Args:
            evaluation_results: è¯„ä¼°ç»“æœåˆ—è¡¨
            
        Returns:
            Dict[str, Any]: åˆ†æç»“æœ
        """
        try:
            scores = []
            outputs_dicts = []
            loop_num = len(evaluation_results)
            
            # æå–å„è½®è¯„åˆ†
            for i, output in enumerate(evaluation_results):
                # å°è¯•æå–æ€»è¯„åˆ†
                pattern = r"æ€»è¯„åˆ†\D*(\d+(\.\d+)?)"
                match = re.search(pattern, output)
                if match:
                    score = float(match.group(1))
                else:
                    # å°è¯•å…¶ä»–è¯„åˆ†æ¨¡å¼
                    pattern = r"æ€»ä½“è¯„ä»·\D*(\d+(\.\d+)?)"
                    match = re.search(pattern, output)
                    if match:
                        score = float(match.group(1))
                    else:
                        # æœªåŒ¹é…åˆ°åˆ†æ•°
                        score = "-"
                        loop_num -= 1
                
                scores.append(score)
                outputs_dict = {
                    "score": score,
                    "text": output
                }
                outputs_dicts.append(outputs_dict)
            
            # è¿‡æ»¤æœ‰æ•ˆè¯„åˆ†
            num_scores = [item for item in scores if isinstance(item, float)]
            if not num_scores:
                return {
                    "error": "æ²¡æœ‰æŠ“åˆ°ä»»ä½•è¯„åˆ†",
                    "scores": [],
                    "analysis": "è¯„åˆ†åˆ†æå¤±è´¥"
                }
            
            # ç»Ÿè®¡åˆ†æ
            high_scores = [s for s in num_scores if s >= 8.0]
            very_high_scores = [s for s in num_scores if s >= 8.5]
            
            # ç¡®å®šè¯„çº§
            if not len(num_scores) == 10:
                attention_level = 'è¿è¡Œå¤±è´¥'
            elif len(very_high_scores) > 0:
                attention_level = "S å¼ºçƒˆå…³æ³¨"
            elif len(high_scores) >= 8:
                attention_level = "S å¼ºçƒˆå…³æ³¨"
            elif len(high_scores) >= 5:
                attention_level = "A å»ºè®®å…³æ³¨"
            else:
                attention_level = "B æ™®é€š"
            
            # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
            min_score = min(num_scores)
            max_score = max(num_scores)
            first_score = num_scores[0]
            avg = round((sum(num_scores) / len(num_scores)), 2)
            
            # è®¡ç®—å»é™¤æœ€é«˜æœ€ä½åˆ†çš„å¹³å‡åˆ†
            if len(num_scores) > 2:
                scores_sorted = sorted(num_scores)
                avg_without_top_and_bottom = round(
                    (sum(scores_sorted[1:-1]) / (len(scores_sorted) - 2)), 2)
            else:
                avg_without_top_and_bottom = avg
            
            # ç”Ÿæˆåˆ†ææŠ¥å‘Š
            summary = f"""
# AIè¯„çº§: {attention_level}
# ç»“æœ 
- è¯„ä¼°æ¬¡æ•°: {loop_num} æ¬¡. è¯„ä¼°ç»“æœ: {avg_without_top_and_bottom if avg_without_top_and_bottom else avg}
    - é¦–æ¬¡è¯„åˆ† {first_score}
    - å¤è¯„åˆ†æ•°ä¾æ¬¡ä¸º {'ã€'.join([str(x) for x in scores[1:]]) if len(scores) > 1 else '-'}
    - æœ€é«˜åˆ† {max_score}
    - æœ€ä½åˆ† {min_score}
    - å¹³å‡åˆ† {avg}
# è¯„ä¼°å‚è€ƒ
- ä»¥è¯„ä¼°åæ¬¡ä¸ºåŸºå‡†ï¼š
    - å½“å‡ºç°ä¸åŠäº”æ¬¡8.0åŠä»¥ä¸Šè¯„åˆ†æ—¶ï¼Œè¡¨ç¤ºè¯¥å¤§çº² "æ™®é€š"ï¼Œå¯¹åº”è¯„çº§ä¸ºBã€‚ 
    - å½“å‡ºç°è‡³å°‘äº”æ¬¡8.0åŠä»¥ä¸Šè¯„åˆ†æ—¶ï¼Œè¡¨ç¤ºè¯¥å¤§çº²å¯ "å»ºè®®å…³æ³¨"ï¼Œå¯¹åº”è¯„çº§ä¸ºAã€‚ 
    - å½“å‡ºç°è‡³å°‘å…«æ¬¡8.0åŠä»¥ä¸Šè¯„åˆ†æ—¶ï¼Œè¡¨ç¤ºè¯¥å¤§çº²å¯ "å¼ºçƒˆå…³æ³¨"ï¼Œå¯¹åº”è¯„çº§ä¸ºSã€‚
    - å½“å‡ºç°è‡³å°‘ä¸€æ¬¡8.5åŠä»¥ä¸Šè¯„åˆ†æ—¶ï¼Œæ— è®ºå…¶ä»–è¯„åˆ†å¦‚ä½•ï¼Œå‡è¡¨ç¤ºè¯¥å¤§çº²å¯ "å¼ºçƒˆå…³æ³¨"ï¼Œå¯¹åº”è¯„çº§ä¸ºSã€‚
"""
            
            # æ·»åŠ è¯¦ç»†è¯„ä¼°ç»“æœ
            for i, v in enumerate(outputs_dicts):
                output = v["text"]
                summary += f"\n## ç¬¬{i + 1}æ¬¡æ‰§è¡Œç»“æœ: \n{output}\n"
            
            analysis_result = {
                "attention_level": attention_level,
                "total_rounds": loop_num,
                "scores": scores,
                "statistics": {
                    "min_score": min_score,
                    "max_score": max_score,
                    "avg_score": avg,
                    "avg_without_extremes": avg_without_top_and_bottom,
                    "first_score": first_score,
                    "high_scores_count": len(high_scores),
                    "very_high_scores_count": len(very_high_scores)
                },
                "evaluation_summary": summary,
                "detailed_results": outputs_dicts
            }
            
            return analysis_result
            
        except Exception as e:
            self.logger.error(f"è¯„åˆ†åˆ†æå¤±è´¥: {str(e)}")
            return {
                "error": str(e),
                "scores": [],
                "analysis": "è¯„åˆ†åˆ†æå¤±è´¥"
            }
    
    def get_tool_info(self) -> Dict[str, Any]:
        """è·å–å·¥å…·ä¿¡æ¯"""
        return {
            "tool_name": "score_analyzer",
            "description": "è¯„åˆ†åˆ†æå·¥å…·æ™ºèƒ½ä½“",
            "function": "å¯¹å¤šè½®è¯„ä¼°ç»“æœè¿›è¡Œç»Ÿè®¡åˆ†æï¼Œç”Ÿæˆè¯„çº§å»ºè®®",
            "input_parameters": {
                "evaluation_results": "list - å¤šè½®è¯„ä¼°ç»“æœåˆ—è¡¨"
            },
            "output": {
                "attention_level": "str - è¯„çº§ç­‰çº§",
                "total_rounds": "int - è¯„ä¼°è½®æ¬¡",
                "scores": "list - è¯„åˆ†åˆ—è¡¨",
                "statistics": "dict - ç»Ÿè®¡æŒ‡æ ‡",
                "evaluation_summary": "str - è¯„ä¼°æ€»ç»“",
                "detailed_results": "list - è¯¦ç»†ç»“æœ"
            },
            "rating_levels": {
                "S": "å¼ºçƒˆå…³æ³¨ - å‡ºç°è‡³å°‘ä¸€æ¬¡8.5åˆ†æˆ–è‡³å°‘å…«æ¬¡8.0åˆ†",
                "A": "å»ºè®®å…³æ³¨ - å‡ºç°è‡³å°‘äº”æ¬¡8.0åˆ†",
                "B": "æ™®é€š - ä¸åŠäº”æ¬¡8.0åˆ†"
            },
            "statistics_metrics": [
                "min_score - æœ€ä½åˆ†",
                "max_score - æœ€é«˜åˆ†", 
                "avg_score - å¹³å‡åˆ†",
                "avg_without_extremes - å»é™¤æå€¼å¹³å‡åˆ†",
                "first_score - é¦–æ¬¡è¯„åˆ†",
                "high_scores_count - é«˜åˆ†æ¬¡æ•°",
                "very_high_scores_count - æé«˜åˆ†æ¬¡æ•°"
            ]
        }