from typing import AsyncGenerator, Dict, Any, Optional

"""
æ•…äº‹è¯„ä¼°æ™ºèƒ½ä½“ - æ”¯æŒAgent as Toolæœºåˆ¶

ä¸šåŠ¡å¤„ç†é€»è¾‘ï¼š
1. è¾“å…¥å¤„ç†ï¼šæ¥æ”¶æ•…äº‹æ–‡æœ¬å’Œè¯„ä¼°å‚æ•°ï¼Œæ”¯æŒå¤šç§è¾“å…¥æ ¼å¼
2. æ·±åº¦é˜…è¯»ï¼šå¯¹æ•…äº‹æ–‡æœ¬è¿›è¡Œæ·±å…¥é˜…è¯»å’Œç†è§£
3. å¤šç»´åº¦è¯„ä¼°ï¼šä»å¸‚åœºæ½œåŠ›ã€åˆ›æ–°å±æ€§ã€å†…å®¹äº®ç‚¹ã€æ€»ä½“è¯„ä»·å››ä¸ªç»´åº¦è¯„ä¼°
4. ä¸¥æ ¼è¯„åˆ†ï¼šæŒ‰ç…§Story Evaluation Frameworkè¿›è¡Œä¸¥æ ¼ã€ç»†è‡´çš„è¯„åˆ†
5. è¯„åˆ†æ ‡å‡†ï¼š8.5åˆ†åŠä»¥ä¸Šä¼˜ç§€ï¼Œ8.0-8.4åˆ†è‰¯å¥½ï¼Œ7.5-7.9åˆ†åˆæ ¼ï¼Œ7.4åˆ†åŠä»¥ä¸‹è¾ƒå·®
6. å¼€å‘å»ºè®®ï¼šç»“åˆè¯„åˆ†ç»“æœç»™å‡ºæ˜¯å¦å€¼å¾—è¿›ä¸€æ­¥å¼€å‘æˆå½±è§†å‰§çš„å»ºè®®
7. è¾“å‡ºæ ¼å¼åŒ–ï¼šè¿”å›ç»“æ„åŒ–çš„è¯„ä¼°ç»“æœå’Œè¯¦ç»†è¯„åˆ†
8. Agent as Toolï¼šæ”¯æŒè¢«å…¶ä»–æ™ºèƒ½ä½“è°ƒç”¨ï¼Œå®ç°ä¸Šä¸‹æ–‡éš”ç¦»

ä»£ç ä½œè€…ï¼šå®«çµç‘
åˆ›å»ºæ—¶é—´ï¼š2025å¹´10æœˆ19æ—¥
"""
from datetime import datetime
try:
    from .base_juben_agent import BaseJubenAgent
except ImportError:
    # å¤„ç†ç›¸å¯¹å¯¼å…¥é—®é¢˜
    import sys
    from pathlib import Path
    sys.path.insert(0, str(Path(__file__).parent.parent))

    from agents.base_juben_agent import BaseJubenAgent 

class StoryEvaluationAgent(BaseJubenAgent):
    """
    æ•…äº‹è¯„ä¼°æ™ºèƒ½ä½“
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. å¯¹æä¾›çš„æ•…äº‹æ–‡æœ¬è¿›è¡Œæ·±å…¥é˜…è¯»
    2. æ ¹æ®é¢˜æä¸ç±»å‹ç±»æ•…äº‹çš„è¯„ä¼°é‡ç‚¹ï¼Œä»å„ä¸ªç»´åº¦å¯¹è¯¥æ•…äº‹è¿›è¡Œåˆ¤æ–­ã€è¯„åˆ†
    3. ç»“åˆåˆ¤æ–­ï¼Œä¸ºç”¨æˆ·åç»­æ˜¯å¦è¦å¼€å‘è¯¥æ•…äº‹ç»™å‡ºæ„è§
    4. ä¸¥æ ¼ã€ç»†è‡´è¦æ±‚ä¸‹çš„åˆ†æä¸æ‰“åˆ†
    5. å¤šç»´åº¦è¯„ä¼°ï¼šå¸‚åœºæ½œåŠ›ã€åˆ›æ–°å±æ€§ã€å†…å®¹äº®ç‚¹ã€æ€»ä½“è¯„ä»·
    """
    
    def __init__(self, model_provider: str = "zhipu"):
        """åˆå§‹åŒ–æ•…äº‹è¯„ä¼°æ™ºèƒ½ä½“"""
        super().__init__("story_evaluation", model_provider)
        
        # ç³»ç»Ÿæç¤ºè¯é…ç½®
        self.logger.info("æ•…äº‹è¯„ä¼°æ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ")
    
    # ç³»ç»Ÿæç¤ºè¯ç”±åŸºç±»è‡ªåŠ¨åŠ è½½ï¼Œæ— éœ€é‡å†™
    
    async def process_request(
        self,
        request_data: Dict[str, Any],
        context: Optional[Dict[str, Any]] = None
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        å¤„ç†è¯·æ±‚ - æ”¯æŒAgent as Toolæœºåˆ¶

        Args:
            request_data: è¯·æ±‚æ•°æ®
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
                - user_id: ç”¨æˆ·ID
                - session_id: ä¼šè¯ID
                - parent_agent: çˆ¶æ™ºèƒ½ä½“åç§°ï¼ˆAgent as Toolæ¨¡å¼ï¼‰
                - tool_call: æ˜¯å¦ä¸ºå·¥å…·è°ƒç”¨

        Yields:
            Dict: æµå¼å“åº”äº‹ä»¶
        """
        try:
            # æå–è¯·æ±‚ä¿¡æ¯
            input_text = request_data.get("input", "")
            user_id = context.get("user_id", "unknown") if context else "unknown"
            session_id = context.get("session_id", "unknown") if context else "unknown"
            parent_agent = context.get("parent_agent", "") if context else ""
            tool_call = context.get("tool_call", False) if context else False

            if tool_call:
                self.logger.info(f"ğŸ”§ Agent as Toolæ¨¡å¼ï¼Œçˆ¶æ™ºèƒ½ä½“: {parent_agent}")

            # åˆå§‹åŒ–Tokenç´¯åŠ å™¨
            await self.initialize_token_accumulator(user_id, session_id)

            # å‘é€å¼€å§‹äº‹ä»¶
            yield {
                "event_type": "tool_start",
                "data": {
                    "tool_name": "story_evaluation",
                    "timestamp": datetime.now().isoformat()
                }
            }

            # è§£æè¾“å…¥å‚æ•°
            story_text = request_data.get("story_text", "")
            theme = request_data.get("theme", "å°è¯´")
            round_num = request_data.get("round", 1)
            
            if not story_text:
                yield {
                    "event_type": "error",
                    "data": {
                        "error": "æ•…äº‹æ–‡æœ¬ä¸ºç©º",
                        "message": "è¯·æä¾›æœ‰æ•ˆçš„æ•…äº‹æ–‡æœ¬å†…å®¹"
                    }
                }
                return
            
            # å‘é€å¤„ç†å¼€å§‹äº‹ä»¶
            yield {
                "event_type": "tool_processing",
                "data": {
                    "message": f"æ­£åœ¨è¿›è¡Œç¬¬{round_num}è½®æ•…äº‹è¯„ä¼°...",
                    "theme": theme,
                    "text_length": len(story_text)
                }
            }
            
            # æ„å»ºç”¨æˆ·æç¤ºè¯
            user_prompt = f"""
é¢˜æç±»å‹ä¸ºï¼š{theme}
ç”¨æˆ·è¾“å…¥å¦‚ä¸‹
-----------------
{story_text}
"""
            
            # è°ƒç”¨LLMç”Ÿæˆæ•…äº‹è¯„ä¼°
            evaluation_chunks = []
            async for event in self._call_llm(user_prompt, context):
                if event.get("event_type") == "llm_chunk":
                    chunk = event.get("data", "")
                    evaluation_chunks.append(chunk)
                    yield event
            
            # æ•´åˆç”Ÿæˆçš„è¯„ä¼°ç»“æœ
            full_evaluation = "".join(evaluation_chunks)
            
            # éªŒè¯å’Œä¼˜åŒ–è¯„ä¼°ç»“æœ
            optimized_evaluation = await self._optimize_evaluation(full_evaluation, round_num)
            
            # æå–è¯„åˆ†ä¿¡æ¯
            scores = self._extract_scores(optimized_evaluation)
            
            # å‘é€æœ€ç»ˆç»“æœ
            yield {
                "event_type": "tool_complete",
                "data": {
                    "tool_name": "story_evaluation",
                    "result": {
                        "evaluation": optimized_evaluation,
                        "scores": scores,
                        "round": round_num,
                        "theme": theme
                    },
                    "timestamp": datetime.now().isoformat()
                }
            }
            
        except Exception as e:
            self.logger.error(f"å¤„ç†æ•…äº‹è¯„ä¼°è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            yield {
                "event_type": "error",
                "data": {
                    "error": str(e),
                    "message": "æ•…äº‹è¯„ä¼°è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯"
                }
            }
    
    async def _optimize_evaluation(self, evaluation: str, round_num: int) -> str:
        """
        ä¼˜åŒ–è¯„ä¼°ç»“æœï¼Œç¡®ä¿æ ¼å¼æ­£ç¡®
        
        Args:
            evaluation: åŸå§‹è¯„ä¼°æ–‡æœ¬
            round_num: è¯„ä¼°è½®æ¬¡
            
        Returns:
            str: ä¼˜åŒ–åçš„è¯„ä¼°ç»“æœ
        """
        try:
            # æ¸…ç†æ–‡æœ¬
            evaluation = evaluation.strip()
            
            # ç¡®ä¿åŒ…å«å¿…è¦çš„è¯„ä¼°ç»´åº¦
            required_sections = [
                "ã€å¸‚åœºæ½œåŠ›ã€‘", "ã€åˆ›æ–°å±æ€§ã€‘", "ã€å†…å®¹äº®ç‚¹ã€‘", 
                "ã€æ€»ä½“è¯„ä»·ã€‘", "ã€è·Ÿè¿›å»ºè®®ã€‘"
            ]
            
            missing_sections = []
            for section in required_sections:
                if section not in evaluation:
                    missing_sections.append(section)
            
            # å¦‚æœæœ‰ç¼ºå¤±çš„éƒ¨åˆ†ï¼Œå°è¯•è¡¥å……
            if missing_sections:
                self.logger.warning(f"è¯„ä¼°ç»“æœç¼ºå°‘å¿…è¦éƒ¨åˆ†: {missing_sections}")
                # è¿™é‡Œå¯ä»¥æ ¹æ®éœ€è¦å®ç°è¡¥å……é€»è¾‘
            
            # ç¡®ä¿åŒ…å«ç‰ˆæœ¬ä¿¡æ¯
            if "ã€version2.9ã€‘" not in evaluation:
                evaluation = "ã€version2.9ã€‘\n" + evaluation
            
            return evaluation
            
        except Exception as e:
            self.logger.error(f"ä¼˜åŒ–è¯„ä¼°ç»“æœå¤±è´¥: {str(e)}")
            return evaluation
    
    def _extract_scores(self, evaluation: str) -> Dict[str, float]:
        """
        ä»è¯„ä¼°ç»“æœä¸­æå–è¯„åˆ†ä¿¡æ¯
        
        Args:
            evaluation: è¯„ä¼°ç»“æœæ–‡æœ¬
            
        Returns:
            Dict[str, float]: è¯„åˆ†ä¿¡æ¯å­—å…¸
        """
        try:
            scores = {}
            
            # å®šä¹‰è¯„åˆ†æå–æ¨¡å¼
            score_patterns = {
                "audience_suitability": r"å—ä¼—é€‚åˆåº¦.*?è¯„åˆ†[ï¼š:]\s*(\d+\.?\d*)",
                "discussion_heat": r"è®¨è®ºçƒ­åº¦.*?è¯„åˆ†[ï¼š:]\s*(\d+\.?\d*)",
                "scarcity": r"ç¨€ç¼ºæ€§.*?è¯„åˆ†[ï¼š:]\s*(\d+\.?\d*)",
                "playback_data": r"æ’­æ”¾æ•°æ®.*?è¯„åˆ†[ï¼š:]\s*(\d+\.?\d*)",
                "core_selection": r"æ ¸å¿ƒé€‰ç‚¹.*?è¯„åˆ†[ï¼š:]\s*(\d+\.?\d*)",
                "story_concept": r"æ•…äº‹æ¦‚å¿µ.*?è¯„åˆ†[ï¼š:]\s*(\d+\.?\d*)",
                "story_design": r"æ•…äº‹è®¾è®¡.*?è¯„åˆ†[ï¼š:]\s*(\d+\.?\d*)",
                "theme_meaning": r"ä¸»é¢˜ç«‹æ„.*?è¯„åˆ†[ï¼š:]\s*(\d+\.?\d*)",
                "story_situation": r"æ•…äº‹æƒ…å¢ƒ.*?è¯„åˆ†[ï¼š:]\s*(\d+\.?\d*)",
                "character_setting": r"äººç‰©è®¾å®š.*?è¯„åˆ†[ï¼š:]\s*(\d+\.?\d*)",
                "character_relationship": r"äººç‰©å…³ç³».*?è¯„åˆ†[ï¼š:]\s*(\d+\.?\d*)",
                "plot_bridge": r"æƒ…èŠ‚æ¡¥æ®µ.*?è¯„åˆ†[ï¼š:]\s*(\d+\.?\d*)",
                "total_score": r"æ€»è¯„åˆ†[ï¼š:]\s*(\d+\.?\d*)"
            }
            
            # æå–å„é¡¹è¯„åˆ†
            for key, pattern in score_patterns.items():
                match = re.search(pattern, evaluation)
                if match:
                    try:
                        scores[key] = float(match.group(1))
                    except ValueError:
                        continue
            
            return scores
            
        except Exception as e:
            self.logger.error(f"æå–è¯„åˆ†ä¿¡æ¯å¤±è´¥: {str(e)}")
            return {}
    
    def get_tool_info(self) -> Dict[str, Any]:
        """è·å–å·¥å…·ä¿¡æ¯"""
        return {
            "tool_name": "story_evaluation",
            "description": "æ•…äº‹è¯„ä¼°æ™ºèƒ½ä½“",
            "function": "å¯¹æ•…äº‹æ–‡æœ¬è¿›è¡Œå¤šç»´åº¦è¯„ä¼°å’Œè¯„åˆ†",
            "input_parameters": {
                "story_text": "str - éœ€è¦è¯„ä¼°çš„æ•…äº‹æ–‡æœ¬å†…å®¹",
                "theme": "str - æ•…äº‹é¢˜æç±»å‹",
                "round": "int - è¯„ä¼°è½®æ¬¡"
            },
            "output": {
                "evaluation": "str - å®Œæ•´çš„è¯„ä¼°ç»“æœ",
                "scores": "dict - å„é¡¹è¯„åˆ†ä¿¡æ¯",
                "round": "int - è¯„ä¼°è½®æ¬¡",
                "theme": "str - æ•…äº‹é¢˜æç±»å‹"
            },
            "evaluation_dimensions": {
                "market_potential": ["å—ä¼—é€‚åˆåº¦", "è®¨è®ºçƒ­åº¦", "ç¨€ç¼ºæ€§", "æ’­æ”¾æ•°æ®"],
                "innovation_attributes": ["æ ¸å¿ƒé€‰ç‚¹", "æ•…äº‹æ¦‚å¿µ", "æ•…äº‹è®¾è®¡"],
                "content_highlights": ["ä¸»é¢˜ç«‹æ„", "æ•…äº‹æƒ…å¢ƒ", "äººç‰©è®¾å®š", "äººç‰©å…³ç³»", "æƒ…èŠ‚æ¡¥æ®µ"],
                "overall_evaluation": ["æ€»ä½“è¯„ä»·"]
            },
            "scoring_standards": {
                "excellent": "8.5åˆ†åŠä»¥ä¸Š - ä¼˜ç§€ï¼Œæå¼ºç«äº‰åŠ›",
                "good": "8.0-8.4åˆ† - è‰¯å¥½ï¼Œè¾ƒå¼ºç«äº‰åŠ›",
                "qualified": "7.5-7.9åˆ† - åˆæ ¼ï¼Œä¸­è§„ä¸­çŸ©",
                "poor": "7.4åˆ†åŠä»¥ä¸‹ - è¾ƒå·®ï¼Œç«äº‰åŠ›å¼±"
            }
        }
