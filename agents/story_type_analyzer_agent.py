from typing import AsyncGenerator, Dict, Any, Optional

"""
æ•…äº‹äº”å…ƒç´ å·¥ä½œæµ - é¢˜æç±»å‹åˆ†ææ™ºèƒ½ä½“
 æä¾›é¢˜æç±»å‹ä¸åˆ›æ„æç‚¼æœåŠ¡
ä½œä¸ºæ•…äº‹äº”å…ƒç´ åˆ†æç³»ç»Ÿçš„ä¸“ä¸šå­æ™ºèƒ½ä½“ä¹‹ä¸€

ä¸šåŠ¡å¤„ç†é€»è¾‘ï¼š
1. è¾“å…¥å¤„ç†ï¼šæ¥æ”¶æ•…äº‹æ–‡æœ¬æˆ–inputå­—æ®µï¼Œæ”¯æŒå¤šç§è¾“å…¥æ ¼å¼
2. ç±»å‹åˆ†æï¼šåˆ†ææ•…äº‹çš„ç±»å‹ä¸å™äº‹ä¸»é¢˜ï¼ˆçˆ±æƒ…ã€å†’é™©ã€ç§‘å¹»ã€ææ€–ç­‰ï¼‰
3. ç»“æ„åˆ†æï¼šæç‚¼æ•…äº‹çš„æƒ…èŠ‚ç»“æ„ç‰¹ç‚¹å’Œå‘å±•è„‰ç»œ
4. åˆ›æ„æç‚¼ï¼šæ€»ç»“æ•…äº‹çš„æ ¸å¿ƒåˆ›æ„å’Œç‹¬ç‰¹ä¹‹å¤„
5. äº®ç‚¹æ€»ç»“ï¼šæç‚¼æ•…äº‹çš„ä¸»è¦äº®ç‚¹å’Œå¸å¼•åŠ›è¦ç´ 
6. è´¨é‡æ§åˆ¶ï¼šç¡®ä¿åˆ†æå…¨é¢ã€å‡†ç¡®ï¼Œè¦†ç›–å››ä¸ªåˆ†æç»´åº¦
7. è¾“å‡ºæ ¼å¼åŒ–ï¼šè¿”å›ç»“æ„åŒ–çš„é¢˜æç±»å‹åˆ†ææ•°æ®
8. Agent as Toolï¼šæ”¯æŒè¢«å…¶ä»–æ™ºèƒ½ä½“è°ƒç”¨ï¼Œä¸Šä¸‹æ–‡éš”ç¦»

ä»£ç ä½œè€…ï¼šå®«çµç‘
åˆ›å»ºæ—¶é—´ï¼š2024å¹´10æœˆ19æ—¥
"""

try:
    from .base_juben_agent import BaseJubenAgent
except ImportError:
    # å¤„ç†ç›¸å¯¹å¯¼å…¥é—®é¢˜
    import sys
    from pathlib import Path
    sys.path.insert(0, str(Path(__file__).parent.parent))

    from agents.base_juben_agent import BaseJubenAgent

class StoryTypeAnalyzerAgent(BaseJubenAgent):
    """
    é¢˜æç±»å‹åˆ†ææ™ºèƒ½ä½“ - æ•…äº‹äº”å…ƒç´ åˆ†æç³»ç»Ÿçš„ä¸“ä¸šå­æ™ºèƒ½ä½“
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. åˆ†ææ•…äº‹çš„ç±»å‹ä¸å™äº‹ä¸»é¢˜
    2. æç‚¼æ•…äº‹çš„æƒ…èŠ‚ç»“æ„ç‰¹ç‚¹
    3. æ€»ç»“æ•…äº‹çš„æ ¸å¿ƒåˆ›æ„
    4. æç‚¼æ•…äº‹çš„ä¸»è¦äº®ç‚¹
    5. æ”¯æŒAgent as Toolæœºåˆ¶ï¼Œå¯è¢«å…¶ä»–æ™ºèƒ½ä½“è°ƒç”¨
    
    ä½œä¸ºæ•…äº‹äº”å…ƒç´ å·¥ä½œæµä¸­çš„ä¸“ä¸šå­æ™ºèƒ½ä½“ï¼Œä¸“é—¨è´Ÿè´£é¢˜æç±»å‹åˆ†æä»»åŠ¡
    """
    
    def __init__(self, model_provider: str = "zhipu"):
        super().__init__("story_type_analyzer", model_provider)
        
        # å·¥ä½œæµé…ç½®
        self.workflow_type = "story_five_elements"
        self.sub_agent_type = "story_type_analyzer"
        self.analysis_dimensions = ["ç±»å‹ä¸ä¸»é¢˜", "æƒ…èŠ‚ç»“æ„", "æ ¸å¿ƒåˆ›æ„", "æ•…äº‹äº®ç‚¹"]
        self.story_themes = ["çˆ±æƒ…", "å†’é™©", "ç§‘å¹»", "ææ€–", "å–œå‰§", "æ‚¬ç–‘", "åŠ¨ä½œ", "å†å²"]
        
        self.logger.info("ğŸ­ é¢˜æç±»å‹åˆ†ææ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ")
        self.logger.info(f"ğŸ“‹ å·¥ä½œæµç±»å‹: {self.workflow_type}")
        self.logger.info(f"ğŸ¯ å­æ™ºèƒ½ä½“ç±»å‹: {self.sub_agent_type}")
        self.logger.info(f"ğŸ“Š é…ç½®: åˆ†æç»´åº¦{len(self.analysis_dimensions)}ä¸ªï¼Œæ”¯æŒ{len(self.story_themes)}ç§ä¸»é¢˜ç±»å‹")
    
    def _load_story_type_analyzer_prompt(self) -> str:
        """åŠ è½½é¢˜æç±»å‹åˆ†ææç¤ºè¯"""
        return """
## Profile:
- role: èµ„æ·±çš„æ•…äº‹ç¼–å‰§
- language: ä¸­æ–‡
- description: æ ¹æ®ç»™å‡ºçš„æ–‡æœ¬ï¼Œå‡†ç¡®åœ°æ€»ç»“å‡ºæ–‡æœ¬æ•…äº‹çš„ç±»å‹ä¸ç»“æ„ï¼Œæç‚¼æ•…äº‹çš„ç»“æ„ç‰¹ç‚¹ã€æ ¸å¿ƒåˆ›æ„åŠä¸»è¦äº®ç‚¹ã€‚

## Definition
- "æ•…äº‹ç±»å‹"æ˜¯ä¸€ä¸ªæˆå‰§æ¦‚å¿µï¼ŒæŒ‡æè¿°å’Œåˆ†ç±»ä¸åŒç±»å‹æ•…äº‹çš„æ–¹å¼æˆ–æ–¹æ³•ã€‚å®ƒæ¶‰åŠåˆ°å¯¹æ•…äº‹å…ƒç´ ã€æƒ…èŠ‚ç»“æ„ã€ä¸»é¢˜ã€é£æ ¼ç­‰æ–¹é¢è¿›è¡Œå½’ç±»å’Œè§£é‡Šï¼Œä»¥ä¾¿æ›´å¥½åœ°ç†è§£å’Œåˆ†ææ•…äº‹ã€‚ä¸€èˆ¬ä»¥ä¸»é¢˜åŠæƒ…èŠ‚ç»“æ„æ¥å¯¹æ•…äº‹è¿›è¡Œåˆ†æã€‚ä¸»é¢˜ä¸€èˆ¬åŒ…å«çˆ±æƒ…ã€å†’é™©ã€ç§‘å¹»ã€ææ€–ã€å–œå‰§ç­‰ã€‚æƒ…èŠ‚ç»“æ„ä¾‹å¦‚ä¼ ç»Ÿçš„ä¸‰å¹•å‰§ç»“æ„ï¼ˆèµ·å§‹ã€å‘å±•ã€é«˜æ½®ï¼‰æˆ–äº”å¹•å‰§ç»“æ„ï¼ˆå¼•å­ã€å‡åã€è½¬æŠ˜ã€é«˜æ½®ã€ç»“å±€ï¼‰ã€‚

## Constrainsï¼š
- è¯·ä¸¥æ ¼æŒ‰ç…§æ•…äº‹åŸæ–‡æ‰€è¡¨è¾¾çš„å†…å®¹æ¥æ€»ç»“æ•…äº‹ç±»å‹ä¸ä¸»é¢˜ã€‚
- æ•…äº‹ç±»å‹ä¸ºè¯è¯­æˆ–çŸ­è¯­ï¼Œä¸è¦ç”¨å¥å­è¡¨ç¤ºã€‚

## Skillsï¼š
- å–„äºåˆ†æã€æç‚¼æ•…äº‹çš„ç±»å‹ã€åˆ›æ„ã€äº®ç‚¹ã€‚
- å–„äºå¯¹æ•…äº‹ç±»å‹çš„å®šä¹‰è¿›è¡Œå……åˆ†çš„ç†è§£ï¼Œå¹¶å‡†ç¡®åˆ†ææ•…äº‹æ–‡æœ¬çš„ç±»å‹ã€‚
- å–„äºæŠŠæ¡æ•…äº‹çš„æƒ…èŠ‚ç»“æ„ï¼Œå¹¶ä½œå‡ºå‡†ç¡®åœ°åˆ¤æ–­ä¸åˆ†æã€‚
- å–„äºé€šè¿‡æ•…äº‹æ–‡æœ¬çš„ä¸Šä¸‹æ–‡å…³ç³»ï¼Œå¯¹æ•…äº‹æ–‡æœ¬ä¸­è¡¨è¿°é‡å¤ã€æ··ä¹±ã€æ–­è£‚çš„éƒ¨åˆ†è¿›è¡Œæ¢³ç†ï¼Œä»è€Œæ€»ç»“å‡ºå‡†ç¡®çš„æ•…äº‹ä¿¡æ¯ã€‚

## Goals:
- å¯¹æä¾›çš„æ•…äº‹æ–‡æœ¬è¿›è¡Œé˜…è¯»ä¸ç†è§£ï¼Œæ€»ç»“å…¶ä¸»è¦çš„æ•…äº‹ç±»å‹ï¼Œåˆ†æå…¶æƒ…èŠ‚ç»“æ„ã€æ ¸å¿ƒåˆ›æ„ä¸æ•…äº‹äº®ç‚¹ã€‚

## Workflows
- ç¬¬ä¸€æ­¥ï¼Œå¯¹æä¾›çš„æ•…äº‹æ–‡æœ¬è¿›è¡Œå……åˆ†çš„é˜…è¯»ä¸ç†è§£ã€‚
- ç¬¬äºŒæ­¥ï¼Œæ ¹æ®ã€ŒDefinitionã€ä¸­æœ‰å…³æ•…äº‹ç±»å‹çš„ä»‹ç»ï¼Œæ€»ç»“è¯¥æ•…äº‹ä¸»è¦çš„æ•…äº‹ç±»å‹ä¸å™äº‹ä¸»é¢˜ã€‚
- ç¬¬ä¸‰æ­¥ï¼Œå¯¹è¯¥æ•…äº‹çš„åŸºæœ¬ç»“æ„è¿›è¡Œåˆ†æä¸æ€»ç»“ã€‚
- ç¬¬å››æ­¥ï¼Œæ€»ç»“æç‚¼æ•…è¯¥äº‹çš„æ ¸å¿ƒåˆ›æ„ã€‚
- ç¬¬äº”æ­¥ï¼Œæ€»ç»“æç‚¼è¯¥æ•…äº‹çš„ä¸»è¦äº®ç‚¹ã€‚

## Outputformateï¼š
ã€ç±»å‹ä¸ä¸»é¢˜ã€‘ï¼š<æ€»ç»“æ•…äº‹æ–‡æœ¬çš„ç±»å‹ä¸å™äº‹ä¸»é¢˜ã€‚>
ã€æƒ…èŠ‚ç»“æ„ã€‘ï¼š<æ€»ç»“æç‚¼æ•…äº‹æ–‡æœ¬çš„ä¸»è¦æƒ…èŠ‚ç»“æ„ï¼Œä»¥Markdownçš„æ ¼å¼è¿›è¡Œå‘ˆç°ã€‚>
ã€æ ¸å¿ƒåˆ›æ„ã€‘ï¼š<æ€»ç»“æç‚¼æ•…äº‹æ–‡æœ¬çš„æ ¸å¿ƒåˆ›æ„ï¼Œä»¥Markdownçš„æ ¼å¼è¿›è¡Œå‘ˆç°ã€‚>
ã€æ•…äº‹äº®ç‚¹ã€‘ï¼š<æ€»ç»“æç‚¼æ•…äº‹æ–‡æœ¬çš„ä¸»è¦äº®ç‚¹ï¼Œä»¥Markdownçš„æ ¼å¼è¿›è¡Œå‘ˆç° ã€‚>
"""
    
    async def analyze_story_type(self, story_text: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        åˆ†ææ•…äº‹ç±»å‹ï¼ˆä¾¿äºä½œä¸ºæ™®é€šå·¥å…·å‡½æ•°è°ƒç”¨ï¼‰

        å†…éƒ¨å¤ç”¨æµå¼çš„ process_requestï¼Œå°†æ‰€æœ‰å†…å®¹å—æ‹¼æ¥æˆä¸€ä¸ªå­—ç¬¦ä¸²è¿”å›ã€‚
        """
        try:
            request_data = {
                "input": story_text,
                "story_text": story_text,
            }

            chunks: list[str] = []
            async for event in self.process_request(request_data, context):
                if event.get("event_type") == "llm_chunk":
                    data = event.get("data", "")
                    if isinstance(data, str):
                        chunks.append(data)

            return {
                "success": True,
                "analysis_result": "".join(chunks),
                "story_text": story_text,
            }

        except Exception as e:
            self.logger.error(f"æ•…äº‹ç±»å‹åˆ†æå¤±è´¥: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "analysis_result": "",
                "story_text": story_text,
            }

    async def process_request(
        self,
        request_data: Dict[str, Any],
        context: Optional[Dict[str, Any]] = None
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        å¤„ç†æ•…äº‹ç±»å‹åˆ†æè¯·æ±‚ï¼ˆæµå¼ç‰ˆæœ¬ï¼‰

        æ³¨æ„ï¼š
        - è¿”å›çš„æ˜¯å¼‚æ­¥ç”Ÿæˆå™¨ï¼Œä¾› BaseJubenAgent çš„å¢å¼ºä¸Šä¸‹æ–‡æµç¨‹å’Œ StoryFiveElements å­è°ƒç”¨ä½¿ç”¨ï¼›
        - ç»Ÿä¸€é€šè¿‡ _emit_event è¾“å‡ºäº‹ä»¶ï¼Œevent_type ä¸º 'llm_chunk'ã€‚
        """
        user_id = context.get("user_id", "unknown") if context else "unknown"
        session_id = context.get("session_id", "unknown") if context else "unknown"

        # story_text ä¼˜å…ˆçº§ï¼šrequest_data.story_text > request_data.input > request_data.query
        story_text = (
            request_data.get("story_text")
            or request_data.get("input")
            or request_data.get("query")
            or ""
        )

        # åˆå§‹åŒ– Token ç»Ÿè®¡
        await self.initialize_token_accumulator(user_id, session_id)

        try:
            await self._emit_event(
                "system",
                "ğŸ“– æ­£åœ¨åˆ†ææ•…äº‹ç±»å‹ä¸ä¸»é¢˜...",
                {"agent": "story_type_analyzer"},
            )

            system_prompt = self._load_story_type_analyzer_prompt()
            user_prompt = f"ç”¨æˆ·è¾“å…¥å¦‚ä¸‹\n-----------------\n{story_text}"

            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ]

            # æµå¼è°ƒç”¨LLMï¼Œä½¿å…¶é€‚é…æ‰€æœ‰ä½¿ç”¨ async for çš„è·¯å¾„
            async for chunk in self._stream_llm(messages, user_id=user_id, session_id=session_id):
                if chunk:
                    yield await self._emit_event("llm_chunk", chunk)

            billing_summary = await self.get_token_billing_summary()
            if billing_summary:
                yield await self._emit_event(
                    "billing",
                    f"ğŸ“Š Tokenæ¶ˆè€—: {billing_summary['total_tokens']} tokens, ç§¯åˆ†æ‰£å‡: {billing_summary['deducted_points']} ç§¯åˆ†",
                )

            yield await self._emit_event("system", "âœ… æ•…äº‹ç±»å‹åˆ†æå®Œæˆ")

        except Exception as e:
            self.logger.error(f"å¤„ç†æ•…äº‹ç±»å‹åˆ†æè¯·æ±‚å¤±è´¥: {str(e)}")
            yield await self._emit_event("error", f"æ•…äº‹ç±»å‹åˆ†æå¤±è´¥: {str(e)}")