"""
Juben Concierge - ç«–å±çŸ­å‰§ç­–åˆ’æ¥å¾…å‘˜
 çš„conciergeè®¾è®¡ï¼Œä¸“é—¨ç”¨äºç«–å±çŸ­å‰§ç­–åˆ’çš„ç”¨æˆ·äº¤äº’å’Œéœ€æ±‚ç†è§£

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. ç”¨æˆ·éœ€æ±‚ç†è§£å’Œåˆ†æ
2. æ™ºèƒ½ä»»åŠ¡è·¯ç”±å’Œå§”æ´¾
3. ä¸Šä¸‹æ–‡ç®¡ç†å’Œå¯¹è¯ç»´æŠ¤
4. å¤šæ¨¡æ€å†…å®¹å¤„ç†
5. å®æ—¶åé¦ˆå’ŒçŠ¶æ€æ›´æ–°
"""
import asyncio
import json
import re
from typing import AsyncGenerator, Dict, Any, List, Optional, Union, Tuple
from datetime import datetime
import uuid

from .base_juben_agent import BaseJubenAgent
from .juben_orchestrator import JubenOrchestrator
from ..utils.logger import JubenLogger
from ..utils.intent_recognition import IntentRecognizer
from ..utils.url_extractor import URLExtractor
from ..utils.multimodal_processor import MultimodalProcessor


class AgentInitializationError(Exception):
    """Agent åˆå§‹åŒ–é”™è¯¯"""
    pass


class JubenConcierge(BaseJubenAgent):
    """
    ç«–å±çŸ­å‰§ç­–åˆ’æ¥å¾…å‘˜
    
    æ ¸å¿ƒèŒè´£ï¼š
    1. ğŸ¯ éœ€æ±‚ç†è§£ï¼šæ·±åº¦è§£æç”¨æˆ·æ„å›¾å’Œåˆ›ä½œéœ€æ±‚
    2. ğŸ”„ ä»»åŠ¡è·¯ç”±ï¼šæ™ºèƒ½åˆ¤æ–­å¹¶å§”æ´¾ç»™åˆé€‚çš„Agent
    3. ğŸ“ ä¸Šä¸‹æ–‡ç®¡ç†ï¼šç»´æŠ¤å¯¹è¯å†å²å’Œç”¨æˆ·åå¥½
    4. ğŸ¬ å¤šæ¨¡æ€å¤„ç†ï¼šå¤„ç†æ–‡ä»¶ã€å›¾ç‰‡ç­‰å¤šåª’ä½“å†…å®¹
    5. ğŸ¤ ç”¨æˆ·ä½“éªŒï¼šæä¾›å‹å¥½çš„äº¤äº’å’Œå®æ—¶åé¦ˆ
    """
    
    def __init__(self, model_provider: str = "zhipu"):
        """åˆå§‹åŒ–æ¥å¾…å‘˜"""
        super().__init__("juben_concierge", model_provider)

        # åˆå§‹åŒ–ç»„ä»¶ - æ·»åŠ é”™è¯¯å¤„ç†
        try:
            self.intent_recognizer = IntentRecognizer()
        except Exception as e:
            self.logger.warning(f"IntentRecognizer åˆå§‹åŒ–å¤±è´¥: {e}")
            self.intent_recognizer = None

        try:
            self.url_extractor = URLExtractor()
        except Exception as e:
            self.logger.warning(f"URLExtractor åˆå§‹åŒ–å¤±è´¥: {e}")
            self.url_extractor = None

        try:
            self.multimodal_processor = MultimodalProcessor()
        except Exception as e:
            self.logger.warning(f"MultimodalProcessor åˆå§‹åŒ–å¤±è´¥: {e}")
            self.multimodal_processor = None

        try:
            self.orchestrator = JubenOrchestrator(model_provider)
        except Exception as e:
            self.logger.error(f"JubenOrchestrator åˆå§‹åŒ–å¤±è´¥: {e}")
            raise AgentInitializationError(f"Failed to initialize orchestrator: {e}")

        # å¯¹è¯çŠ¶æ€ç®¡ç† - ä½¿ç”¨ LRU ç¼“å­˜é˜²æ­¢å†…å­˜æ³„æ¼
        from collections import OrderedDict
        self.conversation_states = OrderedDict()  # ä¼šè¯çŠ¶æ€ç¼“å­˜
        self.user_preferences = OrderedDict()     # ç”¨æˆ·åå¥½ç¼“å­˜
        self._max_conversation_states = 1000  # æœ€å¤§ä¼šè¯çŠ¶æ€æ•°
        self._max_user_preferences = 5000      # æœ€å¤§ç”¨æˆ·åå¥½æ•°

        # æ–‡ä»¶å¤„ç†é™åˆ¶
        self._max_files_per_request = 20       # å•æ¬¡è¯·æ±‚æœ€å¤§æ–‡ä»¶æ•°
        self._max_file_size = 100 * 1024 * 1024  # å•ä¸ªæ–‡ä»¶æœ€å¤§ 100MB

        # ä»»åŠ¡è·¯ç”±é…ç½®
        self.task_routing_rules = {
            "story_analysis": ["åˆ†æ", "è¯„ä¼°", "ip", "æ•…äº‹åˆ†æ", "å‰§æœ¬åˆ†æ"],
            "story_creation": ["åˆ›ä½œ", "ç¼–å†™", "åˆ›ä½œæ•…äº‹", "å†™æ•…äº‹", "æ•…äº‹åˆ›ä½œ"],
            "character_development": ["è§’è‰²", "äººç‰©", "è§’è‰²è®¾å®š", "äººç‰©å…³ç³»"],
            "plot_development": ["æƒ…èŠ‚", "æƒ…èŠ‚ç‚¹", "ç»“æ„", "æƒ…èŠ‚è®¾è®¡"],
            "drama_evaluation": ["è¯„ä¼°", "è¯„ä»·", "çŸ­å‰§è¯„ä¼°", "å‰§æœ¬è¯„ä¼°"],
            "series_analysis": ["å‰§é›†", "ç³»åˆ—", "å·²æ’­", "å‰§é›†åˆ†æ"]
        }

        self.logger.info("ğŸ­ Jubenæ¥å¾…å‘˜åˆå§‹åŒ–å®Œæˆ")
        self.logger.info(f"ğŸ”§ æ”¯æŒçš„ä»»åŠ¡ç±»å‹: {list(self.task_routing_rules.keys())}")
        multimodal_enabled = self.multimodal_processor is not None and self.multimodal_processor.is_enabled()
        self.logger.info(f"ğŸ“ å¤šæ¨¡æ€å¤„ç†: {'å¯ç”¨' if multimodal_enabled else 'ç¦ç”¨'}")
    
    async def process_request(
        self, 
        request_data: Dict[str, Any],
        context: Optional[Dict[str, Any]] = None
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        å¤„ç†ç”¨æˆ·è¯·æ±‚
        
        Args:
            request_data: è¯·æ±‚æ•°æ®
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Yields:
            Dict: æµå¼å“åº”äº‹ä»¶
        """
        user_id = request_data.get("user_id", "unknown")
        session_id = request_data.get("session_id", "unknown")
        query = request_data.get("query", "")
        file_ids = request_data.get("file_ids", [])
        
        # åˆå§‹åŒ–Tokenç´¯åŠ å™¨
        await self.initialize_token_accumulator(user_id, session_id)
        
        try:
            self.logger.info(f"ğŸ­ å¼€å§‹å¤„ç†ç”¨æˆ·è¯·æ±‚: {query[:100]}...")
            
            # å‘é€æ¥å¾…å¼€å§‹äº‹ä»¶
            yield await self._emit_event(
                "concierge_start",
                f"å¼€å§‹åˆ†æç”¨æˆ·éœ€æ±‚: {query}",
                {"user_id": user_id, "session_id": session_id, "status": "analyzing"}
            )
            
            # è·å–æˆ–åˆ›å»ºä¼šè¯çŠ¶æ€
            conversation_state = await self._get_or_create_conversation_state(user_id, session_id)
            
            # å¤„ç†å¤šæ¨¡æ€å†…å®¹
            multimodal_results = []
            if file_ids:
                yield await self._emit_event(
                    "multimodal_processing",
                    "æ­£åœ¨å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶...",
                    {"file_count": len(file_ids), "status": "processing"}
                )
                
                multimodal_results = await self._process_multimodal_content(
                    file_ids, user_id, session_id, query
                )
                
                if multimodal_results:
                    yield await self._emit_event(
                        "multimodal_complete",
                        f"æ–‡ä»¶å¤„ç†å®Œæˆï¼Œå…±åˆ†æ {len(multimodal_results)} ä¸ªæ–‡ä»¶",
                        {"results": multimodal_results, "status": "completed"}
                    )
            
            # æ„å›¾è¯†åˆ«å’Œä»»åŠ¡åˆ†æ
            intent_analysis = await self._analyze_user_intent(query, conversation_state, multimodal_results)
            
            yield await self._emit_event(
                "intent_analysis",
                f"éœ€æ±‚åˆ†æå®Œæˆ: {intent_analysis['intent_type']}",
                {"intent_analysis": intent_analysis, "status": "analyzed"}
            )
            
            # æ ¹æ®æ„å›¾å†³å®šå¤„ç†æ–¹å¼
            if intent_analysis["requires_orchestrator"]:
                # å¤æ‚ä»»åŠ¡ï¼Œå§”æ´¾ç»™ç¼–æ’å™¨
                yield await self._emit_event(
                    "orchestrator_delegation",
                    "æ£€æµ‹åˆ°å¤æ‚ä»»åŠ¡ï¼Œæ­£åœ¨å§”æ´¾ç»™ä¸“ä¸šç¼–æ’å™¨...",
                    {"task_type": intent_analysis["task_type"], "status": "delegating"}
                )
                
                # æ„å»ºç¼–æ’å™¨è¯·æ±‚
                orchestrator_request = {
                    "instruction": query,
                    "user_id": user_id,
                    "session_id": session_id,
                    "intent_analysis": intent_analysis,
                    "multimodal_results": multimodal_results,
                    "context": conversation_state
                }
                
                # å§”æ´¾ç»™ç¼–æ’å™¨
                async for event in self.orchestrator.process_request(orchestrator_request):
                    yield event
                
            else:
                # ç®€å•ä»»åŠ¡ï¼Œç›´æ¥å¤„ç†
                response = await self._handle_simple_request(
                    query, intent_analysis, conversation_state, multimodal_results
                )
                
                yield await self._emit_event(
                    "concierge_response",
                    response,
                    {"response_type": "direct", "intent_type": intent_analysis["intent_type"]}
                )
            
            # æ›´æ–°å¯¹è¯çŠ¶æ€
            await self._update_conversation_state(
                user_id, session_id, query, intent_analysis, multimodal_results
            )
            
            # ä¿å­˜å¯¹è¯è®°å½•åˆ°æ–‡ä»¶ç³»ç»Ÿ
            await self._save_conversation_record(
                user_id, session_id, query, intent_analysis, multimodal_results
            )
            
            self.logger.info(f"âœ… ç”¨æˆ·è¯·æ±‚å¤„ç†å®Œæˆ: {user_id}:{session_id}")
            
        except Exception as e:
            self.logger.error(f"âŒ å¤„ç†ç”¨æˆ·è¯·æ±‚å¤±è´¥: {e}")
            yield await self._emit_event(
                "concierge_error",
                f"å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}",
                {"error_type": "concierge_failed", "error": str(e)}
            )
            raise
    
    def _manage_lru_cache(self, cache: OrderedDict, max_size: int) -> None:
        """ç®¡ç† LRU ç¼“å­˜å¤§å°"""
        while len(cache) > max_size:
            cache.popitem(last=False)  # ç§»é™¤æœ€æ—§çš„é¡¹

    async def _get_or_create_conversation_state(
        self,
        user_id: str,
        session_id: str
    ) -> Dict[str, Any]:
        """è·å–æˆ–åˆ›å»ºä¼šè¯çŠ¶æ€ï¼ˆä½¿ç”¨ LRU ç¼“å­˜ï¼‰"""
        state_key = f"{user_id}:{session_id}"

        if state_key not in self.conversation_states:
            # æ£€æŸ¥ç¼“å­˜å¤§å°
            self._manage_lru_cache(self.conversation_states, self._max_conversation_states)

            # åˆ›å»ºæ–°çš„ä¼šè¯çŠ¶æ€
            self.conversation_states[state_key] = {
                "user_id": user_id,
                "session_id": session_id,
                "created_at": datetime.now().isoformat(),
                "conversation_history": [],
                "user_preferences": {},
                "context_data": {},
                "multimodal_context": []
            }

            self.logger.info(f"ğŸ“ åˆ›å»ºæ–°ä¼šè¯çŠ¶æ€: {state_key}")
        else:
            # ç§»åˆ°æœ«å°¾ï¼ˆæœ€è¿‘ä½¿ç”¨ï¼‰
            self.conversation_states.move_to_end(state_key)

        return self.conversation_states[state_key]
    
    async def _process_multimodal_content(
        self,
        file_ids: List[str],
        user_id: str,
        session_id: str,
        query: str
    ) -> List[Dict[str, Any]]:
        """å¤„ç†å¤šæ¨¡æ€å†…å®¹"""
        if self.multimodal_processor is None:
            self.logger.warning("âš ï¸ å¤šæ¨¡æ€å¤„ç†å™¨æœªåˆå§‹åŒ–")
            return []

        if not self.multimodal_processor.is_enabled():
            self.logger.warning("âš ï¸ å¤šæ¨¡æ€å¤„ç†å™¨æœªå¯ç”¨")
            return []
        
        try:
            results = []
            for file_id in file_ids:
                self.logger.info(f"ğŸ¬ å¤„ç†æ–‡ä»¶: {file_id}")
                
                # è°ƒç”¨å¤šæ¨¡æ€å¤„ç†å™¨
                result = await self.multimodal_processor.process_file(
                    file_id=file_id,
                    user_id=user_id,
                    session_id=session_id,
                    instruction=query
                )
                
                if result:
                    results.append(result)
                    self.logger.info(f"âœ… æ–‡ä»¶å¤„ç†å®Œæˆ: {file_id}")
                else:
                    self.logger.warning(f"âš ï¸ æ–‡ä»¶å¤„ç†å¤±è´¥: {file_id}")
            
            return results
            
        except Exception as e:
            self.logger.error(f"âŒ å¤šæ¨¡æ€å†…å®¹å¤„ç†å¤±è´¥: {e}")
            return []
    
    # ==================== æ–°å¢æ ¸å¿ƒåŠŸèƒ½æ–¹æ³• ====================
    
    async def should_use_multimodal_processing(self, user_id: str, session_id: str, instruction: str) -> bool:
        """æ£€æµ‹æ˜¯å¦éœ€è¦å¤šæ¨¡æ€å¤„ç†"""
        return await self.multimodal_processor.should_use_multimodal_processing(user_id, session_id, instruction)
    
    async def process_multimodal_files(
        self, 
        user_id: str, 
        session_id: str, 
        instruction: str
    ) -> List[Dict[str, Any]]:
        """
        ğŸ¯ Concierge ä¸“ç”¨ï¼šå¤„ç†å¤šæ¨¡æ€æ–‡ä»¶å¹¶ç”Ÿæˆåˆ†æç»“æœ
        
        è¿™æ˜¯æ•´ä¸ª Juben ç³»ç»Ÿä¸­å”¯ä¸€çš„å¤šæ¨¡æ€å¤„ç†å…¥å£ã€‚
        ä¼šåˆ†ææ–‡ä»¶å†…å®¹å¹¶å°†ç»“æœæ–‡æœ¬åŒ–ï¼Œä¾›åç»­ Agent ä½¿ç”¨ã€‚
        
        Returns:
            List[Dict]: æ–‡ä»¶åˆ†æç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å« file_ref, analysis_result, file_type ç­‰
        """
        # ä½¿ç”¨å…¬å…±å¤šæ¨¡æ€å¤„ç†å™¨
        analysis_results = await self.multimodal_processor.process_multimodal_files(
            user_id, session_id, instruction, agent_name="concierge"
        )
        
        # è½¬æ¢ä¸º Concierge æœŸæœ›çš„æ ¼å¼
        formatted_results = []
        for result in analysis_results:
            formatted_results.append({
                "file_ref": result.get("ref_name", ""),
                "file_name": result.get("file_info", {}).get("original_filename", ""),
                "file_type": result.get("file_type", "unknown"),
                "analysis_result": result.get("analysis", "").strip(),
                "file_info": result.get("file_info", {})
            })
        
        return formatted_results
    
    async def save_file_analysis_as_notes(
        self, 
        analysis_results: List[Dict[str, Any]], 
        user_id: str, 
        session_id: str
    ) -> List[str]:
        """
        å°†æ–‡ä»¶åˆ†æç»“æœä¿å­˜ä¸º Notes
        
        Returns:
            List[str]: ä¿å­˜æˆåŠŸçš„ note åç§°åˆ—è¡¨
        """
        if not analysis_results:
            return []
        
        # å¤„ç†ä¸¤ç§æ ¼å¼çš„ç»“æœï¼š
        # 1. process_multimodal_files è¿”å›çš„æ ¼å¼ï¼ˆæœ‰file_ref, analysis_resultå­—æ®µï¼‰
        # 2. _process_file_ids_directly è¿”å›çš„æ ¼å¼ï¼ˆæœ‰ref_name, analysiså­—æ®µï¼‰
        processor_results = []
        for result in analysis_results:
            # ç»Ÿä¸€å­—æ®µå
            ref_name = result.get("file_ref") or result.get("ref_name", "")
            analysis = result.get("analysis_result") or result.get("analysis", "")
            file_info = result.get("file_info", {})
            file_type = result.get("file_type", "unknown")
            
            if ref_name and analysis:
                processor_results.append({
                    "ref_name": ref_name,
                    "analysis": analysis,
                    "file_info": file_info,
                    "file_type": file_type
                })
        
        # ä¿å­˜ä¸ºNotes
        saved_notes = []
        for result in processor_results:
            try:
                note_id = await self.create_note(
                    user_id=user_id,
                    session_id=session_id,
                    title=f"æ–‡ä»¶åˆ†æ: {result['file_info'].get('original_filename', 'unknown')}",
                    content=result['analysis'],
                    note_type="file_analysis",
                    tags=["æ–‡ä»¶åˆ†æ", result['file_type']]
                )
                if note_id:
                    saved_notes.append(note_id)
            except Exception as e:
                self.logger.error(f"âŒ ä¿å­˜æ–‡ä»¶åˆ†æNoteå¤±è´¥: {e}")
        
        return saved_notes
    
    async def _process_file_ids_directly(
        self,
        user_id: str,
        session_id: str,
        file_ids: List[str],
        instruction: str
    ) -> List[Dict[str, Any]]:
        """
        ğŸ¯ ç›´æ¥å¤„ç†æ–‡ä»¶IDåˆ—è¡¨ï¼Œä¸èµ°æ–‡æœ¬å¼•ç”¨æµç¨‹

        ç›´æ¥ä»æ•°æ®åº“è·å–æ–‡ä»¶ä¿¡æ¯ï¼Œè°ƒç”¨å¤šæ¨¡æ€åˆ†æï¼Œè¿”å›ç»“æœ
        """
        if not file_ids:
            return []

        if self.multimodal_processor is None or not self.multimodal_processor.is_enabled():
            self.logger.warning("âš ï¸ å¤šæ¨¡æ€å¤„ç†æœªå¯ç”¨ï¼Œè·³è¿‡æ–‡ä»¶å¤„ç†")
            return []

        # æ–‡ä»¶æ•°é‡é™åˆ¶
        if len(file_ids) > self._max_files_per_request:
            self.logger.warning(f"âš ï¸ æ–‡ä»¶æ•°é‡è¶…è¿‡é™åˆ¶: {len(file_ids)} > {self._max_files_per_request}")
            file_ids = file_ids[:self._max_files_per_request]

        try:
            self.logger.info(f"ğŸ¯ ç›´æ¥å¤„ç†{len(file_ids)}ä¸ªæ–‡ä»¶ID")

            # ä»æ•°æ®åº“è·å–æ–‡ä»¶ä¿¡æ¯
            file_infos = await self._get_file_infos_from_db(file_ids)
            if not file_infos:
                self.logger.warning("âš ï¸ æœªæ‰¾åˆ°æ–‡ä»¶ä¿¡æ¯")
                return []

            # å¤„ç†æ¯ä¸ªæ–‡ä»¶
            results = []
            for file_info in file_infos:
                try:
                    # æ–‡ä»¶å¤§å°æ£€æŸ¥
                    file_size = file_info.get('size', 0)
                    if file_size > self._max_file_size:
                        self.logger.warning(f"âš ï¸ æ–‡ä»¶è¿‡å¤§: {file_info.get('filename', 'unknown')} ({file_size} bytes)")
                        continue

                    result = await self._process_single_file_directly(
                        file_info, user_id, session_id, instruction
                    )
                    if result:
                        results.append(result)
                except Exception as e:
                    self.logger.error(f"âŒ å¤„ç†æ–‡ä»¶å¤±è´¥: {file_info.get('filename', 'unknown')}, {e}")
                    continue

            self.logger.info(f"âœ… ç›´æ¥æ–‡ä»¶å¤„ç†å®Œæˆ: {len(results)}ä¸ªæ–‡ä»¶")
            return results

        except Exception as e:
            self.logger.error(f"âŒ ç›´æ¥æ–‡ä»¶å¤„ç†å¤±è´¥: {e}")
            return []
    
    async def _get_file_infos_from_db(self, file_ids: List[str]) -> List[Dict[str, Any]]:
        """ä»æ•°æ®åº“è·å–æ–‡ä»¶ä¿¡æ¯"""
        try:
            # è¿™é‡Œåº”è¯¥ä»æ•°æ®åº“è·å–æ–‡ä»¶ä¿¡æ¯
            # æš‚æ—¶è¿”å›æ¨¡æ‹Ÿæ•°æ®
            file_infos = []
            for file_id in file_ids:
                file_infos.append({
                    "file_id": file_id,
                    "filename": f"file_{file_id}.txt",
                    "file_path": f"/tmp/file_{file_id}",
                    "file_type": "document"
                })
            return file_infos
        except Exception as e:
            self.logger.error(f"âŒ è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥: {e}")
            return []
    
    async def _process_single_file_directly(
        self,
        file_info: Dict[str, Any],
        user_id: str,
        session_id: str,
        instruction: str
    ) -> Optional[Dict[str, Any]]:
        """å¤„ç†å•ä¸ªæ–‡ä»¶"""
        try:
            file_id = file_info.get("file_id")
            filename = file_info.get("filename", "unknown")
            
            # è°ƒç”¨å¤šæ¨¡æ€å¤„ç†å™¨åˆ†ææ–‡ä»¶
            result = await self.multimodal_processor.process_file(
                file_id=file_id,
                user_id=user_id,
                session_id=session_id,
                instruction=instruction
            )
            
            if result:
                # æ·»åŠ æ–‡ä»¶ä¿¡æ¯
                result["file_info"] = file_info
                result["file_id"] = file_id
                result["filename"] = filename
                
                self.logger.info(f"âœ… æ–‡ä»¶å¤„ç†å®Œæˆ: {filename}")
                return result
            else:
                self.logger.warning(f"âš ï¸ æ–‡ä»¶å¤„ç†å¤±è´¥: {filename}")
                return None
                
        except Exception as e:
            self.logger.error(f"âŒ å¤„ç†å•ä¸ªæ–‡ä»¶å¤±è´¥: {e}")
            return None
    
    async def extract_notes_from_conversation(
        self,
        user_id: str,
        session_id: str,
        conversation_history: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """ä»å¯¹è¯å†å²ä¸­æå–Notes"""
        try:
            if not conversation_history:
                return []
            
            # æ„å»ºæå–æç¤ºè¯
            extraction_prompt = f"""
            è¯·ä»ä»¥ä¸‹å¯¹è¯å†å²ä¸­æå–æœ‰ä»·å€¼çš„ä¿¡æ¯ï¼Œåˆ›å»ºç»“æ„åŒ–çš„Notesï¼š
            
            å¯¹è¯å†å²:
            {json.dumps(conversation_history[-10:], ensure_ascii=False, indent=2)}
            
            è¯·æå–ä»¥ä¸‹ç±»å‹çš„ä¿¡æ¯ï¼š
            1. ç”¨æˆ·åå¥½å’Œéœ€æ±‚
            2. é‡è¦çš„å†³ç­–å’Œé€‰æ‹©
            3. å…³é”®çš„ä¸šåŠ¡ä¿¡æ¯
            4. æŠ€æœ¯è¦æ±‚å’Œé™åˆ¶
            5. æ—¶é—´çº¿å’Œé‡Œç¨‹ç¢‘
            
            è¯·ä»¥JSONæ ¼å¼è¿”å›æå–çš„Notesåˆ—è¡¨ã€‚
            """
            
            messages = [
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": extraction_prompt}
            ]
            
            # è°ƒç”¨LLMæå–
            response = await self._call_llm(messages, user_id=user_id, session_id=session_id)
            
            # è§£æå“åº”
            try:
                extracted_notes = json.loads(response)
                if isinstance(extracted_notes, list):
                    # ä¿å­˜æå–çš„Notes
                    saved_notes = []
                    for note_data in extracted_notes:
                        note_id = await self.create_note(
                            user_id=user_id,
                            session_id=session_id,
                            title=note_data.get("title", "æå–çš„Note"),
                            content=note_data.get("content", ""),
                            note_type=note_data.get("type", "extracted"),
                            tags=note_data.get("tags", [])
                        )
                        if note_id:
                            saved_notes.append(note_id)
                    
                    self.logger.info(f"âœ… ä»å¯¹è¯ä¸­æå–äº†{len(saved_notes)}ä¸ªNotes")
                    return saved_notes
            except json.JSONDecodeError:
                self.logger.warning("âš ï¸ æ— æ³•è§£ææå–çš„Notes")
            
            return []
            
        except Exception as e:
            self.logger.error(f"âŒ ä»å¯¹è¯æå–Noteså¤±è´¥: {e}")
            return []
    
    async def analyze_user_preferences(
        self,
        user_id: str,
        session_id: str,
        conversation_history: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """åˆ†æç”¨æˆ·åå¥½"""
        try:
            if not conversation_history:
                return {}
            
            # æ„å»ºåˆ†ææç¤ºè¯
            analysis_prompt = f"""
            è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·å¯¹è¯å†å²ï¼Œè¯†åˆ«ç”¨æˆ·çš„åå¥½å’Œç‰¹ç‚¹ï¼š
            
            å¯¹è¯å†å²:
            {json.dumps(conversation_history[-20:], ensure_ascii=False, indent=2)}
            
            è¯·åˆ†æå¹¶è¿”å›ä»¥ä¸‹ä¿¡æ¯ï¼š
            1. ç”¨æˆ·çš„å·¥ä½œé£æ ¼åå¥½
            2. æ²Ÿé€šæ–¹å¼åå¥½
            3. æŠ€æœ¯åå¥½
            4. æ—¶é—´åå¥½
            5. è´¨é‡è¦æ±‚åå¥½
            
            è¯·ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœã€‚
            """
            
            messages = [
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": analysis_prompt}
            ]
            
            # è°ƒç”¨LLMåˆ†æ
            response = await self._call_llm(messages, user_id=user_id, session_id=session_id)
            
            # è§£æå“åº”
            try:
                preferences = json.loads(response)
                if isinstance(preferences, dict):
                    # ä¿å­˜ç”¨æˆ·åå¥½
                    await self._save_user_preferences(user_id, session_id, preferences)
                    self.logger.info(f"âœ… ç”¨æˆ·åå¥½åˆ†æå®Œæˆ")
                    return preferences
            except json.JSONDecodeError:
                self.logger.warning("âš ï¸ æ— æ³•è§£æç”¨æˆ·åå¥½")
            
            return {}
            
        except Exception as e:
            self.logger.error(f"âŒ åˆ†æç”¨æˆ·åå¥½å¤±è´¥: {e}")
            return {}
    
    async def _save_user_preferences(
        self,
        user_id: str,
        session_id: str,
        preferences: Dict[str, Any]
    ):
        """ä¿å­˜ç”¨æˆ·åå¥½"""
        try:
            # æ›´æ–°å†…å­˜ä¸­çš„ç”¨æˆ·åå¥½
            state_key = f"{user_id}:{session_id}"
            if state_key in self.conversation_states:
                self.conversation_states[state_key]["user_preferences"] = preferences
            
            # ä¿å­˜åˆ°æŒä¹…åŒ–å­˜å‚¨
            await self.storage.save_user_preferences(user_id, session_id, preferences)
            
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜ç”¨æˆ·åå¥½å¤±è´¥: {e}")
    
    async def get_user_preferences(
        self,
        user_id: str,
        session_id: str
    ) -> Dict[str, Any]:
        """è·å–ç”¨æˆ·åå¥½"""
        try:
            # å…ˆä»å†…å­˜è·å–
            state_key = f"{user_id}:{session_id}"
            if state_key in self.conversation_states:
                return self.conversation_states[state_key].get("user_preferences", {})
            
            # ä»æŒä¹…åŒ–å­˜å‚¨è·å–
            preferences = await self.storage.get_user_preferences(user_id, session_id)
            return preferences or {}
            
        except Exception as e:
            self.logger.error(f"âŒ è·å–ç”¨æˆ·åå¥½å¤±è´¥: {e}")
            return {}
    
    async def optimize_conversation_context(
        self,
        user_id: str,
        session_id: str,
        current_query: str
    ) -> str:
        """ä¼˜åŒ–å¯¹è¯ä¸Šä¸‹æ–‡"""
        try:
            # è·å–å¯¹è¯å†å²
            conversation_history = await self.get_conversation_history(user_id, session_id, limit=10)
            
            # è·å–ç”¨æˆ·åå¥½
            user_preferences = await self.get_user_preferences(user_id, session_id)
            
            # è·å–ç›¸å…³Notes
            relevant_notes = await self.get_notes(
                user_id=user_id,
                session_id=session_id,
                limit=5
            )
            
            # æ„å»ºä¼˜åŒ–åçš„ä¸Šä¸‹æ–‡
            optimized_context = f"""
## å½“å‰æŸ¥è¯¢
{current_query}

## å¯¹è¯å†å²æ‘˜è¦
{json.dumps(conversation_history[-5:], ensure_ascii=False, indent=2)}

## ç”¨æˆ·åå¥½
{json.dumps(user_preferences, ensure_ascii=False, indent=2)}

## ç›¸å…³Notes
{json.dumps([note.get('title', '') for note in relevant_notes], ensure_ascii=False)}

## ä¸Šä¸‹æ–‡ä¼˜åŒ–å»ºè®®
åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œè¯·ä¸ºç”¨æˆ·æä¾›ä¸ªæ€§åŒ–çš„å“åº”ã€‚
"""
            
            return optimized_context
            
        except Exception as e:
            self.logger.error(f"âŒ ä¼˜åŒ–å¯¹è¯ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            return f"## å½“å‰æŸ¥è¯¢\n{current_query}"
    
    async def handle_user_feedback(
        self,
        user_id: str,
        session_id: str,
        feedback: Dict[str, Any]
    ) -> Dict[str, Any]:
        """å¤„ç†ç”¨æˆ·åé¦ˆ"""
        try:
            feedback_type = feedback.get("type", "general")
            feedback_content = feedback.get("content", "")
            feedback_rating = feedback.get("rating", 0)
            
            # è®°å½•åé¦ˆ
            feedback_record = {
                "user_id": user_id,
                "session_id": session_id,
                "feedback_type": feedback_type,
                "feedback_content": feedback_content,
                "feedback_rating": feedback_rating,
                "timestamp": datetime.now().isoformat()
            }
            
            # ä¿å­˜åé¦ˆ
            await self.storage.save_feedback(feedback_record)
            
            # æ ¹æ®åé¦ˆè°ƒæ•´ç­–ç•¥
            if feedback_rating < 3:
                # è´Ÿé¢åé¦ˆï¼Œéœ€è¦æ”¹è¿›
                await self._handle_negative_feedback(user_id, session_id, feedback)
            elif feedback_rating >= 4:
                # æ­£é¢åé¦ˆï¼Œå¯ä»¥å¼ºåŒ–ç›¸å…³è¡Œä¸º
                await self._handle_positive_feedback(user_id, session_id, feedback)
            
            self.logger.info(f"âœ… ç”¨æˆ·åé¦ˆå¤„ç†å®Œæˆ: ç±»å‹={feedback_type}, è¯„åˆ†={feedback_rating}")
            
            return {
                "status": "success",
                "message": "åé¦ˆå·²è®°å½•å¹¶å¤„ç†",
                "feedback_id": feedback_record.get("id")
            }
            
        except Exception as e:
            self.logger.error(f"âŒ å¤„ç†ç”¨æˆ·åé¦ˆå¤±è´¥: {e}")
            return {
                "status": "error",
                "message": f"å¤„ç†åé¦ˆå¤±è´¥: {str(e)}"
            }
    
    async def _handle_negative_feedback(
        self,
        user_id: str,
        session_id: str,
        feedback: Dict[str, Any]
    ):
        """å¤„ç†è´Ÿé¢åé¦ˆ"""
        try:
            # åˆ†æè´Ÿé¢åé¦ˆåŸå› 
            feedback_content = feedback.get("content", "")
            
            # åˆ›å»ºæ”¹è¿›å»ºè®®Note
            improvement_note = await self.create_note(
                user_id=user_id,
                session_id=session_id,
                title="ç”¨æˆ·åé¦ˆæ”¹è¿›å»ºè®®",
                content=f"è´Ÿé¢åé¦ˆ: {feedback_content}\n\næ”¹è¿›å»ºè®®:\n1. åˆ†æç”¨æˆ·ä¸æ»¡æ„çš„å…·ä½“åŸå› \n2. è°ƒæ•´å“åº”ç­–ç•¥\n3. ä¼˜åŒ–ç”¨æˆ·ä½“éªŒ",
                note_type="improvement",
                tags=["åé¦ˆ", "æ”¹è¿›"]
            )
            
            # æ›´æ–°ç”¨æˆ·åå¥½ï¼Œé¿å…ç±»ä¼¼é—®é¢˜
            current_preferences = await self.get_user_preferences(user_id, session_id)
            current_preferences["avoid_patterns"] = current_preferences.get("avoid_patterns", [])
            current_preferences["avoid_patterns"].append(feedback_content)
            
            await self._save_user_preferences(user_id, session_id, current_preferences)
            
        except Exception as e:
            self.logger.error(f"âŒ å¤„ç†è´Ÿé¢åé¦ˆå¤±è´¥: {e}")
    
    async def _handle_positive_feedback(
        self,
        user_id: str,
        session_id: str,
        feedback: Dict[str, Any]
    ):
        """å¤„ç†æ­£é¢åé¦ˆ"""
        try:
            # è®°å½•æˆåŠŸæ¨¡å¼
            feedback_content = feedback.get("content", "")
            
            # åˆ›å»ºæˆåŠŸæ¨¡å¼Note
            success_note = await self.create_note(
                user_id=user_id,
                session_id=session_id,
                title="æˆåŠŸæ¨¡å¼è®°å½•",
                content=f"æ­£é¢åé¦ˆ: {feedback_content}\n\næˆåŠŸè¦ç´ :\n1. ç”¨æˆ·æ»¡æ„çš„æ–¹æ³•\n2. æœ‰æ•ˆçš„æ²Ÿé€šæ–¹å¼\n3. é«˜è´¨é‡çš„è¾“å‡º",
                note_type="success_pattern",
                tags=["åé¦ˆ", "æˆåŠŸ"]
            )
            
            # æ›´æ–°ç”¨æˆ·åå¥½ï¼Œå¼ºåŒ–æˆåŠŸæ¨¡å¼
            current_preferences = await self.get_user_preferences(user_id, session_id)
            current_preferences["success_patterns"] = current_preferences.get("success_patterns", [])
            current_preferences["success_patterns"].append(feedback_content)
            
            await self._save_user_preferences(user_id, session_id, current_preferences)
            
        except Exception as e:
            self.logger.error(f"âŒ å¤„ç†æ­£é¢åé¦ˆå¤±è´¥: {e}")
    
    async def generate_conversation_summary(
        self,
        user_id: str,
        session_id: str
    ) -> str:
        """ç”Ÿæˆå¯¹è¯æ‘˜è¦"""
        try:
            # è·å–å¯¹è¯å†å²
            conversation_history = await self.get_conversation_history(user_id, session_id, limit=20)
            
            if not conversation_history:
                return "æš‚æ— å¯¹è¯å†å²"
            
            # æ„å»ºæ‘˜è¦æç¤ºè¯
            summary_prompt = f"""
            è¯·ä¸ºä»¥ä¸‹å¯¹è¯å†å²ç”Ÿæˆä¸€ä¸ªç®€æ´çš„æ‘˜è¦ï¼š
            
            å¯¹è¯å†å²:
            {json.dumps(conversation_history, ensure_ascii=False, indent=2)}
            
            è¯·åŒ…å«ä»¥ä¸‹å†…å®¹ï¼š
            1. ä¸»è¦è®¨è®ºè¯é¢˜
            2. å…³é”®å†³ç­–å’Œç»“è®º
            3. ç”¨æˆ·éœ€æ±‚å’Œåå¥½
            4. å¾…åŠäº‹é¡¹å’Œåç»­è¡ŒåŠ¨
            
            è¯·ç”¨ç®€æ´çš„è¯­è¨€æ€»ç»“ï¼Œä¸è¶…è¿‡200å­—ã€‚
            """
            
            messages = [
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": summary_prompt}
            ]
            
            # è°ƒç”¨LLMç”Ÿæˆæ‘˜è¦
            summary = await self._call_llm(messages, user_id=user_id, session_id=session_id)
            
            # ä¿å­˜æ‘˜è¦ä¸ºNote
            await self.create_note(
                user_id=user_id,
                session_id=session_id,
                title=f"å¯¹è¯æ‘˜è¦ - {datetime.now().strftime('%Y-%m-%d %H:%M')}",
                content=summary,
                note_type="summary",
                tags=["æ‘˜è¦", "å¯¹è¯"]
            )
            
            self.logger.info(f"âœ… å¯¹è¯æ‘˜è¦ç”Ÿæˆå®Œæˆ")
            return summary
            
        except Exception as e:
            self.logger.error(f"âŒ ç”Ÿæˆå¯¹è¯æ‘˜è¦å¤±è´¥: {e}")
            return "æ‘˜è¦ç”Ÿæˆå¤±è´¥"
    
    async def get_conversation_insights(
        self,
        user_id: str,
        session_id: str
    ) -> Dict[str, Any]:
        """è·å–å¯¹è¯æ´å¯Ÿ"""
        try:
            # è·å–å¯¹è¯å†å²
            conversation_history = await self.get_conversation_history(user_id, session_id, limit=50)
            
            # è·å–ç”¨æˆ·åå¥½
            user_preferences = await self.get_user_preferences(user_id, session_id)
            
            # è·å–ç›¸å…³Notes
            notes = await self.get_notes(user_id=user_id, session_id=session_id, limit=10)
            
            # åˆ†æå¯¹è¯æ¨¡å¼
            insights = {
                "total_conversations": len(conversation_history),
                "user_preferences": user_preferences,
                "notes_count": len(notes),
                "conversation_topics": self._extract_conversation_topics(conversation_history),
                "user_satisfaction": self._analyze_user_satisfaction(conversation_history),
                "recommendations": self._generate_recommendations(user_preferences, conversation_history)
            }
            
            return insights
            
        except Exception as e:
            self.logger.error(f"âŒ è·å–å¯¹è¯æ´å¯Ÿå¤±è´¥: {e}")
            return {"error": str(e)}
    
    def _extract_conversation_topics(self, conversation_history: List[Dict[str, Any]]) -> List[str]:
        """æå–å¯¹è¯è¯é¢˜"""
        topics = set()
        for conversation in conversation_history:
            query = conversation.get("user_query", "")
            intent = conversation.get("intent_analysis", {})
            task_type = intent.get("task_type", "")
            if task_type:
                topics.add(task_type)
        return list(topics)
    
    def _analyze_user_satisfaction(self, conversation_history: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ†æç”¨æˆ·æ»¡æ„åº¦"""
        # ç®€å•çš„æ»¡æ„åº¦åˆ†æé€»è¾‘
        total_conversations = len(conversation_history)
        if total_conversations == 0:
            return {"score": 0, "level": "unknown"}
        
        # åŸºäºå¯¹è¯é•¿åº¦å’Œå†…å®¹åˆ†ææ»¡æ„åº¦
        avg_query_length = sum(len(conv.get("user_query", "")) for conv in conversation_history) / total_conversations
        
        if avg_query_length > 50:
            satisfaction_score = 0.8
            level = "high"
        elif avg_query_length > 20:
            satisfaction_score = 0.6
            level = "medium"
        else:
            satisfaction_score = 0.4
            level = "low"
        
        return {
            "score": satisfaction_score,
            "level": level,
            "avg_query_length": avg_query_length
        }
    
    def _generate_recommendations(
        self,
        user_preferences: Dict[str, Any],
        conversation_history: List[Dict[str, Any]]
    ) -> List[str]:
        """ç”Ÿæˆæ¨èå»ºè®®"""
        recommendations = []
        
        # åŸºäºç”¨æˆ·åå¥½ç”Ÿæˆæ¨è
        if user_preferences.get("work_style") == "detailed":
            recommendations.append("æä¾›æ›´è¯¦ç»†çš„åˆ†ææŠ¥å‘Š")
        
        if user_preferences.get("communication_style") == "formal":
            recommendations.append("ä½¿ç”¨æ›´æ­£å¼çš„è¯­è¨€é£æ ¼")
        
        # åŸºäºå¯¹è¯å†å²ç”Ÿæˆæ¨è
        if len(conversation_history) > 10:
            recommendations.append("è€ƒè™‘åˆ›å»ºå·¥ä½œæµæ¨¡æ¿ä»¥æé«˜æ•ˆç‡")
        
        return recommendations
    
    async def _analyze_user_intent(
        self, 
        query: str, 
        conversation_state: Dict[str, Any],
        multimodal_results: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        åˆ†æç”¨æˆ·æ„å›¾
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            conversation_state: ä¼šè¯çŠ¶æ€
            multimodal_results: å¤šæ¨¡æ€å¤„ç†ç»“æœ
            
        Returns:
            Dict: æ„å›¾åˆ†æç»“æœ
        """
        try:
            # æ„å»ºåˆ†ææç¤ºè¯
            analysis_prompt = f"""
            è¯·åˆ†æä»¥ä¸‹ç«–å±çŸ­å‰§ç­–åˆ’ç›¸å…³çš„ç”¨æˆ·è¯·æ±‚ï¼Œåˆ¤æ–­ç”¨æˆ·çš„å…·ä½“éœ€æ±‚å’Œæ„å›¾ï¼š

            ç”¨æˆ·æŸ¥è¯¢: {query}
            
            ä¼šè¯å†å²: {json.dumps(conversation_state.get('conversation_history', [])[-3:], ensure_ascii=False)}
            
            å¤šæ¨¡æ€å†…å®¹: {len(multimodal_results)} ä¸ªæ–‡ä»¶å·²å¤„ç†
            
            è¯·åˆ†æå¹¶è¿”å›JSONæ ¼å¼çš„ç»“æœï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
            1. intent_type: æ„å›¾ç±»å‹ (simple_query, complex_task, file_analysis, conversation_continue)
            2. task_type: ä»»åŠ¡ç±»å‹ (story_analysis, story_creation, character_development, plot_development, drama_evaluation, series_analysis)
            3. requires_orchestrator: æ˜¯å¦éœ€è¦ç¼–æ’å™¨å¤„ç† (true/false)
            4. confidence: åˆ†æç½®ä¿¡åº¦ (0-1)
            5. key_requirements: å…³é”®éœ€æ±‚åˆ—è¡¨
            6. suggested_workflow: å»ºè®®çš„å·¥ä½œæµç±»å‹
            """
            
            messages = [
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": analysis_prompt}
            ]
            
            # è°ƒç”¨LLMåˆ†æ
            response = await self._call_llm(messages, user_id="system", session_id="intent_analysis")
            
            # è§£æå“åº”
            try:
                intent_analysis = json.loads(response)
            except json.JSONDecodeError:
                # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤åˆ†æ
                intent_analysis = self._fallback_intent_analysis(query)
            
            # éªŒè¯å’Œè¡¥å……åˆ†æç»“æœ
            intent_analysis = self._validate_intent_analysis(intent_analysis, query)
            
            self.logger.info(f"ğŸ¯ æ„å›¾åˆ†æå®Œæˆ: {intent_analysis['intent_type']} -> {intent_analysis['task_type']}")
            
            return intent_analysis
            
        except Exception as e:
            self.logger.error(f"âŒ æ„å›¾åˆ†æå¤±è´¥: {e}")
            return self._fallback_intent_analysis(query)
    
    def _fallback_intent_analysis(self, query: str) -> Dict[str, Any]:
        """å›é€€æ„å›¾åˆ†æ"""
        query_lower = query.lower()
        
        # åŸºäºå…³é”®è¯çš„ç®€å•åˆ†æ
        for task_type, keywords in self.task_routing_rules.items():
            if any(keyword in query_lower for keyword in keywords):
                return {
                    "intent_type": "complex_task",
                    "task_type": task_type,
                    "requires_orchestrator": True,
                    "confidence": 0.7,
                    "key_requirements": [query],
                    "suggested_workflow": task_type
                }
        
        # é»˜è®¤åˆ†æ
        return {
            "intent_type": "simple_query",
            "task_type": "story_analysis",
            "requires_orchestrator": False,
            "confidence": 0.5,
            "key_requirements": [query],
            "suggested_workflow": "story_analysis"
        }
    
    def _validate_intent_analysis(self, analysis: Dict[str, Any], query: str) -> Dict[str, Any]:
        """éªŒè¯å’Œè¡¥å……æ„å›¾åˆ†æç»“æœ"""
        # ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨
        required_fields = ["intent_type", "task_type", "requires_orchestrator", "confidence"]
        for field in required_fields:
            if field not in analysis:
                if field == "intent_type":
                    analysis[field] = "simple_query"
                elif field == "task_type":
                    analysis[field] = "story_analysis"
                elif field == "requires_orchestrator":
                    analysis[field] = False
                elif field == "confidence":
                    analysis[field] = 0.5
        
        # éªŒè¯ä»»åŠ¡ç±»å‹
        if analysis["task_type"] not in self.task_routing_rules:
            analysis["task_type"] = "story_analysis"
        
        # è¡¥å……ç¼ºå¤±å­—æ®µ
        if "key_requirements" not in analysis:
            analysis["key_requirements"] = [query]
        
        if "suggested_workflow" not in analysis:
            analysis["suggested_workflow"] = analysis["task_type"]
        
        return analysis
    
    async def _handle_simple_request(
        self, 
        query: str, 
        intent_analysis: Dict[str, Any],
        conversation_state: Dict[str, Any],
        multimodal_results: List[Dict[str, Any]]
    ) -> str:
        """å¤„ç†ç®€å•è¯·æ±‚"""
        try:
            # æ„å»ºç®€å•å“åº”æç¤ºè¯
            response_prompt = f"""
            è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯ï¼Œä¸ºç”¨æˆ·æä¾›ä¸“ä¸šçš„ç«–å±çŸ­å‰§ç­–åˆ’å»ºè®®ï¼š

            ç”¨æˆ·æŸ¥è¯¢: {query}
            æ„å›¾ç±»å‹: {intent_analysis['intent_type']}
            ä»»åŠ¡ç±»å‹: {intent_analysis['task_type']}
            
            å¤šæ¨¡æ€å†…å®¹: {len(multimodal_results)} ä¸ªæ–‡ä»¶å·²åˆ†æ
            
            è¯·æä¾›ï¼š
            1. é’ˆå¯¹æ€§çš„ä¸“ä¸šå»ºè®®
            2. å…·ä½“çš„å®æ–½æ­¥éª¤
            3. æ³¨æ„äº‹é¡¹å’Œæœ€ä½³å®è·µ
            4. å¦‚éœ€è¿›ä¸€æ­¥åˆ†æï¼Œè¯·è¯´æ˜éœ€è¦ä»€ä¹ˆä¿¡æ¯
            
            è¯·ä»¥å‹å¥½ã€ä¸“ä¸šçš„è¯­è°ƒå›ç­”ã€‚
            """
            
            messages = [
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": response_prompt}
            ]
            
            # è°ƒç”¨LLMç”Ÿæˆå“åº”
            response = await self._call_llm(messages, user_id="system", session_id="simple_response")
            
            return response
            
        except Exception as e:
            self.logger.error(f"âŒ ç®€å•è¯·æ±‚å¤„ç†å¤±è´¥: {e}")
            return f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°é—®é¢˜ï¼š{str(e)}ã€‚è¯·ç¨åé‡è¯•æˆ–æä¾›æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚"
    
    async def _update_conversation_state(
        self, 
        user_id: str, 
        session_id: str, 
        query: str, 
        intent_analysis: Dict[str, Any],
        multimodal_results: List[Dict[str, Any]]
    ):
        """æ›´æ–°å¯¹è¯çŠ¶æ€"""
        state_key = f"{user_id}:{session_id}"
        
        if state_key in self.conversation_states:
            state = self.conversation_states[state_key]
            
            # æ·»åŠ å¯¹è¯å†å²
            state["conversation_history"].append({
                "timestamp": datetime.now().isoformat(),
                "user_query": query,
                "intent_analysis": intent_analysis,
                "multimodal_count": len(multimodal_results)
            })
            
            # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…
            if len(state["conversation_history"]) > 20:
                state["conversation_history"] = state["conversation_history"][-20:]
            
            # æ›´æ–°å¤šæ¨¡æ€ä¸Šä¸‹æ–‡
            if multimodal_results:
                state["multimodal_context"].extend(multimodal_results)
            
            self.logger.info(f"ğŸ“ æ›´æ–°å¯¹è¯çŠ¶æ€: {state_key}, å†å²è®°å½•: {len(state['conversation_history'])}")
    
    async def _save_conversation_record(
        self, 
        user_id: str, 
        session_id: str, 
        query: str, 
        intent_analysis: Dict[str, Any],
        multimodal_results: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """ä¿å­˜å¯¹è¯è®°å½•åˆ°æ–‡ä»¶ç³»ç»Ÿ"""
        try:
            # æ„å»ºå¯¹è¯è®°å½•
            conversation_record = {
                "user_id": user_id,
                "session_id": session_id,
                "query": query,
                "intent_analysis": intent_analysis,
                "multimodal_results": multimodal_results,
                "timestamp": datetime.now().isoformat(),
                "agent_name": self.agent_name
            }
            
            # ä¿å­˜åˆ°æ–‡ä»¶ç³»ç»Ÿ
            save_result = await self.auto_save_output(
                output_content=conversation_record,
                user_id=user_id,
                session_id=session_id,
                file_type="json",
                metadata={
                    "conversation_type": "user_interaction",
                    "intent_type": intent_analysis.get("intent_type", "unknown"),
                    "task_type": intent_analysis.get("task_type", "unknown"),
                    "multimodal_count": len(multimodal_results),
                    "concierge_version": "1.0"
                }
            )
            
            if save_result.get("success"):
                self.logger.info(f"ğŸ’¾ å¯¹è¯è®°å½•ä¿å­˜æˆåŠŸ: {user_id}:{session_id}")
            else:
                self.logger.error(f"âŒ å¯¹è¯è®°å½•ä¿å­˜å¤±è´¥: {save_result.get('error')}")
            
            return save_result
            
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜å¯¹è¯è®°å½•å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}
    
    async def get_conversation_history(
        self, 
        user_id: str, 
        session_id: str, 
        limit: int = 10
    ) -> List[Dict[str, Any]]:
        """è·å–å¯¹è¯å†å²"""
        state_key = f"{user_id}:{session_id}"
        
        if state_key in self.conversation_states:
            history = self.conversation_states[state_key]["conversation_history"]
            return history[-limit:] if limit > 0 else history
        
        return []
    
    async def clear_conversation_state(self, user_id: str, session_id: str) -> bool:
        """æ¸…é™¤å¯¹è¯çŠ¶æ€"""
        state_key = f"{user_id}:{session_id}"
        
        if state_key in self.conversation_states:
            del self.conversation_states[state_key]
            self.logger.info(f"ğŸ—‘ï¸ æ¸…é™¤å¯¹è¯çŠ¶æ€: {state_key}")
            return True
        
        return False
    
    def get_agent_info(self) -> Dict[str, Any]:
        """è·å–Agentä¿¡æ¯"""
        base_info = super().get_agent_info()
        base_info.update({
            "concierge_type": "juben_planning",
            "supported_task_types": list(self.task_routing_rules.keys()),
            "multimodal_enabled": self.multimodal_processor.is_enabled(),
            "active_conversations": len(self.conversation_states)
        })
        return base_info
