"""
Meta ä¼˜åŒ–å™¨ Agent
ä¸“é—¨è´Ÿè´£ä¼˜åŒ–å…¶ä»– Agent çš„ System Prompt

åŠŸèƒ½ï¼š
1. åˆ†æå·®è¯„æ¡ˆä¾‹ï¼Œæ‰¾å‡ºé—®é¢˜æ ¹æº
2. å­¦ä¹ ç”¨æˆ·ä¿®æ”¹åçš„æ­£ç¡®èŒƒæ–‡
3. ç”Ÿæˆä¼˜åŒ–åçš„ Prompt ç‰ˆæœ¬
4. æä¾›ä¼˜åŒ–å»ºè®®å’Œå˜æ›´æ—¥å¿—

ä»£ç ä½œè€…ï¼šClaude
åˆ›å»ºæ—¶é—´ï¼š2026å¹´2æœˆ7æ—¥
"""

import os
import asyncio
import logging
from typing import Dict, Any, List, Optional, AsyncGenerator
from datetime import datetime
from dataclasses import dataclass

try:
    from .base_juben_agent import BaseJubenAgent
except ImportError:
    import sys
    from pathlib import Path
    sys.path.insert(0, str(Path(__file__).parent.parent))
    from agents.base_juben_agent import BaseJubenAgent


@dataclass
class PromptOptimizationResult:
    """Prompt ä¼˜åŒ–ç»“æœ"""
    original_prompt: str
    optimized_prompt: str
    agent_name: str
    version: str

    # åˆ†æç»“æœ
    problems_identified: List[str]
    improvement_suggestions: List[str]
    optimization_reasoning: str

    # ç¤ºä¾‹
    negative_examples_used: int
    positive_examples_used: int

    # å…ƒæ•°æ®
    timestamp: str
    confidence: float


class MetaOptimizerAgent(BaseJubenAgent):
    """
    Meta ä¼˜åŒ–å™¨ Agent

    System Prompt: "ä½ æ˜¯ä¸€ä¸ª Prompt å·¥ç¨‹å¸ˆä¸“å®¶ï¼Œä¸“é—¨ä¼˜åŒ– AI Agent çš„ System Promptã€‚"

    åŠŸèƒ½ï¼š
    1. åˆ†æ Agent çš„å·®è¯„æ¡ˆä¾‹ï¼Œæ‰¾å‡º Prompt çš„é—®é¢˜
    2. å­¦ä¹ ç”¨æˆ·ä¿®æ”¹åçš„æ­£ç¡®è¾“å‡º
    3. ç”Ÿæˆä¼˜åŒ–åçš„ Prompt ç‰ˆæœ¬
    4. ä¿æŒ Prompt çš„æ ¸å¿ƒé€»è¾‘ï¼Œåªæ”¹è¿›è¡¨è¾¾æ–¹å¼
    """

    def __init__(self):
        super().__init__(
            agent_name="meta_optimizer",
            model_provider="zhipu"
        )

        # è¦†ç›–ç³»ç»Ÿæç¤ºè¯
        self.system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ Prompt å·¥ç¨‹å¸ˆä¸“å®¶ï¼Œä¸“é—¨ä¼˜åŒ– AI Agent çš„ System Promptã€‚

## ä½ çš„ä¸“é•¿

1. **Prompt åˆ†æ**ï¼šæ·±å…¥ç†è§£ç°æœ‰ Prompt çš„æ„å›¾ã€ç»“æ„å’Œé—®é¢˜
2. **é—®é¢˜è¯Šæ–­**ï¼šä»ç”¨æˆ·åé¦ˆä¸­è¯†åˆ« Prompt çš„ä¸è¶³ä¹‹å¤„
3. **ä¼˜åŒ–ç­–ç•¥**ï¼šåº”ç”¨æœ€ä½³å®è·µæ”¹è¿› Prompt çš„æ•ˆæœ
4. **ç‰ˆæœ¬ç®¡ç†**ï¼šä¿æŒä¼˜åŒ–è¿‡ç¨‹çš„å¯è¿½æº¯æ€§

## ä¼˜åŒ–åŸåˆ™

1. **ä¿æŒæ ¸å¿ƒé€»è¾‘**ï¼šä¸è¦æ”¹å˜ Prompt çš„ä¸»è¦åŠŸèƒ½å’Œç›®æ ‡
2. **æ˜ç¡®æŒ‡ä»¤**ï¼šä½¿ç”¨æ¸…æ™°ã€å…·ä½“ã€æ— æ­§ä¹‰çš„è¯­è¨€
3. **ç»“æ„åŒ–**ï¼šåˆç†ä½¿ç”¨åˆ†æ®µã€æ ‡é¢˜å’Œåˆ—è¡¨
4. **ç¤ºä¾‹é©±åŠ¨**ï¼šæ·»åŠ æ°å½“çš„ç¤ºä¾‹æ¥å¼•å¯¼è¾“å‡º
5. **çº¦æŸæ˜ç¡®**ï¼šæ¸…æ¥šåœ°è¯´æ˜è¾“å‡ºæ ¼å¼å’Œè¦æ±‚

## å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

| é—®é¢˜ | è§£å†³æ–¹æ¡ˆ |
|------|----------|
| è¾“å‡ºè¿‡äºç”Ÿç¡¬ | æ·»åŠ è¯­æ°”è¦æ±‚ï¼Œä½¿ç”¨æ›´è‡ªç„¶çš„è¡¨è¾¾æ–¹å¼ |
| é€»è¾‘ä¸é€š | å¼ºåŒ–é€»è¾‘æµç¨‹è¦æ±‚ï¼Œæ·»åŠ æ£€æŸ¥ç‚¹ |
| æ ¼å¼æ··ä¹± | æ˜ç¡®è¾“å‡ºæ ¼å¼æ¨¡æ¿ |
| ç»†èŠ‚ä¸è¶³ | å¼ºè°ƒç»†èŠ‚æå†™çš„é‡è¦æ€§ |
| é£æ ¼ä¸ä¸€è‡´ | æ·»åŠ é£æ ¼ä¸€è‡´æ€§è¦æ±‚ |

## ä¼˜åŒ–æµç¨‹

1. åˆ†æåŸå§‹ Prompt çš„ç»“æ„å’Œæ„å›¾
2. ç ”ç©¶å·®è¯„æ¡ˆä¾‹ï¼Œæ‰¾å‡ºå…±åŒé—®é¢˜
3. ç ”ç©¶å¥½è¯„æ¡ˆä¾‹ï¼Œæ€»ç»“æˆåŠŸæ¨¡å¼
4. åº”ç”¨ä¼˜åŒ–ç­–ç•¥ï¼Œç”Ÿæˆæ–°ç‰ˆæœ¬
5. ç¼–å†™è¯¦ç»†çš„å˜æ›´è¯´æ˜

è¯·å§‹ç»ˆä»¥ä¸“ä¸šã€å®¢è§‚ã€å»ºè®¾æ€§çš„æ€åº¦è¿›è¡Œ Prompt ä¼˜åŒ–ã€‚"""

        self.logger.info("Meta ä¼˜åŒ–å™¨ Agent åˆå§‹åŒ–å®Œæˆ")

    async def optimize_prompt(
        self,
        agent_name: str,
        current_prompt: str,
        negative_cases: List[Dict[str, Any]],
        positive_cases: List[Dict[str, Any]],
        context: Optional[Dict[str, Any]] = None
    ) -> PromptOptimizationResult:
        """
        ä¼˜åŒ– Prompt

        Args:
            agent_name: Agent åç§°
            current_prompt: å½“å‰ System Prompt
            negative_cases: å·®è¯„æ¡ˆä¾‹åˆ—è¡¨ [{"user_input": "...", "ai_output": "...", "feedback": "..."}]
            positive_cases: å¥½è¯„æ¡ˆä¾‹/ç”¨æˆ·ä¿®æ”¹åçš„æ­£ç¡®èŒƒæ–‡
            context: é¢å¤–ä¸Šä¸‹æ–‡

        Returns:
            PromptOptimizationResult: ä¼˜åŒ–ç»“æœ
        """
        try:
            self.logger.info(f"ğŸ”§ å¼€å§‹ä¼˜åŒ– Prompt (agent: {agent_name})")

            # æ„å»ºä¼˜åŒ–è¯·æ±‚
            optimization_request = self._build_optimization_request(
                agent_name, current_prompt, negative_cases, positive_cases, context
            )

            # è°ƒç”¨ LLM è¿›è¡Œä¼˜åŒ–
            messages = [
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": optimization_request}
            ]

            optimized_response = await self._call_llm(messages)

            # è§£æå“åº”
            result = self._parse_optimization_response(
                agent_name, current_prompt, optimized_response,
                len(negative_cases), len(positive_cases)
            )

            self.logger.info(f"âœ… Prompt ä¼˜åŒ–å®Œæˆ (agent: {agent_name}, version: {result.version})")
            return result

        except Exception as e:
            self.logger.error(f"Prompt ä¼˜åŒ–å¤±è´¥: {e}")
            # è¿”å›åŸå§‹ç»“æœ
            return PromptOptimizationResult(
                original_prompt=current_prompt,
                optimized_prompt=current_prompt,
                agent_name=agent_name,
                version="v1.0.0-failed",
                problems_identified=[],
                improvement_suggestions=[],
                optimization_reasoning=f"ä¼˜åŒ–å¤±è´¥: {str(e)}",
                negative_examples_used=len(negative_cases),
                positive_examples_used=len(positive_cases),
                timestamp=datetime.now().isoformat(),
                confidence=0.0
            )

    def _build_optimization_request(
        self,
        agent_name: str,
        current_prompt: str,
        negative_cases: List[Dict[str, Any]],
        positive_cases: List[Dict[str, Any]],
        context: Optional[Dict[str, Any]]
    ) -> str:
        """æ„å»ºä¼˜åŒ–è¯·æ±‚"""
        request = f"""# Prompt ä¼˜åŒ–è¯·æ±‚

## ç›®æ ‡ Agent
- Agent åç§°: {agent_name}
- ä¼˜åŒ–ç›®æ ‡: æ ¹æ®ç”¨æˆ·åé¦ˆä¼˜åŒ– System Prompt

## å½“å‰ System Prompt
```
{current_prompt}
```

## å·®è¯„æ¡ˆä¾‹åˆ†æï¼ˆ{len(negative_cases)} ä¸ªæ¡ˆä¾‹ï¼‰
"""

        # æ·»åŠ å·®è¯„æ¡ˆä¾‹
        for i, case in enumerate(negative_cases[:5], 1):
            request += f"""
### æ¡ˆä¾‹ {i}
**ç”¨æˆ·è¾“å…¥**: {case.get('user_input', '')[:200]}

**AI è¾“å‡º**: {case.get('ai_output', '')[:300]}

**ç”¨æˆ·åé¦ˆ**: {case.get('feedback', '')[:200]}

**é—®é¢˜ç‚¹**: {case.get('problem', 'å¾…åˆ†æ')}
"""

        request += f"""

## å¥½è¯„æ¡ˆä¾‹/æ­£ç¡®èŒƒæ–‡ï¼ˆ{len(positive_cases)} ä¸ªæ¡ˆä¾‹ï¼‰
"""

        # æ·»åŠ å¥½è¯„æ¡ˆä¾‹
        for i, case in enumerate(positive_cases[:5], 1):
            request += f"""
### æ¡ˆä¾‹ {i}
**ç”¨æˆ·è¾“å…¥**: {case.get('user_input', '')[:200]}

**ç†æƒ³è¾“å‡º**: {case.get('ai_output', '')[:300]}

**æˆåŠŸåŸå› **: {case.get('success_reason', 'å¾…åˆ†æ')}
"""

        if context:
            request += f"""

## é¢å¤–ä¸Šä¸‹æ–‡
{str(context)[:500]}
"""

        request += """

## è¾“å‡ºè¦æ±‚

è¯·ä»¥ JSON æ ¼å¼è¿”å›ä¼˜åŒ–ç»“æœï¼š

```json
{
  "problems_identified": ["é—®é¢˜1", "é—®é¢˜2", "é—®é¢˜3"],
  "improvement_suggestions": ["å»ºè®®1", "å»ºè®®2"],
  "optimization_reasoning": "è¯¦ç»†çš„ä¼˜åŒ–æ€è·¯è¯´æ˜...",
  "optimized_prompt": "ä¼˜åŒ–åçš„å®Œæ•´ System Prompt..."
}
```

**æ³¨æ„**ï¼š
1. optimized_prompt å¿…é¡»æ˜¯å®Œæ•´çš„ã€å¯ç›´æ¥ä½¿ç”¨çš„ System Prompt
2. ä¿æŒåŸ Prompt çš„æ ¸å¿ƒåŠŸèƒ½å’Œç»“æ„
3. é’ˆå¯¹è¯†åˆ«å‡ºçš„é—®é¢˜è¿›è¡Œæœ‰é’ˆå¯¹æ€§çš„æ”¹è¿›
4. ä¼˜åŒ–åçš„ Prompt åº”è¯¥æ›´åŠ æ¸…æ™°ã€å…·ä½“ã€æœ‰æ•ˆ
"""

        return request

    def _parse_optimization_response(
        self,
        agent_name: str,
        original_prompt: str,
        response: str,
        negative_count: int,
        positive_count: int
    ) -> PromptOptimizationResult:
        """è§£æä¼˜åŒ–å“åº”"""
        try:
            import json
            import re

            # æå– JSON
            json_match = re.search(r'```json\s*([\s\S]*?)\s*```', response)
            if json_match:
                json_str = json_match.group(1)
            else:
                # å°è¯•ç›´æ¥è§£æ
                json_str = response

            data = json.loads(json_str)

            # ç”Ÿæˆæ–°ç‰ˆæœ¬å·
            version = self._generate_next_version()

            return PromptOptimizationResult(
                original_prompt=original_prompt,
                optimized_prompt=data.get('optimized_prompt', original_prompt),
                agent_name=agent_name,
                version=version,
                problems_identified=data.get('problems_identified', []),
                improvement_suggestions=data.get('improvement_suggestions', []),
                optimization_reasoning=data.get('optimization_reasoning', ''),
                negative_examples_used=negative_count,
                positive_examples_used=positive_count,
                timestamp=datetime.now().isoformat(),
                confidence=0.8
            )

        except Exception as e:
            self.logger.warning(f"è§£æä¼˜åŒ–å“åº”å¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå§‹å“åº”")
            # è¿”å›åŸºæœ¬ç»“æœ
            return PromptOptimizationResult(
                original_prompt=original_prompt,
                optimized_prompt=response if len(response) < 5000 else original_prompt,
                agent_name=agent_name,
                version=self._generate_next_version(),
                problems_identified=["è§£æå“åº”å¤±è´¥ï¼Œå¯èƒ½éœ€è¦äººå·¥å®¡æ ¸"],
                improvement_suggestions=[],
                optimization_reasoning=response[:500],
                negative_examples_used=negative_count,
                positive_examples_used=positive_count,
                timestamp=datetime.now().isoformat(),
                confidence=0.3
            )

    def _generate_next_version(self) -> str:
        """ç”Ÿæˆä¸‹ä¸€ä¸ªç‰ˆæœ¬å·"""
        import time
        return f"v1.{int(time.time() % 1000)}"

    async def analyze_feedback(
        self,
        feedbacks: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        åˆ†æåé¦ˆæ•°æ®

        Args:
            feedbacks: åé¦ˆåˆ—è¡¨

        Returns:
            Dict: åˆ†æç»“æœ
        """
        try:
            # æ„å»ºåˆ†æè¯·æ±‚
            analysis_request = f"""# åé¦ˆåˆ†æè¯·æ±‚

è¯·åˆ†æä»¥ä¸‹ {len(feedbacks)} æ¡ç”¨æˆ·åé¦ˆæ•°æ®ï¼Œæ€»ç»“ä¸»è¦é—®é¢˜å’Œæ”¹è¿›æ–¹å‘ã€‚

## åé¦ˆæ•°æ®
"""
            for i, fb in enumerate(feedbacks[:10], 1):
                analysis_request += f"""
### åé¦ˆ {i}
- ç”¨æˆ·è¯„åˆ†: {fb.get('user_rating', 'N/A')}
- AI è¾“å‡º: {fb.get('ai_output', '')[:200]}...
- ç”¨æˆ·ä¿®æ”¹: {fb.get('user_edit_text', 'æ— ')[:200]}...
- é—®é¢˜ç±»å‹: {fb.get('problem_type', 'æœªçŸ¥')}
"""

            analysis_request += """

## è¾“å‡ºè¦æ±‚

è¯·ä»¥ JSON æ ¼å¼è¿”å›åˆ†æç»“æœï¼š

```json
{
  "common_problems": ["é—®é¢˜1", "é—®é¢˜2"],
  "problem_categories": ["ç±»åˆ«1", "ç±»åˆ«2"],
  "improvement_priority": "ä¼˜å…ˆçº§æœ€é«˜çš„æ”¹è¿›æ–¹å‘",
  "recommended_changes": ["å»ºè®®ä¿®æ”¹1", "å»ºè®®ä¿®æ”¹2"]
}
```
"""

            messages = [
                {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„ AI äº§å“åˆ†æä¸“å®¶ï¼Œæ“…é•¿ä»ç”¨æˆ·åé¦ˆä¸­æç‚¼é—®é¢˜å’Œæ”¹è¿›æ–¹å‘ã€‚"},
                {"role": "user", "content": analysis_request}
            ]

            response = await self._call_llm(messages)

            # è§£æ JSON å“åº”
            import json
            import re
            json_match = re.search(r'```json\s*([\s\S]*?)\s*```', response)
            if json_match:
                json_str = json_match.group(1)
            else:
                json_str = response

            try:
                return json.loads(json_str)
            except:
                return {
                    "common_problems": ["æ— æ³•è‡ªåŠ¨è§£æï¼Œéœ€è¦äººå·¥åˆ†æ"],
                    "analysis_raw": response[:1000]
                }

        except Exception as e:
            self.logger.error(f"åˆ†æåé¦ˆå¤±è´¥: {e}")
            return {}

    async def process_request(
        self,
        request_data: Dict[str, Any],
        context: Optional[Dict[str, Any]] = None
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        å¤„ç†ä¼˜åŒ–è¯·æ±‚ï¼ˆå…¼å®¹åŸºç±»æ¥å£ï¼‰

        Args:
            request_data: è¯·æ±‚æ•°æ®
                - action: "optimize" æˆ– "analyze"
                - agent_name: Agent åç§°
                - current_prompt: å½“å‰ Promptï¼ˆä¼˜åŒ–æ—¶éœ€è¦ï¼‰
                - negative_cases: å·®è¯„æ¡ˆä¾‹
                - positive_cases: å¥½è¯„æ¡ˆä¾‹
            context: ä¸Šä¸‹æ–‡

        Yields:
            Dict[str, Any]: æµå¼å“åº”äº‹ä»¶
        """
        try:
            action = request_data.get("action", "optimize")
            agent_name = request_data.get("agent_name", "unknown")

            yield await self._emit_event("system", f"ğŸ”§ Meta ä¼˜åŒ–å™¨å¯åŠ¨ (action: {action}, agent: {agent_name})")

            if action == "optimize":
                # æ‰§è¡Œä¼˜åŒ–
                result = await self.optimize_prompt(
                    agent_name=agent_name,
                    current_prompt=request_data.get("current_prompt", ""),
                    negative_cases=request_data.get("negative_cases", []),
                    positive_cases=request_data.get("positive_cases", []),
                    context=context
                )

                yield await self._emit_event("content", f"""# Prompt ä¼˜åŒ–å®Œæˆ

## ä¼˜åŒ–ç‰ˆæœ¬
**ç‰ˆæœ¬**: {result.version}
**ç½®ä¿¡åº¦**: {result.confidence:.2f}

## è¯†åˆ«çš„é—®é¢˜
{chr(10).join(f'- {p}' for p in result.problems_identified)}

## æ”¹è¿›å»ºè®®
{chr(10).join(f'- {s}' for s in result.improvement_suggestions)}

## ä¼˜åŒ–æ€è·¯
{result.optimization_reasoning}

## ä¼˜åŒ–åçš„ Prompt
```
{result.optimized_prompt}
```
""")

                yield await self._emit_event("metadata", f'{{"version": "{result.version}", "confidence": {result.confidence}}}')

            elif action == "analyze":
                # æ‰§è¡Œåˆ†æ
                feedbacks = request_data.get("feedbacks", [])
                analysis = await self.analyze_feedback(feedbacks)

                yield await self._emit_event("content", f"""# åé¦ˆåˆ†æå®Œæˆ

## å¸¸è§é—®é¢˜
{chr(10).join(f'- {p}' for p in analysis.get("common_problems", []))}

## é—®é¢˜ç±»åˆ«
{chr(10).join(f'- {c}' for c in analysis.get("problem_categories", []))}

## æ”¹è¿›ä¼˜å…ˆçº§
**{analysis.get("improvement_priority", "æœªçŸ¥")}**

## æ¨èä¿®æ”¹
{chr(10).join(f'{i+1}. {c}' for i, c in enumerate(analysis.get("recommended_changes", [])))}
""")

            yield await self._emit_event("system", "âœ… Meta ä¼˜åŒ–å™¨å¤„ç†å®Œæˆ")

        except Exception as e:
            self.logger.error(f"å¤„ç†è¯·æ±‚å¤±è´¥: {e}")
            yield await self._emit_event("error", f"å¤„ç†å¤±è´¥: {str(e)}")

    async def _emit_event(self, event_type: str, content: str) -> Dict[str, Any]:
        """æ„å»ºäº‹ä»¶"""
        return {
            "type": event_type,
            "content": content,
            "timestamp": datetime.now().isoformat()
        }


# ==================== å…¨å±€å®ä¾‹ ====================

_meta_optimizer_agent: Optional[MetaOptimizerAgent] = None


def get_meta_optimizer_agent() -> MetaOptimizerAgent:
    """è·å– Meta ä¼˜åŒ–å™¨å•ä¾‹"""
    global _meta_optimizer_agent
    if _meta_optimizer_agent is None:
        _meta_optimizer_agent = MetaOptimizerAgent()
    return _meta_optimizer_agent
