"""
ç«–å±çŸ­å‰§çŸ¥è¯†åº“æŸ¥è¯¢æ™ºèƒ½ä½“
 ä¸“æ³¨äºçŸ¥è¯†åº“æŸ¥è¯¢å’Œä¿¡æ¯æ£€ç´¢

ä¸šåŠ¡å¤„ç†é€»è¾‘ï¼š
1. è¾“å…¥å¤„ç†ï¼šæ¥æ”¶æŸ¥è¯¢è¯·æ±‚ï¼Œæ”¯æŒå¤šç§æŸ¥è¯¢æ ¼å¼å’Œæ„å›¾è¯†åˆ«
2. æ„å›¾è¯†åˆ«ï¼šä½¿ç”¨IntentRecognizeråˆ†æç”¨æˆ·æŸ¥è¯¢æ„å›¾
3. URLæå–ï¼šä»æŸ¥è¯¢ä¸­æå–ç›¸å…³çš„URLé“¾æ¥ä¿¡æ¯
4. çŸ¥è¯†åº“æŸ¥è¯¢ï¼šåœ¨ç«–å±çŸ­å‰§çŸ¥è¯†åº“ä¸­è¿›è¡Œä¿¡æ¯æ£€ç´¢
5. ä¿¡æ¯è¿‡æ»¤ï¼šæ ¹æ®æŸ¥è¯¢æ„å›¾è¿‡æ»¤å’Œæ’åºæ£€ç´¢ç»“æœ
6. å†…å®¹ç”Ÿæˆï¼šåŸºäºæ£€ç´¢ç»“æœç”Ÿæˆç»“æ„åŒ–çš„å›ç­”
7. ä¸Šä¸‹æ–‡ç®¡ç†ï¼šç»´æŠ¤æŸ¥è¯¢å†å²å’Œä¸Šä¸‹æ–‡ä¿¡æ¯
8. è¾“å‡ºæ ¼å¼åŒ–ï¼šè¿”å›ç»“æ„åŒ–çš„çŸ¥è¯†åº“æŸ¥è¯¢ç»“æœ
9. Agent as Toolï¼šæ”¯æŒè¢«å…¶ä»–æ™ºèƒ½ä½“è°ƒç”¨ï¼Œå®ç°ä¸Šä¸‹æ–‡éš”ç¦»

ä»£ç ä½œè€…ï¼šå®«çµç‘
åˆ›å»ºæ—¶é—´ï¼š2024å¹´10æœˆ19æ—¥
"""
import asyncio
import logging
import re
from typing import Dict, Any, List, Optional, AsyncGenerator
from datetime import datetime
import json

try:
    from .base_juben_agent import BaseJubenAgent
    from ..utils.intent_recognition import IntentRecognizer
    from ..utils.url_extractor import URLExtractor
except ImportError:
    # å¤„ç†ç›¸å¯¹å¯¼å…¥é—®é¢˜
    import sys
    from pathlib import Path
    sys.path.insert(0, str(Path(__file__).parent.parent))
    
    from agents.base_juben_agent import BaseJubenAgent
    from utils.intent_recognition import IntentRecognizer
    from utils.url_extractor import URLExtractor


class KnowledgeAgent(BaseJubenAgent):
    """
    ç«–å±çŸ­å‰§çŸ¥è¯†åº“æŸ¥è¯¢æ™ºèƒ½ä½“
    
    åŠŸèƒ½ï¼š
    1. çŸ¥è¯†åº“è¯­ä¹‰æœç´¢
    2. ä¸“ä¸šçŸ¥è¯†æå–
    3. çŸ¥è¯†å†…å®¹æ€»ç»“
    4. å¤šé›†åˆæŸ¥è¯¢æ”¯æŒ
    5. çŸ¥è¯†æ¨èå’Œå…³è”
    """
    
    def __init__(self):
        super().__init__("knowledge", model_provider="zhipu")
        
        # ç³»ç»Ÿæç¤ºè¯é…ç½®ï¼ˆä»promptsæ–‡ä»¶å¤¹åŠ è½½ï¼‰
        self._load_system_prompt()
        
        # åˆå§‹åŒ–ä¸“ç”¨ç»„ä»¶
        self.intent_recognizer = IntentRecognizer()
        self.url_extractor = URLExtractor()
        
        # çŸ¥è¯†åº“é…ç½®
        self.knowledge_config = {
            "default_collection": "script_segments",
            "available_collections": [
                "script_segments",      # å‰§æœ¬æ¡¥æ®µåº“
                "drama_highlights"      # çŸ­å‰§é«˜èƒ½æƒ…èŠ‚åº“
            ],
            "default_top_k": 5,
            "max_top_k": 20
        }
        
        self.logger.info("ç«–å±çŸ­å‰§çŸ¥è¯†åº“æŸ¥è¯¢æ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ")
    
    async def process_request(
        self, 
        request_data: Dict[str, Any],
        context: Optional[Dict[str, Any]] = None
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        å¤„ç†çŸ¥è¯†åº“æŸ¥è¯¢è¯·æ±‚
        
        Args:
            request_data: è¯·æ±‚æ•°æ®
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Yields:
            Dict: æµå¼å“åº”äº‹ä»¶
        """
        try:
            # æå–è¯·æ±‚ä¿¡æ¯
            query = request_data.get("query", request_data.get("input", ""))
            instruction = request_data.get("instruction", query)
            user_id = context.get("user_id", "unknown") if context else "unknown"
            session_id = context.get("session_id", "unknown") if context else "unknown"
            collection = request_data.get("collection", self.knowledge_config["default_collection"])
            top_k = request_data.get("top_k", self.knowledge_config["default_top_k"])
            
            self.logger.info(f"å¼€å§‹å¤„ç†çŸ¥è¯†åº“æŸ¥è¯¢è¯·æ±‚: {instruction}")
            
            # åˆå§‹åŒ–Tokenç´¯åŠ å™¨
            await self.initialize_token_accumulator(user_id, session_id)
            
            # å‘é€å¼€å§‹å¤„ç†äº‹ä»¶
            yield await self._emit_event("system", f"ğŸ“š å¼€å§‹çŸ¥è¯†åº“æŸ¥è¯¢: {instruction}")
            
            # 1. æ„å›¾è¯†åˆ«
            yield await self._emit_event("system", "ğŸ” æ­£åœ¨åˆ†ææŸ¥è¯¢æ„å›¾...")
            intent_result = await self._analyze_intent(instruction)
            yield await self._emit_event("system", f"âœ… æ„å›¾è¯†åˆ«å®Œæˆ: {intent_result['intent']}")
            
            # 2. URLæå–å’Œå†…å®¹è·å–
            urls = self.url_extractor.extract_urls(instruction)
            url_contents = []
            if urls:
                yield await self._emit_event("system", f"ğŸ“ å‘ç°{len(urls)}ä¸ªé“¾æ¥ï¼Œæ­£åœ¨æå–å†…å®¹...")
                url_contents = await self._extract_url_contents(urls)
                yield await self._emit_event("system", "âœ… URLå†…å®¹æå–å®Œæˆ")
            
            # 3. çŸ¥è¯†åº“æŸ¥è¯¢
            yield await self._emit_event("system", "ğŸ“š æ­£åœ¨æŸ¥è¯¢çŸ¥è¯†åº“...")
            knowledge_results = await self._search_knowledge_base(instruction, collection=collection, top_k=top_k)
            yield await self._emit_event("system", "âœ… çŸ¥è¯†åº“æŸ¥è¯¢å®Œæˆ")
            
            # 4. æ ¼å¼åŒ–çŸ¥è¯†åº“ç»“æœ
            formatted_results = self._format_knowledge_results(knowledge_results, instruction)
            
            # 5. å‘é€çŸ¥è¯†åº“æŸ¥è¯¢ç»“æœ
            yield await self._emit_event("knowledge_results", formatted_results)
            
            # 6. æ™ºèƒ½æ€»ç»“çŸ¥è¯†å†…å®¹
            if formatted_results:
                yield await self._emit_event("system", "ğŸ“ æ­£åœ¨åˆ†æå’Œæ€»ç»“çŸ¥è¯†å†…å®¹...")
                
                async for chunk in self._generate_knowledge_summary(instruction, knowledge_results, user_id, session_id):
                    yield chunk
                
                yield await self._emit_event("system", "âœ… çŸ¥è¯†å†…å®¹æ€»ç»“å®Œæˆ")
            
            # 7. è·å–Tokenè®¡è´¹æ‘˜è¦
            billing_summary = await self.get_token_billing_summary()
            if billing_summary:
                yield await self._emit_event("billing", f"ğŸ“Š Tokenæ¶ˆè€—: {billing_summary['total_tokens']} tokens, ç§¯åˆ†æ‰£å‡: {billing_summary['deducted_points']} ç§¯åˆ†")
            
            # 8. å‘é€å®Œæˆäº‹ä»¶
            yield await self._emit_event("system", "ğŸ¯ çŸ¥è¯†åº“æŸ¥è¯¢ä»»åŠ¡å®Œæˆï¼")
            
        except Exception as e:
            self.logger.error(f"å¤„ç†çŸ¥è¯†åº“æŸ¥è¯¢è¯·æ±‚å¤±è´¥: {e}")
            yield await self._emit_event("error", f"å¤„ç†å¤±è´¥: {str(e)}")
    
    async def _analyze_intent(self, user_input: str) -> Dict[str, Any]:
        """åˆ†æç”¨æˆ·æŸ¥è¯¢æ„å›¾"""
        try:
            # çŸ¥è¯†åº“ç›¸å…³çš„æ„å›¾è¯†åˆ«
            intent_result = await self.intent_recognizer.analyze(user_input)
            
            # æ ¹æ®æŸ¥è¯¢éœ€æ±‚è°ƒæ•´æ„å›¾
            if "å‰§æœ¬" in user_input or "æ¡¥æ®µ" in user_input or "æƒ…èŠ‚" in user_input:
                intent_result.update({
                    "intent": "script_knowledge",
                    "needs_knowledge_base": True,
                    "needs_web_search": False,
                    "preferred_collection": "script_segments"
                })
            elif "é«˜èƒ½" in user_input or "çˆ†ç‚¹" in user_input or "çˆ½ç‚¹" in user_input:
                intent_result.update({
                    "intent": "drama_highlights",
                    "needs_knowledge_base": True,
                    "needs_web_search": False,
                    "preferred_collection": "drama_highlights"
                })
            elif "çŸ¥è¯†" in user_input or "æŸ¥è¯¢" in user_input or "æ£€ç´¢" in user_input:
                intent_result.update({
                    "intent": "general_knowledge",
                    "needs_knowledge_base": True,
                    "needs_web_search": False
                })
            elif "æŠ€å·§" in user_input or "æ–¹æ³•" in user_input or "ç»éªŒ" in user_input:
                intent_result.update({
                    "intent": "skill_knowledge",
                    "needs_knowledge_base": True,
                    "needs_web_search": False
                })
            
            return intent_result
        except Exception as e:
            self.logger.error(f"æ„å›¾è¯†åˆ«å¤±è´¥: {e}")
            return {
                "intent": "general_knowledge",
                "confidence": 0.5,
                "needs_knowledge_base": True,
                "needs_web_search": False
            }
    
    async def _extract_url_contents(self, urls: List[str]) -> List[Dict[str, Any]]:
        """æå–URLå†…å®¹"""
        contents = []
        for url in urls:
            try:
                content = await self.url_extractor.extract_content(url)
                contents.append(content)
            except Exception as e:
                self.logger.error(f"æå–URLå†…å®¹å¤±è´¥ {url}: {e}")
                contents.append({
                    "url": url,
                    "success": False,
                    "error": str(e)
                })
        return contents
    
    def _format_knowledge_results(self, knowledge_results: Dict[str, Any], query: str) -> List[Dict[str, Any]]:
        """æ ¼å¼åŒ–çŸ¥è¯†åº“æŸ¥è¯¢ç»“æœ"""
        formatted_results = []
        
        if not knowledge_results.get("success", False):
            return formatted_results
        
        raw_results = knowledge_results.get("results", [])
        # å…¼å®¹ BaseJubenAgent è¿”å›ç»“æ„ï¼š
        # {"success": True, "results": {"success": True, "results": [...]}}
        if isinstance(raw_results, dict):
            results = raw_results.get("results", []) or []
        else:
            results = raw_results or []
        
        for i, result in enumerate(results):
            formatted_result = {
                "id": f"knowledge_{i+1}",
                "type": "knowledge",
                "title": result.get("title", f"çŸ¥è¯†ç‚¹ {i+1}"),
                "content": result.get("content", ""),
                "similarity": result.get("similarity", 0.0),
                "source": result.get("source", ""),
                "chunk_index": result.get("chunk_index", 0)
            }
            formatted_results.append(formatted_result)
        
        return formatted_results
    
    def _extract_knowledge_content(self, knowledge_results: Dict[str, Any]) -> str:
        """ä»çŸ¥è¯†åº“æŸ¥è¯¢ç»“æœä¸­æå–æ–‡æœ¬å†…å®¹ç”¨äºæ€»ç»“"""
        content_list = []
        
        if not knowledge_results.get("success", False):
            return "æ— çŸ¥è¯†åº“æŸ¥è¯¢ç»“æœ"
        
        raw_results = knowledge_results.get("results", [])
        if isinstance(raw_results, dict):
            results = raw_results.get("results", []) or []
        else:
            results = raw_results or []
        
        for i, result in enumerate(results):
            title = result.get("title", f"çŸ¥è¯†ç‚¹ {i+1}")
            content = result.get("content", "")
            similarity = result.get("similarity", 0.0)
            source = result.get("source", "")
            
            result_text = f"çŸ¥è¯†ç‚¹{i+1}:\næ ‡é¢˜: {title}\nç›¸ä¼¼åº¦: {similarity:.2f}\næ¥æº: {source}\nå†…å®¹: {content}\n"
            content_list.append(result_text)
        
        return "\n".join(content_list)
    
    def _build_knowledge_summary_prompt(self, original_query: str, knowledge_content: str) -> str:
        """æ„å»ºçŸ¥è¯†æ€»ç»“çš„ç”¨æˆ·æç¤ºè¯"""
        return f"""ç”¨æˆ·æŸ¥è¯¢éœ€æ±‚: {original_query}

ä»¥ä¸‹æ˜¯çŸ¥è¯†åº“æŸ¥è¯¢è¿”å›çš„ç»“æœ:
{knowledge_content}

è¯·æ ¹æ®ç”¨æˆ·çš„æŸ¥è¯¢éœ€æ±‚ï¼Œå°†ä¸Šè¿°çŸ¥è¯†åº“å†…å®¹æ•´ç†ä¸ºæ•°ä¸ªæœ‰ç”¨çš„çŸ¥è¯†ç‚¹ã€‚æ¯ä¸ªçŸ¥è¯†ç‚¹åº”è¯¥æœ‰å®Œæ•´çš„èƒŒæ™¯ã€æ–¹æ³•å’Œåº”ç”¨åœºæ™¯ï¼Œè€Œä¸æ˜¯ç¢ç‰‡åŒ–çš„ä¿¡æ¯ã€‚ä½¿ç”¨åˆé€‚çš„é¢—ç²’åº¦è¿›è¡Œæ•´ç†ã€‚

è¦æ±‚ï¼š
1. ä¿æŒçŸ¥è¯†çš„å‡†ç¡®æ€§å’Œä¸“ä¸šæ€§
2. æŒ‰ç…§é€»è¾‘é¡ºåºç»„ç»‡çŸ¥è¯†ç‚¹
3. çªå‡ºä¸æŸ¥è¯¢éœ€æ±‚æœ€ç›¸å…³çš„å†…å®¹
4. æä¾›å®ç”¨çš„å»ºè®®å’ŒæŠ€å·§
5. ç¡®ä¿å†…å®¹çš„å®Œæ•´æ€§å’Œå¯æ“ä½œæ€§
"""
    
    async def _generate_knowledge_summary(self, query: str, knowledge_results: Dict[str, Any], user_id: str, session_id: str) -> AsyncGenerator[Dict[str, Any], None]:
        """ç”ŸæˆçŸ¥è¯†æ€»ç»“"""
        try:
            # æ„å»ºæ€»ç»“æç¤ºè¯
            knowledge_content = self._extract_knowledge_content(knowledge_results)
            user_prompt = self._build_knowledge_summary_prompt(query, knowledge_content)
            
            # æ„å»ºæ¶ˆæ¯
            messages = [
                {"role": "user", "content": user_prompt}
            ]
            
            # æµå¼è°ƒç”¨LLMï¼ˆå¸¦è¿½è¸ªï¼‰
            async for chunk in self._stream_llm(messages, user_id=user_id, session_id=session_id):
                yield await self._emit_event("llm_chunk", chunk)
                
        except Exception as e:
            self.logger.error(f"ç”ŸæˆçŸ¥è¯†æ€»ç»“å¤±è´¥: {e}")
            yield await self._emit_event("error", f"ç”Ÿæˆæ€»ç»“å¤±è´¥: {str(e)}")
    
    def get_available_collections(self) -> List[Dict[str, str]]:
        """è·å–å¯ç”¨çš„çŸ¥è¯†åº“é›†åˆ"""
        collections = []
        for collection_name in self.knowledge_config["available_collections"]:
            if collection_name == "script_segments":
                collections.append({
                    "name": collection_name,
                    "display_name": "å‰§æœ¬æ¡¥æ®µåº“",
                    "description": "åŒ…å«å„ç§ç»å…¸å‰§æœ¬æ¡¥æ®µå’Œæƒ…èŠ‚æ¨¡æ¿"
                })
            elif collection_name == "drama_highlights":
                collections.append({
                    "name": collection_name,
                    "display_name": "çŸ­å‰§é«˜èƒ½æƒ…èŠ‚åº“",
                    "description": "åŒ…å«çŸ­å‰§ä¸­çš„é«˜èƒ½æƒ…èŠ‚å’Œçˆ†ç‚¹è®¾è®¡"
                })
        return collections
    
    def get_agent_info(self) -> Dict[str, Any]:
        """è·å–Agentä¿¡æ¯"""
        base_info = super().get_agent_info()
        base_info.update({
            "agent_type": "knowledge",
            "description": "ç«–å±çŸ­å‰§çŸ¥è¯†åº“æŸ¥è¯¢æ™ºèƒ½ä½“ï¼Œä¸“æ³¨äºçŸ¥è¯†åº“æŸ¥è¯¢å’Œä¿¡æ¯æ£€ç´¢",
            "capabilities": [
                "çŸ¥è¯†åº“è¯­ä¹‰æœç´¢",
                "ä¸“ä¸šçŸ¥è¯†æå–",
                "çŸ¥è¯†å†…å®¹æ€»ç»“",
                "å¤šé›†åˆæŸ¥è¯¢æ”¯æŒ",
                "çŸ¥è¯†æ¨èå’Œå…³è”"
            ],
            "knowledge_config": self.knowledge_config,
            "available_collections": self.get_available_collections()
        })
        return base_info
