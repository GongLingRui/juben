"""
Generative Agentsæœºåˆ¶ - ä»è§‚å¯Ÿä¸­æ€»ç»“ï¼Œåˆæˆæ´å¯Ÿ
åŸºäºå‘¨æœŸæ€§çš„è§‚å¯Ÿæ€»ç»“å’Œæ´å¯Ÿåˆæˆç³»ç»Ÿ
"""
import os
import json
import asyncio
import logging
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Union, Tuple
from dataclasses import dataclass, asdict
from pathlib import Path
import hashlib
import uuid

try:
    from ..config.settings import JubenSettings
    from ..utils.logger import JubenLogger
    from ..utils.storage_manager import JubenStorageManager, Note
    from ..utils.llm_client import JubenLLMClient
    from ..utils.vector_store import VectorStore
except ImportError:
    import sys
    from pathlib import Path
    sys.path.insert(0, str(Path(__file__).parent.parent))
    
    from config.settings import JubenSettings
    from utils.logger import JubenLogger
    from utils.storage_manager import JubenStorageManager, Note
    from utils.llm_client import JubenLLMClient
    from utils.vector_store import VectorStore


@dataclass
class ObservationLog:
    """è§‚å¯Ÿæ—¥å¿—"""
    id: str
    timestamp: str
    content: str
    source: str  # user_input, system_response, interaction, etc.
    importance: int  # 1-10
    category: str
    tags: List[str]
    user_id: str
    session_id: str
    agent_name: str
    metadata: Dict[str, Any]


@dataclass
class SynthesisInsight:
    """åˆæˆæ´å¯Ÿ"""
    id: str
    insight_type: str  # pattern, trend, behavior, preference, etc.
    title: str
    description: str
    evidence: List[str]  # æ”¯æ’‘è¯æ®
    confidence: float  # 0-1
    importance: int  # 1-10
    created_at: str
    updated_at: str
    tags: List[str]
    related_observations: List[str]  # ç›¸å…³è§‚å¯ŸID
    user_id: str
    metadata: Dict[str, Any]


@dataclass
class SynthesisSession:
    """åˆæˆä¼šè¯"""
    id: str
    user_id: str
    start_time: str
    end_time: str
    observations_processed: int
    insights_generated: int
    synthesis_method: str
    quality_score: float  # 0-1
    status: str  # active, completed, failed
    metadata: Dict[str, Any]


class GenerativeAgents:
    """Generative Agentsæœºåˆ¶"""
    
    def __init__(self, model_provider: str = "zhipu"):
        """
        åˆå§‹åŒ–Generative Agentsæœºåˆ¶
        
        Args:
            model_provider: æ¨¡å‹æä¾›å•†
        """
        self.config = JubenSettings()
        self.logger = JubenLogger("GenerativeAgents", level=self.config.log_level)
        self.storage_manager = JubenStorageManager()
        self.llm_client = JubenLLMClient(model_provider)
        self.vector_store = VectorStore()
        
        # è§‚å¯Ÿå’Œæ´å¯ŸçŠ¶æ€
        self.observation_logs: Dict[str, ObservationLog] = {}
        self.synthesis_insights: Dict[str, SynthesisInsight] = {}
        self.synthesis_sessions: Dict[str, SynthesisSession] = {}
        
        # åˆæˆé…ç½®
        self.synthesis_config = {
            "auto_synthesis": True,
            "synthesis_interval_hours": 24,  # åˆæˆé—´éš”ï¼ˆå°æ—¶ï¼‰
            "min_observations_for_synthesis": 10,  # æœ€å°‘è§‚å¯Ÿæ•°é‡
            "insight_confidence_threshold": 0.6,  # æ´å¯Ÿç½®ä¿¡åº¦é˜ˆå€¼
            "max_insights_per_session": 20,  # æ¯æ¬¡åˆæˆæœ€å¤§æ´å¯Ÿæ•°
            "observation_retention_days": 30  # è§‚å¯Ÿä¿ç•™å¤©æ•°
        }
        
        self.logger.info("Generative Agentsæœºåˆ¶åˆå§‹åŒ–å®Œæˆ")
    
    async def initialize(self):
        """åˆå§‹åŒ–Generative Agentsæœºåˆ¶"""
        try:
            await self.storage_manager.initialize()
            await self.vector_store.initialize()
            self.logger.info("âœ… Generative Agentsæœºåˆ¶åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            self.logger.error(f"âŒ Generative Agentsæœºåˆ¶åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    async def log_observation(
        self,
        content: str,
        source: str,
        importance: int,
        category: str,
        user_id: str,
        session_id: str,
        agent_name: str,
        tags: List[str] = None,
        metadata: Dict[str, Any] = None
    ) -> ObservationLog:
        """
        è®°å½•è§‚å¯Ÿæ—¥å¿—
        
        Args:
            content: è§‚å¯Ÿå†…å®¹
            source: è§‚å¯Ÿæ¥æº
            importance: é‡è¦æ€§ï¼ˆ1-10ï¼‰
            category: ç±»åˆ«
            user_id: ç”¨æˆ·ID
            session_id: ä¼šè¯ID
            agent_name: Agentåç§°
            tags: æ ‡ç­¾
            metadata: å…ƒæ•°æ®
            
        Returns:
            è§‚å¯Ÿæ—¥å¿—å¯¹è±¡
        """
        try:
            # åˆ›å»ºè§‚å¯Ÿæ—¥å¿—
            observation = ObservationLog(
                id=str(uuid.uuid4()),
                timestamp=datetime.now().isoformat(),
                content=content,
                source=source,
                importance=importance,
                category=category,
                tags=tags or [],
                user_id=user_id,
                session_id=session_id,
                agent_name=agent_name,
                metadata=metadata or {}
            )
            
            # å­˜å‚¨è§‚å¯Ÿæ—¥å¿—
            self.observation_logs[observation.id] = observation
            
            # å­˜å‚¨åˆ°æŒä¹…åŒ–å­˜å‚¨
            await self._store_observation(observation)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è§¦å‘åˆæˆ
            if await self._should_trigger_synthesis(user_id):
                await self._trigger_synthesis(user_id)
            
            self.logger.info(f"ğŸ“ è®°å½•è§‚å¯Ÿ: {observation.id}")
            return observation
            
        except Exception as e:
            self.logger.error(f"è®°å½•è§‚å¯Ÿå¤±è´¥: {e}")
            raise
    
    async def _store_observation(self, observation: ObservationLog):
        """å­˜å‚¨è§‚å¯Ÿæ—¥å¿—"""
        try:
            # å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
            await self.vector_store.add_document(
                id=observation.id,
                content=observation.content,
                metadata={
                    "timestamp": observation.timestamp,
                    "source": observation.source,
                    "importance": observation.importance,
                    "category": observation.category,
                    "tags": observation.tags,
                    "user_id": observation.user_id,
                    "session_id": observation.session_id,
                    "agent_name": observation.agent_name
                }
            )
            
            # å­˜å‚¨åˆ°æŒä¹…åŒ–å­˜å‚¨
            note = Note(
                id=observation.id,
                user_id=observation.user_id,
                title=f"è§‚å¯Ÿ_{observation.category}_{observation.timestamp}",
                content=observation.content,
                note_type="observation",
                tags=observation.tags,
                metadata={
                    "source": observation.source,
                    "importance": observation.importance,
                    "category": observation.category,
                    "session_id": observation.session_id,
                    "agent_name": observation.agent_name,
                    "timestamp": observation.timestamp
                }
            )
            
            await self.storage_manager.save_note(note)
            
        except Exception as e:
            self.logger.error(f"å­˜å‚¨è§‚å¯Ÿå¤±è´¥: {e}")
    
    async def _should_trigger_synthesis(self, user_id: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦éœ€è¦è§¦å‘åˆæˆ"""
        try:
            # è·å–ç”¨æˆ·çš„è§‚å¯Ÿæ•°é‡
            user_observations = [
                obs for obs in self.observation_logs.values()
                if obs.user_id == user_id
            ]
            
            # æ£€æŸ¥è§‚å¯Ÿæ•°é‡
            if len(user_observations) >= self.synthesis_config['min_observations_for_synthesis']:
                return True
            
            # æ£€æŸ¥æ—¶é—´é—´éš”
            if user_observations:
                latest_observation = max(user_observations, key=lambda x: x.timestamp)
                latest_time = datetime.fromisoformat(latest_observation.timestamp)
                if (datetime.now() - latest_time).total_seconds() >= \
                   self.synthesis_config['synthesis_interval_hours'] * 3600:
                    return True
            
            return False
            
        except Exception as e:
            self.logger.error(f"æ£€æŸ¥åˆæˆè§¦å‘æ¡ä»¶å¤±è´¥: {e}")
            return False
    
    async def _trigger_synthesis(self, user_id: str):
        """è§¦å‘åˆæˆæµç¨‹"""
        try:
            self.logger.info(f"ğŸ”„ è§¦å‘åˆæˆæµç¨‹: {user_id}")
            
            # åˆ›å»ºåˆæˆä¼šè¯
            synthesis_session = SynthesisSession(
                id=str(uuid.uuid4()),
                user_id=user_id,
                start_time=datetime.now().isoformat(),
                end_time="",
                observations_processed=0,
                insights_generated=0,
                synthesis_method="llm_synthesis",
                quality_score=0.0,
                status="active",
                metadata={}
            )
            
            self.synthesis_sessions[synthesis_session.id] = synthesis_session
            
            # æ‰§è¡Œåˆæˆæµç¨‹
            await self._execute_synthesis(synthesis_session)
            
        except Exception as e:
            self.logger.error(f"è§¦å‘åˆæˆæµç¨‹å¤±è´¥: {e}")
    
    async def _execute_synthesis(self, synthesis_session: SynthesisSession):
        """æ‰§è¡Œåˆæˆæµç¨‹"""
        try:
            self.logger.info(f"ğŸ§  å¼€å§‹åˆæˆæµç¨‹: {synthesis_session.id}")
            
            # 1. æ”¶é›†ç›¸å…³è§‚å¯Ÿ
            relevant_observations = await self._collect_relevant_observations(synthesis_session.user_id)
            synthesis_session.observations_processed = len(relevant_observations)
            
            if not relevant_observations:
                self.logger.warning("æ²¡æœ‰æ‰¾åˆ°ç›¸å…³è§‚å¯Ÿï¼Œè·³è¿‡åˆæˆ")
                return
            
            # 2. ç”Ÿæˆè§‚å¯Ÿæ€»ç»“
            observation_summary = await self._generate_observation_summary(relevant_observations)
            
            # 3. ç”Ÿæˆæ´å¯Ÿ
            insights = await self._generate_insights(observation_summary, relevant_observations)
            
            # 4. å­˜å‚¨æ´å¯Ÿ
            for insight in insights:
                self.synthesis_insights[insight.id] = insight
                await self._store_insight(insight)
                synthesis_session.insights_generated += 1
            
            # 5. æ›´æ–°åˆæˆä¼šè¯
            synthesis_session.end_time = datetime.now().isoformat()
            synthesis_session.status = "completed"
            synthesis_session.quality_score = self._calculate_synthesis_quality(insights)
            
            # 6. å­˜å‚¨åˆæˆä¼šè¯
            await self._store_synthesis_session(synthesis_session)
            
            self.logger.info(f"âœ… åˆæˆæµç¨‹å®Œæˆ: ç”Ÿæˆ {len(insights)} ä¸ªæ´å¯Ÿ")
            
        except Exception as e:
            self.logger.error(f"æ‰§è¡Œåˆæˆæµç¨‹å¤±è´¥: {e}")
            synthesis_session.status = "failed"
            synthesis_session.end_time = datetime.now().isoformat()
    
    async def _collect_relevant_observations(self, user_id: str) -> List[ObservationLog]:
        """æ”¶é›†ç›¸å…³è§‚å¯Ÿ"""
        try:
            # è·å–ç”¨æˆ·çš„æ‰€æœ‰è§‚å¯Ÿ
            user_observations = [
                obs for obs in self.observation_logs.values()
                if obs.user_id == user_id
            ]
            
            # æŒ‰é‡è¦æ€§æ’åº
            user_observations.sort(key=lambda x: x.importance, reverse=True)
            
            # é™åˆ¶æ•°é‡
            max_observations = 50
            relevant_observations = user_observations[:max_observations]
            
            self.logger.info(f"ğŸ“Š æ”¶é›†åˆ° {len(relevant_observations)} ä¸ªç›¸å…³è§‚å¯Ÿ")
            return relevant_observations
            
        except Exception as e:
            self.logger.error(f"æ”¶é›†ç›¸å…³è§‚å¯Ÿå¤±è´¥: {e}")
            return []
    
    async def _generate_observation_summary(self, observations: List[ObservationLog]) -> str:
        """ç”Ÿæˆè§‚å¯Ÿæ€»ç»“"""
        try:
            # æ„å»ºè§‚å¯Ÿæ€»ç»“æç¤ºè¯
            prompt = self._build_observation_summary_prompt(observations)
            
            # è°ƒç”¨LLMç”Ÿæˆæ€»ç»“
            response = await self.llm_client.generate_response(
                prompt=prompt,
                max_tokens=2000,
                temperature=0.3
            )
            
            if response and response.get('content'):
                return response['content']
            else:
                return self._simple_observation_summary(observations)
                
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆè§‚å¯Ÿæ€»ç»“å¤±è´¥: {e}")
            return self._simple_observation_summary(observations)
    
    def _build_observation_summary_prompt(self, observations: List[ObservationLog]) -> str:
        """æ„å»ºè§‚å¯Ÿæ€»ç»“æç¤ºè¯"""
        # å‡†å¤‡è§‚å¯Ÿæ•°æ®
        observation_data = []
        for obs in observations[:20]:  # é™åˆ¶æ•°é‡
            observation_data.append({
                "timestamp": obs.timestamp,
                "content": obs.content,
                "source": obs.source,
                "importance": obs.importance,
                "category": obs.category,
                "tags": obs.tags
            })
        
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§‚å¯Ÿæ€»ç»“ä¸“å®¶ï¼Œéœ€è¦ä»å¤§é‡è§‚å¯Ÿä¸­æç‚¼æ ¸å¿ƒåŠ¨æ€å’Œæ¨¡å¼ã€‚

## è§‚å¯Ÿæ•°æ®
{json.dumps(observation_data, ensure_ascii=False, indent=2)}

## ä»»åŠ¡è¦æ±‚
è¯·åˆ†æä»¥ä¸Šè§‚å¯Ÿæ•°æ®ï¼Œç”Ÿæˆä¸€ä¸ªç»¼åˆæ€»ç»“ï¼ŒåŒ…æ‹¬ï¼š

1. **æ ¸å¿ƒåŠ¨æ€**: è§‚å¯Ÿä¸­ä½“ç°çš„ä¸»è¦è¶‹åŠ¿å’Œå˜åŒ–
2. **å…³é”®æ¨¡å¼**: é‡å¤å‡ºç°çš„è¡Œä¸ºæ¨¡å¼å’Œè§„å¾‹
3. **é‡è¦äº‹ä»¶**: å…·æœ‰ç‰¹æ®Šæ„ä¹‰çš„äº‹ä»¶å’Œè½¬æŠ˜ç‚¹
4. **ç”¨æˆ·ç‰¹å¾**: ä»è§‚å¯Ÿä¸­æ¨æ–­å‡ºçš„ç”¨æˆ·ç‰¹å¾å’Œåå¥½
5. **ç³»ç»Ÿè¡¨ç°**: ç³»ç»Ÿåœ¨ä¸åŒæƒ…å†µä¸‹çš„è¡¨ç°ç‰¹ç‚¹

## è¾“å‡ºè¦æ±‚
è¯·ç”Ÿæˆä¸€ä¸ªç»“æ„åŒ–çš„æ€»ç»“ï¼Œçªå‡ºé‡ç‚¹ï¼Œé¿å…å†—ä½™ï¼Œç¡®ä¿æ€»ç»“å…·æœ‰æ´å¯Ÿä»·å€¼ã€‚

æ€»ç»“åº”è¯¥ï¼š
- ç®€æ´æ˜äº†ï¼Œé‡ç‚¹çªå‡º
- åŸºäºæ•°æ®ï¼Œæœ‰ç†æœ‰æ®
- å…·æœ‰å‰ç»æ€§ï¼Œèƒ½å¤ŸæŒ‡å¯¼æœªæ¥è¡ŒåŠ¨
- ä½“ç°ç”¨æˆ·å’Œç³»ç»Ÿçš„äº’åŠ¨æ¨¡å¼
"""
        
        return prompt
    
    def _simple_observation_summary(self, observations: List[ObservationLog]) -> str:
        """ç®€å•è§‚å¯Ÿæ€»ç»“ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        # æŒ‰ç±»åˆ«ç»Ÿè®¡
        category_stats = {}
        for obs in observations:
            category = obs.category
            if category not in category_stats:
                category_stats[category] = 0
            category_stats[category] += 1
        
        # æŒ‰é‡è¦æ€§ç»Ÿè®¡
        high_importance = [obs for obs in observations if obs.importance >= 7]
        
        summary = f"""
è§‚å¯Ÿæ€»ç»“ï¼š
- æ€»è§‚å¯Ÿæ•°: {len(observations)}
- é«˜é‡è¦æ€§è§‚å¯Ÿ: {len(high_importance)}
- ç±»åˆ«åˆ†å¸ƒ: {category_stats}
- æ—¶é—´èŒƒå›´: {observations[0].timestamp if observations else 'N/A'} åˆ° {observations[-1].timestamp if observations else 'N/A'}
"""
        
        return summary
    
    async def _generate_insights(
        self, 
        observation_summary: str, 
        observations: List[ObservationLog]
    ) -> List[SynthesisInsight]:
        """ç”Ÿæˆæ´å¯Ÿ"""
        try:
            # æ„å»ºæ´å¯Ÿç”Ÿæˆæç¤ºè¯
            prompt = self._build_insight_generation_prompt(observation_summary, observations)
            
            # è°ƒç”¨LLMç”Ÿæˆæ´å¯Ÿ
            response = await self.llm_client.generate_response(
                prompt=prompt,
                max_tokens=3000,
                temperature=0.4
            )
            
            if response and response.get('content'):
                # è§£ææ´å¯Ÿ
                insights_data = self._parse_insights_response(response['content'])
                return self._create_insights_from_data(insights_data, observations)
            else:
                return self._create_default_insights(observations)
                
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆæ´å¯Ÿå¤±è´¥: {e}")
            return self._create_default_insights(observations)
    
    def _build_insight_generation_prompt(
        self, 
        observation_summary: str, 
        observations: List[ObservationLog]
    ) -> str:
        """æ„å»ºæ´å¯Ÿç”Ÿæˆæç¤ºè¯"""
        # å‡†å¤‡è§‚å¯Ÿæ ·æœ¬
        sample_observations = observations[:10]  # å–å‰10ä¸ªè§‚å¯Ÿä½œä¸ºæ ·æœ¬
        
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ´å¯Ÿç”Ÿæˆä¸“å®¶ï¼Œéœ€è¦ä»è§‚å¯Ÿæ€»ç»“ä¸­æç‚¼æœ‰ä»·å€¼çš„æ´å¯Ÿã€‚

## è§‚å¯Ÿæ€»ç»“
{observation_summary}

## è§‚å¯Ÿæ ·æœ¬
{json.dumps([{
    "timestamp": obs.timestamp,
    "content": obs.content,
    "source": obs.source,
    "importance": obs.importance,
    "category": obs.category
} for obs in sample_observations], ensure_ascii=False, indent=2)}

## ä»»åŠ¡è¦æ±‚
åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œç”Ÿæˆ3-5ä¸ªæœ‰ä»·å€¼çš„æ´å¯Ÿï¼Œæ¯ä¸ªæ´å¯Ÿåº”è¯¥ï¼š

1. **æ´å¯Ÿç±»å‹**: æ˜ç¡®æ´å¯Ÿçš„ç±»å‹ï¼ˆæ¨¡å¼ã€è¶‹åŠ¿ã€è¡Œä¸ºã€åå¥½ç­‰ï¼‰
2. **æ´å¯Ÿæ ‡é¢˜**: ç®€æ´æ˜äº†çš„æ ‡é¢˜
3. **æ´å¯Ÿæè¿°**: è¯¦ç»†çš„æè¿°å’Œè§£é‡Š
4. **æ”¯æ’‘è¯æ®**: å…·ä½“çš„è¯æ®å’Œä¾‹å­
5. **ç½®ä¿¡åº¦**: å¯¹æ´å¯Ÿå‡†ç¡®æ€§çš„è¯„ä¼°ï¼ˆ0-1ï¼‰
6. **é‡è¦æ€§**: æ´å¯Ÿçš„é‡è¦æ€§ï¼ˆ1-10ï¼‰

## è¾“å‡ºæ ¼å¼
è¯·æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼š

```json
{{
    "insights": [
        {{
            "insight_type": "æ¨¡å¼/è¶‹åŠ¿/è¡Œä¸º/åå¥½",
            "title": "æ´å¯Ÿæ ‡é¢˜",
            "description": "æ´å¯Ÿè¯¦ç»†æè¿°",
            "evidence": ["è¯æ®1", "è¯æ®2"],
            "confidence": 0.8,
            "importance": 8
        }}
    ]
}}
```

è¯·ç¡®ä¿æ´å¯Ÿå…·æœ‰ï¼š
- å®ç”¨æ€§å’Œå¯æ“ä½œæ€§
- åŸºäºæ•°æ®çš„å‡†ç¡®æ€§
- å¯¹æœªæ¥è¡ŒåŠ¨çš„æŒ‡å¯¼ä»·å€¼
- ä½“ç°ç”¨æˆ·å’Œç³»ç»Ÿçš„æ·±å±‚ç‰¹å¾
"""
        
        return prompt
    
    def _parse_insights_response(self, llm_response: str) -> Dict[str, Any]:
        """è§£ææ´å¯Ÿå“åº”"""
        try:
            import re
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', llm_response, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
                return json.loads(json_str)
            else:
                return self._simple_parse_insights_response(llm_response)
        except Exception as e:
            self.logger.error(f"è§£ææ´å¯Ÿå“åº”å¤±è´¥: {e}")
            return self._simple_parse_insights_response(llm_response)
    
    def _simple_parse_insights_response(self, response: str) -> Dict[str, Any]:
        """ç®€å•è§£ææ´å¯Ÿå“åº”"""
        return {
            "insights": [
                {
                    "insight_type": "æ¨¡å¼",
                    "title": "ç”¨æˆ·è¡Œä¸ºæ¨¡å¼",
                    "description": response[:200],
                    "evidence": ["è§‚å¯Ÿæ•°æ®"],
                    "confidence": 0.6,
                    "importance": 6
                }
            ]
        }
    
    def _create_insights_from_data(
        self, 
        insights_data: Dict[str, Any], 
        observations: List[ObservationLog]
    ) -> List[SynthesisInsight]:
        """ä»æ•°æ®åˆ›å»ºæ´å¯Ÿ"""
        insights = []
        
        for insight_data in insights_data.get('insights', []):
            insight = SynthesisInsight(
                id=str(uuid.uuid4()),
                insight_type=insight_data.get('insight_type', 'general'),
                title=insight_data.get('title', 'æœªå‘½åæ´å¯Ÿ'),
                description=insight_data.get('description', ''),
                evidence=insight_data.get('evidence', []),
                confidence=insight_data.get('confidence', 0.5),
                importance=insight_data.get('importance', 5),
                created_at=datetime.now().isoformat(),
                updated_at=datetime.now().isoformat(),
                tags=['synthesis', 'auto_generated'],
                related_observations=[obs.id for obs in observations[:5]],  # å…³è”å‰5ä¸ªè§‚å¯Ÿ
                user_id=observations[0].user_id if observations else 'unknown',
                metadata={
                    'synthesis_method': 'llm_generated',
                    'observation_count': len(observations)
                }
            )
            insights.append(insight)
        
        return insights
    
    def _create_default_insights(self, observations: List[ObservationLog]) -> List[SynthesisInsight]:
        """åˆ›å»ºé»˜è®¤æ´å¯Ÿ"""
        if not observations:
            return []
        
        # åŸºäºè§‚å¯Ÿæ•°æ®åˆ›å»ºç®€å•æ´å¯Ÿ
        insight = SynthesisInsight(
            id=str(uuid.uuid4()),
            insight_type="æ¨¡å¼",
            title="ç”¨æˆ·è¡Œä¸ºæ¨¡å¼åˆ†æ",
            description=f"åŸºäº {len(observations)} ä¸ªè§‚å¯Ÿçš„ç”¨æˆ·è¡Œä¸ºæ¨¡å¼åˆ†æ",
            evidence=[obs.content for obs in observations[:3]],
            confidence=0.5,
            importance=6,
            created_at=datetime.now().isoformat(),
            updated_at=datetime.now().isoformat(),
            tags=['synthesis', 'default'],
            related_observations=[obs.id for obs in observations[:5]],
            user_id=observations[0].user_id,
            metadata={
                'synthesis_method': 'default_generated',
                'observation_count': len(observations)
            }
        )
        
        return [insight]
    
    async def _store_insight(self, insight: SynthesisInsight):
        """å­˜å‚¨æ´å¯Ÿ"""
        try:
            # å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
            await self.vector_store.add_document(
                id=insight.id,
                content=f"{insight.title}: {insight.description}",
                metadata={
                    "insight_type": insight.insight_type,
                    "confidence": insight.confidence,
                    "importance": insight.importance,
                    "user_id": insight.user_id,
                    "created_at": insight.created_at
                }
            )
            
            # å­˜å‚¨åˆ°æŒä¹…åŒ–å­˜å‚¨
            note = Note(
                id=insight.id,
                user_id=insight.user_id,
                title=f"æ´å¯Ÿ_{insight.title}",
                content=insight.description,
                note_type="synthesis_insight",
                tags=insight.tags,
                metadata={
                    "insight_type": insight.insight_type,
                    "confidence": insight.confidence,
                    "importance": insight.importance,
                    "evidence": insight.evidence,
                    "related_observations": insight.related_observations,
                    "created_at": insight.created_at
                }
            )
            
            await self.storage_manager.save_note(note)
            
        except Exception as e:
            self.logger.error(f"å­˜å‚¨æ´å¯Ÿå¤±è´¥: {e}")
    
    async def _store_synthesis_session(self, session: SynthesisSession):
        """å­˜å‚¨åˆæˆä¼šè¯"""
        try:
            note = Note(
                id=session.id,
                user_id=session.user_id,
                title=f"åˆæˆä¼šè¯_{session.start_time}",
                content=json.dumps(asdict(session), ensure_ascii=False, indent=2),
                note_type="synthesis_session",
                tags=['synthesis', 'session'],
                metadata={
                    "user_id": session.user_id,
                    "start_time": session.start_time,
                    "end_time": session.end_time,
                    "status": session.status,
                    "quality_score": session.quality_score
                }
            )
            
            await self.storage_manager.save_note(note)
            
        except Exception as e:
            self.logger.error(f"å­˜å‚¨åˆæˆä¼šè¯å¤±è´¥: {e}")
    
    def _calculate_synthesis_quality(self, insights: List[SynthesisInsight]) -> float:
        """è®¡ç®—åˆæˆè´¨é‡åˆ†æ•°"""
        try:
            if not insights:
                return 0.0
            
            # åŸºäºæ´å¯Ÿçš„ç½®ä¿¡åº¦å’Œé‡è¦æ€§è®¡ç®—è´¨é‡åˆ†æ•°
            total_score = 0.0
            for insight in insights:
                score = (insight.confidence + insight.importance / 10.0) / 2.0
                total_score += score
            
            quality_score = total_score / len(insights)
            return min(1.0, max(0.0, quality_score))
            
        except Exception as e:
            self.logger.error(f"è®¡ç®—åˆæˆè´¨é‡åˆ†æ•°å¤±è´¥: {e}")
            return 0.5
    
    async def get_user_insights(
        self, 
        user_id: str, 
        limit: int = 10
    ) -> List[SynthesisInsight]:
        """è·å–ç”¨æˆ·æ´å¯Ÿ"""
        try:
            user_insights = [
                insight for insight in self.synthesis_insights.values()
                if insight.user_id == user_id
            ]
            
            # æŒ‰é‡è¦æ€§å’Œç½®ä¿¡åº¦æ’åº
            user_insights.sort(
                key=lambda x: (x.importance, x.confidence), 
                reverse=True
            )
            
            return user_insights[:limit]
            
        except Exception as e:
            self.logger.error(f"è·å–ç”¨æˆ·æ´å¯Ÿå¤±è´¥: {e}")
            return []
    
    async def get_synthesis_summary(self, user_id: str) -> Dict[str, Any]:
        """è·å–åˆæˆæ‘˜è¦"""
        try:
            # ç»Ÿè®¡è§‚å¯Ÿæ•°é‡
            user_observations = [
                obs for obs in self.observation_logs.values()
                if obs.user_id == user_id
            ]
            
            # ç»Ÿè®¡æ´å¯Ÿæ•°é‡
            user_insights = [
                insight for insight in self.synthesis_insights.values()
                if insight.user_id == user_id
            ]
            
            # ç»Ÿè®¡åˆæˆä¼šè¯
            user_sessions = [
                session for session in self.synthesis_sessions.values()
                if session.user_id == user_id
            ]
            
            summary = {
                "user_id": user_id,
                "total_observations": len(user_observations),
                "total_insights": len(user_insights),
                "total_sessions": len(user_sessions),
                "insight_types": {},
                "recent_insights": [],
                "synthesis_quality": 0.0,
                "created_at": datetime.now().isoformat()
            }
            
            # ç»Ÿè®¡æ´å¯Ÿç±»å‹
            for insight in user_insights:
                insight_type = insight.insight_type
                summary["insight_types"][insight_type] = \
                    summary["insight_types"].get(insight_type, 0) + 1
            
            # æœ€è¿‘æ´å¯Ÿ
            recent_insights = sorted(
                user_insights,
                key=lambda x: x.created_at,
                reverse=True
            )[:5]
            summary["recent_insights"] = [
                {
                    "id": i.id,
                    "title": i.title,
                    "type": i.insight_type,
                    "confidence": i.confidence,
                    "importance": i.importance
                }
                for i in recent_insights
            ]
            
            # è®¡ç®—åˆæˆè´¨é‡
            if user_sessions:
                quality_scores = [s.quality_score for s in user_sessions if s.quality_score > 0]
                if quality_scores:
                    summary["synthesis_quality"] = sum(quality_scores) / len(quality_scores)
            
            return summary
            
        except Exception as e:
            self.logger.error(f"è·å–åˆæˆæ‘˜è¦å¤±è´¥: {e}")
            return {"error": str(e)}


# å…¨å±€Generative Agentså®ä¾‹
_global_generative_agents = None

def get_generative_agents() -> GenerativeAgents:
    """è·å–å…¨å±€Generative Agents"""
    global _global_generative_agents
    if _global_generative_agents is None:
        _global_generative_agents = GenerativeAgents()
    return _global_generative_agents


async def log_observation(
    content: str,
    source: str,
    importance: int,
    category: str,
    user_id: str,
    session_id: str,
    agent_name: str,
    tags: List[str] = None,
    metadata: Dict[str, Any] = None
) -> ObservationLog:
    """è®°å½•è§‚å¯Ÿï¼ˆä¾¿æ·å‡½æ•°ï¼‰"""
    agents = get_generative_agents()
    await agents.initialize()
    return await agents.log_observation(
        content, source, importance, category, user_id, session_id, agent_name, tags, metadata
    )


def main():
    """ä¸»å‡½æ•° - ç”¨äºæµ‹è¯•å’Œæ¼”ç¤º"""
    import sys
    
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # åˆ›å»ºGenerative Agents
    agents = GenerativeAgents()
    
    # æ¨¡æ‹Ÿè§‚å¯Ÿè®°å½•æµ‹è¯•
    logger.info("Generative Agentsæœºåˆ¶æµ‹è¯•å®Œæˆ")
    return True


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
