"""
ä¸“å®¶å›¢é˜Ÿç®¡ç†å™¨ - AIç»„å»ºè‡ªå·±çš„ä¸“å®¶å›¢é˜Ÿ
 æ¶æ„çš„Sub-agentä¸“å®¶å›¢é˜Ÿç®¡ç†ç³»ç»Ÿ
"""
import os
import json
import asyncio
import logging
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Union, Tuple, Callable
from dataclasses import dataclass, asdict
from pathlib import Path
import uuid
from enum import Enum

try:
    from ..config.settings import JubenSettings
    from ..utils.logger import JubenLogger
    from ..utils.storage_manager import JubenStorageManager
    from ..utils.llm_client import JubenLLMClient
    from ..utils.performance_monitor import PerformanceMonitor, get_performance_monitor
except ImportError:
    import sys
    from pathlib import Path
    sys.path.insert(0, str(Path(__file__).parent.parent))
    
    from config.settings import JubenSettings
    from utils.logger import JubenLogger
    from utils.storage_manager import JubenStorageManager
    from utils.llm_client import JubenLLMClient
    from utils.performance_monitor import PerformanceMonitor, get_performance_monitor


class ExpertType(Enum):
    """ä¸“å®¶ç±»å‹"""
    ANALYST = "analyst"  # åˆ†æå¸ˆ
    CREATOR = "creator"  # åˆ›ä½œè€…
    EVALUATOR = "evaluator"  # è¯„ä¼°å¸ˆ
    RESEARCHER = "researcher"  # ç ”ç©¶å‘˜
    COORDINATOR = "coordinator"  # åè°ƒå‘˜
    SPECIALIST = "specialist"  # ä¸“ä¸šå¸ˆ


class TaskStatus(Enum):
    """ä»»åŠ¡çŠ¶æ€"""
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"


@dataclass
class ExpertProfile:
    """ä¸“å®¶æ¡£æ¡ˆ"""
    id: str
    name: str
    expert_type: ExpertType
    specialization: List[str]
    capabilities: List[str]
    experience_level: int  # 1-10
    success_rate: float  # 0-1
    response_time: float  # å¹³å‡å“åº”æ—¶é—´ï¼ˆç§’ï¼‰
    availability: bool
    current_workload: int  # å½“å‰å·¥ä½œè´Ÿè½½
    max_workload: int  # æœ€å¤§å·¥ä½œè´Ÿè½½
    created_at: str = ""
    last_active: str = ""
    metadata: Dict[str, Any] = None
    
    def __post_init__(self):
        if not self.created_at:
            self.created_at = datetime.now().isoformat()
        if not self.last_active:
            self.last_active = datetime.now().isoformat()
        if self.metadata is None:
            self.metadata = {}


@dataclass
class TeamTask:
    """å›¢é˜Ÿä»»åŠ¡"""
    id: str
    title: str
    description: str
    task_type: str
    priority: int  # 1-10
    assigned_expert: Optional[str] = None
    status: TaskStatus = TaskStatus.PENDING
    created_at: str = ""
    started_at: Optional[str] = None
    completed_at: Optional[str] = None
    result: Optional[Dict[str, Any]] = None
    error_message: Optional[str] = None
    dependencies: List[str] = None
    estimated_duration: float = 0.0  # é¢„è®¡æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
    actual_duration: float = 0.0  # å®é™…æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
    metadata: Dict[str, Any] = None
    
    def __post_init__(self):
        if not self.created_at:
            self.created_at = datetime.now().isoformat()
        if self.dependencies is None:
            self.dependencies = []
        if self.metadata is None:
            self.metadata = {}


@dataclass
class TeamCollaboration:
    """å›¢é˜Ÿåä½œ"""
    id: str
    session_id: str
    user_id: str
    main_agent: str
    participating_experts: List[str]
    collaboration_type: str  # parallel, sequential, hierarchical
    status: str
    created_at: str = ""
    completed_at: Optional[str] = None
    results: Dict[str, Any] = None
    coordination_strategy: str = ""
    metadata: Dict[str, Any] = None
    
    def __post_init__(self):
        if not self.created_at:
            self.created_at = datetime.now().isoformat()
        if self.results is None:
            self.results = {}
        if self.metadata is None:
            self.metadata = {}


class ExpertTeamManager:
    """ä¸“å®¶å›¢é˜Ÿç®¡ç†å™¨"""
    
    def __init__(self, model_provider: str = "zhipu"):
        """
        åˆå§‹åŒ–ä¸“å®¶å›¢é˜Ÿç®¡ç†å™¨
        
        Args:
            model_provider: æ¨¡å‹æä¾›å•†
        """
        self.config = JubenSettings()
        self.logger = JubenLogger("ExpertTeamManager", level=self.config.log_level)
        self.storage_manager = JubenStorageManager()
        self.llm_client = JubenLLMClient(model_provider)
        self.performance_monitor = get_performance_monitor()
        
        # ä¸“å®¶å›¢é˜Ÿ
        self.experts: Dict[str, ExpertProfile] = {}
        self.active_tasks: Dict[str, TeamTask] = {}
        self.collaborations: Dict[str, TeamCollaboration] = {}
        
        # å›¢é˜Ÿé…ç½®
        self.team_config = {
            "max_parallel_tasks": 5,
            "task_timeout": 300,  # 5åˆ†é’Ÿ
            "expert_rotation": True,
            "load_balancing": True,
            "quality_threshold": 0.8
        }
        
        # ä¸“å®¶æ³¨å†Œè¡¨
        self.expert_registry: Dict[str, Callable] = {}
        
        self.logger.info("ä¸“å®¶å›¢é˜Ÿç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def initialize(self):
        """åˆå§‹åŒ–å›¢é˜Ÿç®¡ç†å™¨"""
        try:
            await self.storage_manager.initialize()
            await self._initialize_expert_team()
            self.logger.info("âœ… ä¸“å®¶å›¢é˜Ÿç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            self.logger.error(f"âŒ ä¸“å®¶å›¢é˜Ÿç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    async def _initialize_expert_team(self):
        """åˆå§‹åŒ–ä¸“å®¶å›¢é˜Ÿ"""
        try:
            # åˆ›å»ºæ ¸å¿ƒä¸“å®¶å›¢é˜Ÿ
            experts = [
                ExpertProfile(
                    id="story_analyst",
                    name="æ•…äº‹åˆ†æå¸ˆ",
                    expert_type=ExpertType.ANALYST,
                    specialization=["æ•…äº‹ç»“æ„", "æƒ…èŠ‚åˆ†æ", "è§’è‰²å‘å±•"],
                    capabilities=["æ–‡æœ¬åˆ†æ", "ç»“æ„è¯„ä¼°", "è¶‹åŠ¿é¢„æµ‹"],
                    experience_level=9,
                    success_rate=0.95,
                    response_time=2.5,
                    availability=True,
                    current_workload=0,
                    max_workload=3
                ),
                ExpertProfile(
                    id="content_creator",
                    name="å†…å®¹åˆ›ä½œè€…",
                    expert_type=ExpertType.CREATOR,
                    specialization=["å‰§æœ¬åˆ›ä½œ", "å¯¹è¯ç¼–å†™", "åœºæ™¯æè¿°"],
                    capabilities=["åˆ›æ„ç”Ÿæˆ", "å†…å®¹åˆ›ä½œ", "é£æ ¼é€‚é…"],
                    experience_level=8,
                    success_rate=0.92,
                    response_time=3.0,
                    availability=True,
                    current_workload=0,
                    max_workload=2
                ),
                ExpertProfile(
                    id="quality_evaluator",
                    name="è´¨é‡è¯„ä¼°å¸ˆ",
                    expert_type=ExpertType.EVALUATOR,
                    specialization=["è´¨é‡è¯„ä¼°", "æ ‡å‡†æ£€æŸ¥", "æ”¹è¿›å»ºè®®"],
                    capabilities=["è´¨é‡åˆ†æ", "æ ‡å‡†è¯„ä¼°", "ä¼˜åŒ–å»ºè®®"],
                    experience_level=9,
                    success_rate=0.98,
                    response_time=1.8,
                    availability=True,
                    current_workload=0,
                    max_workload=4
                ),
                ExpertProfile(
                    id="research_specialist",
                    name="ç ”ç©¶ä¸“å®¶",
                    expert_type=ExpertType.RESEARCHER,
                    specialization=["å¸‚åœºç ”ç©¶", "ç”¨æˆ·åˆ†æ", "ç«å“åˆ†æ"],
                    capabilities=["æ•°æ®æ”¶é›†", "è¶‹åŠ¿åˆ†æ", "æ´å¯Ÿæå–"],
                    experience_level=8,
                    success_rate=0.90,
                    response_time=4.0,
                    availability=True,
                    current_workload=0,
                    max_workload=2
                ),
                ExpertProfile(
                    id="team_coordinator",
                    name="å›¢é˜Ÿåè°ƒå‘˜",
                    expert_type=ExpertType.COORDINATOR,
                    specialization=["ä»»åŠ¡åˆ†é…", "è¿›åº¦ç®¡ç†", "èµ„æºåè°ƒ"],
                    capabilities=["é¡¹ç›®ç®¡ç†", "å›¢é˜Ÿåè°ƒ", "æµç¨‹ä¼˜åŒ–"],
                    experience_level=10,
                    success_rate=0.96,
                    response_time=1.5,
                    availability=True,
                    current_workload=0,
                    max_workload=5
                )
            ]
            
            # æ³¨å†Œä¸“å®¶
            for expert in experts:
                self.experts[expert.id] = expert
                self.logger.info(f"ğŸ‘¨â€ğŸ’¼ æ³¨å†Œä¸“å®¶: {expert.name} ({expert.expert_type.value})")
            
            self.logger.info(f"âœ… ä¸“å®¶å›¢é˜Ÿåˆå§‹åŒ–å®Œæˆ: {len(self.experts)} ä½ä¸“å®¶")
            
        except Exception as e:
            self.logger.error(f"åˆå§‹åŒ–ä¸“å®¶å›¢é˜Ÿå¤±è´¥: {e}")
            raise
    
    async def create_expert_team(
        self,
        user_id: str,
        session_id: str,
        main_agent: str,
        task_description: str,
        collaboration_type: str = "parallel"
    ) -> TeamCollaboration:
        """
        åˆ›å»ºä¸“å®¶å›¢é˜Ÿ
        
        Args:
            user_id: ç”¨æˆ·ID
            session_id: ä¼šè¯ID
            main_agent: ä¸»Agent
            task_description: ä»»åŠ¡æè¿°
            collaboration_type: åä½œç±»å‹
            
        Returns:
            å›¢é˜Ÿåä½œå¯¹è±¡
        """
        try:
            self.logger.info(f"ğŸ‘¥ åˆ›å»ºä¸“å®¶å›¢é˜Ÿ: {user_id}/{session_id}")
            
            # åˆ†æä»»åŠ¡éœ€æ±‚
            task_analysis = await self._analyze_task_requirements(task_description)
            
            # é€‰æ‹©ä¸“å®¶å›¢é˜Ÿ
            selected_experts = await self._select_expert_team(task_analysis)
            
            # åˆ›å»ºå›¢é˜Ÿåä½œ
            collaboration_id = str(uuid.uuid4())
            collaboration = TeamCollaboration(
                id=collaboration_id,
                session_id=session_id,
                user_id=user_id,
                main_agent=main_agent,
                participating_experts=selected_experts,
                collaboration_type=collaboration_type,
                status="active",
                coordination_strategy=self._determine_coordination_strategy(
                    collaboration_type, len(selected_experts)
                ),
                metadata={
                    "task_description": task_description,
                    "task_analysis": task_analysis,
                    "created_by": main_agent
                }
            )
            
            self.collaborations[collaboration_id] = collaboration
            
            # æ›´æ–°ä¸“å®¶å·¥ä½œè´Ÿè½½
            for expert_id in selected_experts:
                if expert_id in self.experts:
                    self.experts[expert_id].current_workload += 1
                    self.experts[expert_id].last_active = datetime.now().isoformat()
            
            self.logger.info(f"âœ… ä¸“å®¶å›¢é˜Ÿåˆ›å»ºæˆåŠŸ: {len(selected_experts)} ä½ä¸“å®¶å‚ä¸")
            return collaboration
            
        except Exception as e:
            self.logger.error(f"âŒ åˆ›å»ºä¸“å®¶å›¢é˜Ÿå¤±è´¥: {e}")
            raise
    
    async def _analyze_task_requirements(self, task_description: str) -> Dict[str, Any]:
        """åˆ†æä»»åŠ¡éœ€æ±‚"""
        try:
            # æ„å»ºä»»åŠ¡åˆ†ææç¤ºè¯
            prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»»åŠ¡åˆ†æä¸“å®¶ï¼Œéœ€è¦åˆ†æä»»åŠ¡éœ€æ±‚å¹¶ç¡®å®šæ‰€éœ€çš„ä¸“å®¶ç±»å‹ã€‚

## ä»»åŠ¡æè¿°
{task_description}

## åˆ†æè¦æ±‚
è¯·åˆ†æè¿™ä¸ªä»»åŠ¡éœ€è¦å“ªäº›ç±»å‹çš„ä¸“å®¶ï¼Œå¹¶æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š

```json
{{
    "required_expert_types": ["analyst", "creator", "evaluator"],
    "task_complexity": 8,
    "estimated_duration": 300,
    "parallel_possible": true,
    "dependencies": ["research", "analysis"],
    "quality_requirements": "high",
    "special_requirements": ["åˆ›æ„èƒ½åŠ›", "åˆ†æèƒ½åŠ›"]
}}
```

è¯·ç¡®ä¿åˆ†æå‡†ç¡®ï¼Œèƒ½å¤ŸæŒ‡å¯¼ä¸“å®¶å›¢é˜Ÿçš„é€‰æ‹©ã€‚
"""
            
            # è°ƒç”¨LLMåˆ†æ
            response = await self.llm_client.generate_response(
                prompt=prompt,
                max_tokens=1000,
                temperature=0.3
            )
            
            if response and response.get('content'):
                # è§£æLLMå“åº”
                return self._parse_task_analysis(response['content'])
            else:
                # ä½¿ç”¨é»˜è®¤åˆ†æ
                return self._default_task_analysis(task_description)
                
        except Exception as e:
            self.logger.error(f"åˆ†æä»»åŠ¡éœ€æ±‚å¤±è´¥: {e}")
            return self._default_task_analysis(task_description)
    
    def _parse_task_analysis(self, llm_response: str) -> Dict[str, Any]:
        """è§£æä»»åŠ¡åˆ†æç»“æœ"""
        try:
            import re
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', llm_response, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
                return json.loads(json_str)
            else:
                return self._default_task_analysis("")
        except Exception as e:
            self.logger.error(f"è§£æä»»åŠ¡åˆ†æå¤±è´¥: {e}")
            return self._default_task_analysis("")
    
    def _default_task_analysis(self, task_description: str) -> Dict[str, Any]:
        """é»˜è®¤ä»»åŠ¡åˆ†æ"""
        return {
            "required_expert_types": ["analyst", "evaluator"],
            "task_complexity": 5,
            "estimated_duration": 180,
            "parallel_possible": True,
            "dependencies": [],
            "quality_requirements": "medium",
            "special_requirements": []
        }
    
    async def _select_expert_team(self, task_analysis: Dict[str, Any]) -> List[str]:
        """é€‰æ‹©ä¸“å®¶å›¢é˜Ÿ"""
        try:
            required_types = task_analysis.get('required_expert_types', [])
            selected_experts = []
            
            # æ ¹æ®éœ€æ±‚é€‰æ‹©ä¸“å®¶
            for expert_id, expert in self.experts.items():
                if not expert.availability:
                    continue
                
                if expert.current_workload >= expert.max_workload:
                    continue
                
                # æ£€æŸ¥ä¸“å®¶ç±»å‹æ˜¯å¦åŒ¹é…
                if expert.expert_type.value in required_types:
                    selected_experts.append(expert_id)
                elif expert.expert_type == ExpertType.COORDINATOR:
                    # åè°ƒå‘˜æ€»æ˜¯éœ€è¦çš„
                    selected_experts.append(expert_id)
            
            # ç¡®ä¿è‡³å°‘æœ‰ä¸€ä¸ªä¸“å®¶
            if not selected_experts:
                # é€‰æ‹©æœ€å¯ç”¨çš„ä¸“å®¶
                available_experts = [
                    (expert_id, expert) for expert_id, expert in self.experts.items()
                    if expert.availability and expert.current_workload < expert.max_workload
                ]
                if available_experts:
                    # æŒ‰æˆåŠŸç‡æ’åº
                    available_experts.sort(key=lambda x: x[1].success_rate, reverse=True)
                    selected_experts.append(available_experts[0][0])
            
            self.logger.info(f"ğŸ¯ é€‰æ‹©ä¸“å®¶å›¢é˜Ÿ: {selected_experts}")
            return selected_experts
            
        except Exception as e:
            self.logger.error(f"é€‰æ‹©ä¸“å®¶å›¢é˜Ÿå¤±è´¥: {e}")
            return []
    
    def _determine_coordination_strategy(self, collaboration_type: str, expert_count: int) -> str:
        """ç¡®å®šåè°ƒç­–ç•¥"""
        if collaboration_type == "parallel":
            return "å¹¶è¡Œå¤„ç†ï¼Œç»“æœæ•´åˆ"
        elif collaboration_type == "sequential":
            return "é¡ºåºå¤„ç†ï¼Œæµæ°´çº¿ä½œä¸š"
        elif collaboration_type == "hierarchical":
            return "åˆ†å±‚å¤„ç†ï¼Œä¸»ä»åè°ƒ"
        else:
            return "è‡ªé€‚åº”åè°ƒ"
    
    async def assign_task_to_expert(
        self,
        collaboration_id: str,
        task_title: str,
        task_description: str,
        expert_id: str,
        priority: int = 5
    ) -> TeamTask:
        """
        åˆ†é…ä»»åŠ¡ç»™ä¸“å®¶
        
        Args:
            collaboration_id: åä½œID
            task_title: ä»»åŠ¡æ ‡é¢˜
            task_description: ä»»åŠ¡æè¿°
            expert_id: ä¸“å®¶ID
            priority: ä¼˜å…ˆçº§
            
        Returns:
            ä»»åŠ¡å¯¹è±¡
        """
        try:
            # åˆ›å»ºä»»åŠ¡
            task_id = str(uuid.uuid4())
            task = TeamTask(
                id=task_id,
                title=task_title,
                description=task_description,
                task_type="expert_task",
                priority=priority,
                assigned_expert=expert_id,
                status=TaskStatus.PENDING,
                estimated_duration=self._estimate_task_duration(task_description, expert_id),
                metadata={
                    "collaboration_id": collaboration_id,
                    "created_by": "team_manager"
                }
            )
            
            self.active_tasks[task_id] = task
            
            # æ›´æ–°ä¸“å®¶çŠ¶æ€
            if expert_id in self.experts:
                self.experts[expert_id].current_workload += 1
                self.experts[expert_id].last_active = datetime.now().isoformat()
            
            self.logger.info(f"ğŸ“‹ ä»»åŠ¡å·²åˆ†é…: {task_title} -> {expert_id}")
            return task
            
        except Exception as e:
            self.logger.error(f"åˆ†é…ä»»åŠ¡å¤±è´¥: {e}")
            raise
    
    def _estimate_task_duration(self, task_description: str, expert_id: str) -> float:
        """ä¼°ç®—ä»»åŠ¡æŒç»­æ—¶é—´"""
        try:
            if expert_id in self.experts:
                expert = self.experts[expert_id]
                base_duration = expert.response_time
                
                # æ ¹æ®ä»»åŠ¡å¤æ‚åº¦è°ƒæ•´
                complexity_factor = len(task_description) / 100  # åŸºäºæè¿°é•¿åº¦
                estimated_duration = base_duration * (1 + complexity_factor)
                
                return min(estimated_duration, 300)  # æœ€å¤š5åˆ†é’Ÿ
            else:
                return 60.0  # é»˜è®¤1åˆ†é’Ÿ
                
        except Exception as e:
            self.logger.error(f"ä¼°ç®—ä»»åŠ¡æŒç»­æ—¶é—´å¤±è´¥: {e}")
            return 60.0
    
    async def execute_expert_task(
        self,
        task_id: str,
        input_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œä¸“å®¶ä»»åŠ¡
        
        Args:
            task_id: ä»»åŠ¡ID
            input_data: è¾“å…¥æ•°æ®
            
        Returns:
            ä»»åŠ¡ç»“æœ
        """
        try:
            if task_id not in self.active_tasks:
                raise ValueError(f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
            
            task = self.active_tasks[task_id]
            expert_id = task.assigned_expert
            
            if not expert_id or expert_id not in self.experts:
                raise ValueError(f"ä¸“å®¶ä¸å­˜åœ¨: {expert_id}")
            
            expert = self.experts[expert_id]
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€
            task.status = TaskStatus.IN_PROGRESS
            task.started_at = datetime.now().isoformat()
            
            self.logger.info(f"ğŸš€ å¼€å§‹æ‰§è¡Œä»»åŠ¡: {task.title} (ä¸“å®¶: {expert.name})")
            
            # è®°å½•æ€§èƒ½ç›‘æ§
            with self.performance_monitor.monitor_performance(
                "ExpertTeamManager", 
                f"execute_task_{expert_id}",
                {"task_id": task_id, "expert": expert.name}
            ):
                # æ‰§è¡Œä¸“å®¶ä»»åŠ¡
                result = await self._execute_expert_workflow(
                    expert, task, input_data
                )
            
            # æ›´æ–°ä»»åŠ¡ç»“æœ
            task.status = TaskStatus.COMPLETED
            task.completed_at = datetime.now().isoformat()
            task.result = result
            task.actual_duration = (
                datetime.fromisoformat(task.completed_at) - 
                datetime.fromisoformat(task.started_at)
            ).total_seconds()
            
            # æ›´æ–°ä¸“å®¶ç»Ÿè®¡
            expert.current_workload = max(0, expert.current_workload - 1)
            expert.last_active = datetime.now().isoformat()
            
            # æ›´æ–°æˆåŠŸç‡
            if result.get('success', False):
                expert.success_rate = (expert.success_rate * 0.9) + 0.1
            else:
                expert.success_rate = expert.success_rate * 0.95
            
            self.logger.info(f"âœ… ä»»åŠ¡æ‰§è¡Œå®Œæˆ: {task.title}")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ æ‰§è¡Œä¸“å®¶ä»»åŠ¡å¤±è´¥: {e}")
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€
            if task_id in self.active_tasks:
                task = self.active_tasks[task_id]
                task.status = TaskStatus.FAILED
                task.error_message = str(e)
                task.completed_at = datetime.now().isoformat()
            
            return {"success": False, "error": str(e)}
    
    async def _execute_expert_workflow(
        self,
        expert: ExpertProfile,
        task: TeamTask,
        input_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """æ‰§è¡Œä¸“å®¶å·¥ä½œæµ"""
        try:
            # æ ¹æ®ä¸“å®¶ç±»å‹é€‰æ‹©æ‰§è¡Œç­–ç•¥
            if expert.expert_type == ExpertType.ANALYST:
                return await self._execute_analyst_workflow(expert, task, input_data)
            elif expert.expert_type == ExpertType.CREATOR:
                return await self._execute_creator_workflow(expert, task, input_data)
            elif expert.expert_type == ExpertType.EVALUATOR:
                return await self._execute_evaluator_workflow(expert, task, input_data)
            elif expert.expert_type == ExpertType.RESEARCHER:
                return await self._execute_researcher_workflow(expert, task, input_data)
            elif expert.expert_type == ExpertType.COORDINATOR:
                return await self._execute_coordinator_workflow(expert, task, input_data)
            else:
                return await self._execute_generic_workflow(expert, task, input_data)
                
        except Exception as e:
            self.logger.error(f"æ‰§è¡Œä¸“å®¶å·¥ä½œæµå¤±è´¥: {e}")
            return {"success": False, "error": str(e)}
    
    async def _execute_analyst_workflow(
        self,
        expert: ExpertProfile,
        task: TeamTask,
        input_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """æ‰§è¡Œåˆ†æå¸ˆå·¥ä½œæµ"""
        try:
            # æ„å»ºåˆ†ææç¤ºè¯
            prompt = f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„{expert.specialization[0]}ï¼Œè¯·åˆ†æä»¥ä¸‹å†…å®¹ï¼š

ä»»åŠ¡: {task.title}
æè¿°: {task.description}
è¾“å…¥æ•°æ®: {input_data}

è¯·æä¾›ä¸“ä¸šçš„åˆ†æç»“æœï¼ŒåŒ…æ‹¬ï¼š
1. æ ¸å¿ƒå‘ç°
2. å…³é”®æ´å¯Ÿ
3. å»ºè®®å’Œæ¨è
4. é£é™©è¯„ä¼°

è¯·ç¡®ä¿åˆ†æä¸“ä¸šã€æ·±å…¥ã€å®ç”¨ã€‚
"""
            
            # è°ƒç”¨LLMè¿›è¡Œåˆ†æ
            response = await self.llm_client.generate_response(
                prompt=prompt,
                max_tokens=2000,
                temperature=0.3
            )
            
            if response and response.get('content'):
                return {
                    "success": True,
                    "expert_type": expert.expert_type.value,
                    "expert_name": expert.name,
                    "analysis_result": response['content'],
                    "confidence": expert.success_rate,
                    "execution_time": task.actual_duration
                }
            else:
                return {
                    "success": False,
                    "error": "åˆ†æå¤±è´¥ï¼šæ— æ³•ç”Ÿæˆåˆ†æç»“æœ"
                }
                
        except Exception as e:
            self.logger.error(f"åˆ†æå¸ˆå·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
            return {"success": False, "error": str(e)}
    
    async def _execute_creator_workflow(
        self,
        expert: ExpertProfile,
        task: TeamTask,
        input_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """æ‰§è¡Œåˆ›ä½œè€…å·¥ä½œæµ"""
        try:
            # æ„å»ºåˆ›ä½œæç¤ºè¯
            prompt = f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„{expert.specialization[0]}ï¼Œè¯·åˆ›ä½œä»¥ä¸‹å†…å®¹ï¼š

ä»»åŠ¡: {task.title}
æè¿°: {task.description}
è¾“å…¥æ•°æ®: {input_data}

è¯·æä¾›é«˜è´¨é‡çš„åˆ›ä½œå†…å®¹ï¼ŒåŒ…æ‹¬ï¼š
1. åˆ›æ„æ„æ€
2. å†…å®¹åˆ›ä½œ
3. é£æ ¼é€‚é…
4. è´¨é‡æ£€æŸ¥

è¯·ç¡®ä¿åˆ›ä½œå†…å®¹ä¸“ä¸šã€åˆ›æ–°ã€å®ç”¨ã€‚
"""
            
            # è°ƒç”¨LLMè¿›è¡Œåˆ›ä½œ
            response = await self.llm_client.generate_response(
                prompt=prompt,
                max_tokens=3000,
                temperature=0.7
            )
            
            if response and response.get('content'):
                return {
                    "success": True,
                    "expert_type": expert.expert_type.value,
                    "expert_name": expert.name,
                    "creation_result": response['content'],
                    "confidence": expert.success_rate,
                    "execution_time": task.actual_duration
                }
            else:
                return {
                    "success": False,
                    "error": "åˆ›ä½œå¤±è´¥ï¼šæ— æ³•ç”Ÿæˆåˆ›ä½œå†…å®¹"
                }
                
        except Exception as e:
            self.logger.error(f"åˆ›ä½œè€…å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
            return {"success": False, "error": str(e)}
    
    async def _execute_evaluator_workflow(
        self,
        expert: ExpertProfile,
        task: TeamTask,
        input_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """æ‰§è¡Œè¯„ä¼°å¸ˆå·¥ä½œæµ"""
        try:
            # æ„å»ºè¯„ä¼°æç¤ºè¯
            prompt = f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„{expert.specialization[0]}ï¼Œè¯·è¯„ä¼°ä»¥ä¸‹å†…å®¹ï¼š

ä»»åŠ¡: {task.title}
æè¿°: {task.description}
è¾“å…¥æ•°æ®: {input_data}

è¯·æä¾›ä¸“ä¸šçš„è¯„ä¼°ç»“æœï¼ŒåŒ…æ‹¬ï¼š
1. è´¨é‡è¯„åˆ†ï¼ˆ1-10åˆ†ï¼‰
2. ä¼˜åŠ¿åˆ†æ
3. æ”¹è¿›å»ºè®®
4. æ€»ä½“è¯„ä»·

è¯·ç¡®ä¿è¯„ä¼°å®¢è§‚ã€ä¸“ä¸šã€å®ç”¨ã€‚
"""
            
            # è°ƒç”¨LLMè¿›è¡Œè¯„ä¼°
            response = await self.llm_client.generate_response(
                prompt=prompt,
                max_tokens=2000,
                temperature=0.2
            )
            
            if response and response.get('content'):
                return {
                    "success": True,
                    "expert_type": expert.expert_type.value,
                    "expert_name": expert.name,
                    "evaluation_result": response['content'],
                    "confidence": expert.success_rate,
                    "execution_time": task.actual_duration
                }
            else:
                return {
                    "success": False,
                    "error": "è¯„ä¼°å¤±è´¥ï¼šæ— æ³•ç”Ÿæˆè¯„ä¼°ç»“æœ"
                }
                
        except Exception as e:
            self.logger.error(f"è¯„ä¼°å¸ˆå·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
            return {"success": False, "error": str(e)}
    
    async def _execute_researcher_workflow(
        self,
        expert: ExpertProfile,
        task: TeamTask,
        input_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """æ‰§è¡Œç ”ç©¶å‘˜å·¥ä½œæµ"""
        try:
            # æ„å»ºç ”ç©¶æç¤ºè¯
            prompt = f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„{expert.specialization[0]}ï¼Œè¯·ç ”ç©¶ä»¥ä¸‹å†…å®¹ï¼š

ä»»åŠ¡: {task.title}
æè¿°: {task.description}
è¾“å…¥æ•°æ®: {input_data}

è¯·æä¾›ä¸“ä¸šçš„ç ”ç©¶ç»“æœï¼ŒåŒ…æ‹¬ï¼š
1. ç ”ç©¶èƒŒæ™¯
2. å…³é”®å‘ç°
3. æ•°æ®æ´å¯Ÿ
4. è¶‹åŠ¿åˆ†æ

è¯·ç¡®ä¿ç ”ç©¶æ·±å…¥ã€å‡†ç¡®ã€æœ‰ä»·å€¼ã€‚
"""
            
            # è°ƒç”¨LLMè¿›è¡Œç ”ç©¶
            response = await self.llm_client.generate_response(
                prompt=prompt,
                max_tokens=2500,
                temperature=0.4
            )
            
            if response and response.get('content'):
                return {
                    "success": True,
                    "expert_type": expert.expert_type.value,
                    "expert_name": expert.name,
                    "research_result": response['content'],
                    "confidence": expert.success_rate,
                    "execution_time": task.actual_duration
                }
            else:
                return {
                    "success": False,
                    "error": "ç ”ç©¶å¤±è´¥ï¼šæ— æ³•ç”Ÿæˆç ”ç©¶ç»“æœ"
                }
                
        except Exception as e:
            self.logger.error(f"ç ”ç©¶å‘˜å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
            return {"success": False, "error": str(e)}
    
    async def _execute_coordinator_workflow(
        self,
        expert: ExpertProfile,
        task: TeamTask,
        input_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """æ‰§è¡Œåè°ƒå‘˜å·¥ä½œæµ"""
        try:
            # æ„å»ºåè°ƒæç¤ºè¯
            prompt = f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„{expert.specialization[0]}ï¼Œè¯·åè°ƒä»¥ä¸‹ä»»åŠ¡ï¼š

ä»»åŠ¡: {task.title}
æè¿°: {task.description}
è¾“å…¥æ•°æ®: {input_data}

è¯·æä¾›ä¸“ä¸šçš„åè°ƒç»“æœï¼ŒåŒ…æ‹¬ï¼š
1. ä»»åŠ¡åˆ†è§£
2. èµ„æºåˆ†é…
3. è¿›åº¦è§„åˆ’
4. é£é™©æ§åˆ¶

è¯·ç¡®ä¿åè°ƒé«˜æ•ˆã€åˆç†ã€å¯è¡Œã€‚
"""
            
            # è°ƒç”¨LLMè¿›è¡Œåè°ƒ
            response = await self.llm_client.generate_response(
                prompt=prompt,
                max_tokens=2000,
                temperature=0.3
            )
            
            if response and response.get('content'):
                return {
                    "success": True,
                    "expert_type": expert.expert_type.value,
                    "expert_name": expert.name,
                    "coordination_result": response['content'],
                    "confidence": expert.success_rate,
                    "execution_time": task.actual_duration
                }
            else:
                return {
                    "success": False,
                    "error": "åè°ƒå¤±è´¥ï¼šæ— æ³•ç”Ÿæˆåè°ƒç»“æœ"
                }
                
        except Exception as e:
            self.logger.error(f"åè°ƒå‘˜å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
            return {"success": False, "error": str(e)}
    
    async def _execute_generic_workflow(
        self,
        expert: ExpertProfile,
        task: TeamTask,
        input_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """æ‰§è¡Œé€šç”¨å·¥ä½œæµ"""
        try:
            # æ„å»ºé€šç”¨æç¤ºè¯
            prompt = f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„{expert.name}ï¼Œè¯·å¤„ç†ä»¥ä¸‹ä»»åŠ¡ï¼š

ä»»åŠ¡: {task.title}
æè¿°: {task.description}
è¾“å…¥æ•°æ®: {input_data}

è¯·æä¾›ä¸“ä¸šçš„å¤„ç†ç»“æœï¼Œç¡®ä¿è´¨é‡é«˜ã€å®ç”¨æ€§å¼ºã€‚
"""
            
            # è°ƒç”¨LLMè¿›è¡Œå¤„ç†
            response = await self.llm_client.generate_response(
                prompt=prompt,
                max_tokens=2000,
                temperature=0.5
            )
            
            if response and response.get('content'):
                return {
                    "success": True,
                    "expert_type": expert.expert_type.value,
                    "expert_name": expert.name,
                    "processing_result": response['content'],
                    "confidence": expert.success_rate,
                    "execution_time": task.actual_duration
                }
            else:
                return {
                    "success": False,
                    "error": "å¤„ç†å¤±è´¥ï¼šæ— æ³•ç”Ÿæˆå¤„ç†ç»“æœ"
                }
                
        except Exception as e:
            self.logger.error(f"é€šç”¨å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
            return {"success": False, "error": str(e)}
    
    async def get_team_status(self) -> Dict[str, Any]:
        """è·å–å›¢é˜ŸçŠ¶æ€"""
        try:
            # ç»Ÿè®¡ä¸“å®¶çŠ¶æ€
            total_experts = len(self.experts)
            available_experts = sum(1 for expert in self.experts.values() if expert.availability)
            busy_experts = sum(1 for expert in self.experts.values() if expert.current_workload > 0)
            
            # ç»Ÿè®¡ä»»åŠ¡çŠ¶æ€
            total_tasks = len(self.active_tasks)
            pending_tasks = sum(1 for task in self.active_tasks.values() if task.status == TaskStatus.PENDING)
            in_progress_tasks = sum(1 for task in self.active_tasks.values() if task.status == TaskStatus.IN_PROGRESS)
            completed_tasks = sum(1 for task in self.active_tasks.values() if task.status == TaskStatus.COMPLETED)
            failed_tasks = sum(1 for task in self.active_tasks.values() if task.status == TaskStatus.FAILED)
            
            # ç»Ÿè®¡åä½œçŠ¶æ€
            total_collaborations = len(self.collaborations)
            active_collaborations = sum(1 for collab in self.collaborations.values() if collab.status == "active")
            
            return {
                "team_status": {
                    "total_experts": total_experts,
                    "available_experts": available_experts,
                    "busy_experts": busy_experts,
                    "utilization_rate": busy_experts / total_experts if total_experts > 0 else 0
                },
                "task_status": {
                    "total_tasks": total_tasks,
                    "pending_tasks": pending_tasks,
                    "in_progress_tasks": in_progress_tasks,
                    "completed_tasks": completed_tasks,
                    "failed_tasks": failed_tasks,
                    "success_rate": completed_tasks / total_tasks if total_tasks > 0 else 0
                },
                "collaboration_status": {
                    "total_collaborations": total_collaborations,
                    "active_collaborations": active_collaborations
                },
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"è·å–å›¢é˜ŸçŠ¶æ€å¤±è´¥: {e}")
            return {"error": str(e)}


# å…¨å±€ä¸“å®¶å›¢é˜Ÿç®¡ç†å™¨å®ä¾‹
_global_team_manager = None

def get_expert_team_manager() -> ExpertTeamManager:
    """è·å–å…¨å±€ä¸“å®¶å›¢é˜Ÿç®¡ç†å™¨"""
    global _global_team_manager
    if _global_team_manager is None:
        _global_team_manager = ExpertTeamManager()
    return _global_team_manager

async def create_expert_team(
    user_id: str,
    session_id: str,
    main_agent: str,
    task_description: str,
    collaboration_type: str = "parallel"
) -> TeamCollaboration:
    """åˆ›å»ºä¸“å®¶å›¢é˜Ÿï¼ˆä¾¿æ·å‡½æ•°ï¼‰"""
    manager = get_expert_team_manager()
    await manager.initialize()
    return await manager.create_expert_team(user_id, session_id, main_agent, task_description, collaboration_type)


def main():
    """ä¸»å‡½æ•° - ç”¨äºæµ‹è¯•å’Œæ¼”ç¤º"""
    import sys
    
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # åˆ›å»ºä¸“å®¶å›¢é˜Ÿç®¡ç†å™¨
    manager = ExpertTeamManager()
    
    # æ¨¡æ‹Ÿå›¢é˜Ÿç®¡ç†æµ‹è¯•
    logger.info("ä¸“å®¶å›¢é˜Ÿç®¡ç†å™¨æµ‹è¯•å®Œæˆ")
    return True


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
