"""
å¢å¼ºç‰ˆè®°å¿†ç®¡ç†å™¨
ç®¡ç†ç”¨æˆ·ç”»åƒã€é£æ ¼å‘é‡åº“å’ŒåŒå±‚è®°å¿†ç³»ç»Ÿ

åŠŸèƒ½ï¼š
1. UserProfileManager: Rediså­˜å‚¨ç”¨æˆ·åå¥½è®¾ç½®
2. StyleMemory: Milvuså‘é‡å­˜å‚¨ç”¨æˆ·ç¼–è¾‘è¿‡çš„é£æ ¼ç‰‡æ®µ
3. ğŸ†• UnifiedMemoryManager: åŒå±‚è®°å¿†ç³»ç»Ÿï¼ˆçŸ­æœŸæ¶ˆæ¯+ä¸­æœŸè®°å¿†ï¼‰
4. ğŸ†• TaskQueueManager: ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†å™¨

"""

import json
import logging
import asyncio
import uuid
import threading
from typing import Dict, Any, List, Optional, Tuple, AsyncGenerator
from dataclasses import dataclass, field, asdict
from enum import Enum
from datetime import datetime
from pathlib import Path

logger = logging.getLogger(__name__)


# ==================== ç”¨æˆ·ç”»åƒç®¡ç† ====================

class LanguageStyle(Enum):
    """è¯­è¨€é£æ ¼"""
    FORMAL = "formal"           # æ­£å¼
    CASUAL = "casual"           # éšæ„
    LITERARY = "literary"       # æ–‡å­¦æ€§
    COLLOQUIAL = "colloquial"   # å£è¯­åŒ–
    HUMOROUS = "humorous"       # å¹½é»˜
    DRAMATIC = "dramatic"       # æˆå‰§åŒ–


@dataclass
class UserProfile:
    """ç”¨æˆ·ç”»åƒ"""
    user_id: str

    # åå¥½è®¾ç½®
    fav_genres: List[str] = field(default_factory=list)           # åå¥½é¢˜æï¼ˆå¦‚ï¼šéƒ½å¸‚ã€å¤è£…ã€æ‚¬ç–‘ã€ç”œå® ï¼‰
    avoid_tropes: List[str] = field(default_factory=list)         # è®¨åŒçš„æ¡¥æ®µï¼ˆå¦‚ï¼šä¸‰è§’æ‹ã€é‡ç”Ÿã€ç©¿è¶Šï¼‰
    language_style: List[str] = field(default_factory=list)       # è¯­è¨€é£æ ¼æ ‡ç­¾

    # å…ƒæ•°æ®
    created_at: str = field(default_factory=lambda: datetime.now().isoformat())
    updated_at: str = field(default_factory=lambda: datetime.now().isoformat())

    # ç»Ÿè®¡ä¿¡æ¯
    total_edits: int = 0
    total_scripts: int = 0

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return asdict(self)

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'UserProfile':
        """ä»å­—å…¸åˆ›å»º"""
        return cls(**data)


class UserProfileManager:
    """
    ç”¨æˆ·ç”»åƒç®¡ç†å™¨

    ä½¿ç”¨ Redis å­˜å‚¨ç”¨æˆ·åå¥½è®¾ç½®
    Key æ ¼å¼: user:{uid}:profile
    """

    def __init__(self, redis_client=None):
        """
        åˆå§‹åŒ–ç”¨æˆ·ç”»åƒç®¡ç†å™¨

        Args:
            redis_client: Rediså®¢æˆ·ç«¯å®ä¾‹
        """
        self.redis_client = redis_client
        self.logger = logger
        self.key_prefix = "user"

    def _get_profile_key(self, user_id: str) -> str:
        """è·å–ç”¨æˆ·ç”»åƒçš„Redis key"""
        return f"{self.key_prefix}:{user_id}:profile"

    async def get_profile(self, user_id: str) -> Optional[UserProfile]:
        """
        è·å–ç”¨æˆ·ç”»åƒ

        Args:
            user_id: ç”¨æˆ·ID

        Returns:
            UserProfile: ç”¨æˆ·ç”»åƒï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
        """
        try:
            if not self.redis_client:
                self.logger.warning("Rediså®¢æˆ·ç«¯æœªé…ç½®ï¼Œè¿”å›é»˜è®¤ç”»åƒ")
                return UserProfile(user_id=user_id)

            key = self._get_profile_key(user_id)
            data = await self.redis_client.get(key)

            if data:
                profile_data = json.loads(data)
                return UserProfile.from_dict(profile_data)
            else:
                return None

        except Exception as e:
            self.logger.error(f"è·å–ç”¨æˆ·ç”»åƒå¤±è´¥ (user: {user_id}): {e}")
            return None

    async def create_profile(self, user_id: str) -> UserProfile:
        """
        åˆ›å»ºæ–°ç”¨æˆ·ç”»åƒ

        Args:
            user_id: ç”¨æˆ·ID

        Returns:
            UserProfile: æ–°åˆ›å»ºçš„ç”¨æˆ·ç”»åƒ
        """
        profile = UserProfile(user_id=user_id)
        await self.save_profile(profile)
        self.logger.info(f"âœ… åˆ›å»ºç”¨æˆ·ç”»åƒ (user: {user_id})")
        return profile

    async def save_profile(self, profile: UserProfile) -> bool:
        """
        ä¿å­˜ç”¨æˆ·ç”»åƒ

        Args:
            profile: ç”¨æˆ·ç”»åƒå¯¹è±¡

        Returns:
            bool: æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            if not self.redis_client:
                self.logger.warning("Rediså®¢æˆ·ç«¯æœªé…ç½®ï¼Œè·³è¿‡ä¿å­˜")
                return False

            profile.updated_at = datetime.now().isoformat()
            key = self._get_profile_key(profile.user_id)
            data = json.dumps(profile.to_dict(), ensure_ascii=False)

            await self.redis_client.set(key, data)
            self.logger.info(f"âœ… ä¿å­˜ç”¨æˆ·ç”»åƒ (user: {profile.user_id})")
            return True

        except Exception as e:
            self.logger.error(f"ä¿å­˜ç”¨æˆ·ç”»åƒå¤±è´¥ (user: {profile.user_id}): {e}")
            return False

    async def update_preferences(
        self,
        user_id: str,
        fav_genres: Optional[List[str]] = None,
        avoid_tropes: Optional[List[str]] = None,
        language_style: Optional[List[str]] = None
    ) -> bool:
        """
        æ›´æ–°ç”¨æˆ·åå¥½

        Args:
            user_id: ç”¨æˆ·ID
            fav_genres: åå¥½é¢˜æ
            avoid_tropes: è®¨åŒçš„æ¡¥æ®µ
            language_style: è¯­è¨€é£æ ¼

        Returns:
            bool: æ˜¯å¦æ›´æ–°æˆåŠŸ
        """
        try:
            # è·å–æˆ–åˆ›å»ºç”»åƒ
            profile = await self.get_profile(user_id)
            if not profile:
                profile = await self.create_profile(user_id)

            # æ›´æ–°å­—æ®µ
            if fav_genres is not None:
                profile.fav_genres = fav_genres
            if avoid_tropes is not None:
                profile.avoid_tropes = avoid_tropes
            if language_style is not None:
                profile.language_style = language_style

            return await self.save_profile(profile)

        except Exception as e:
            self.logger.error(f"æ›´æ–°ç”¨æˆ·åå¥½å¤±è´¥ (user: {user_id}): {e}")
            return False

    async def increment_edits(self, user_id: str) -> bool:
        """å¢åŠ ç¼–è¾‘æ¬¡æ•°"""
        profile = await self.get_profile(user_id)
        if profile:
            profile.total_edits += 1
            return await self.save_profile(profile)
        return False

    async def increment_scripts(self, user_id: str) -> bool:
        """å¢åŠ å‰§æœ¬æ•°é‡"""
        profile = await self.get_profile(user_id)
        if profile:
            profile.total_scripts += 1
            return await self.save_profile(profile)
        return False


# ==================== é£æ ¼å‘é‡åº“ ====================

@dataclass
class StyleFragment:
    """é£æ ¼ç‰‡æ®µ"""
    fragment_id: str
    user_id: str
    session_id: str

    # å†…å®¹
    original_text: str        # AIåŸæ–‡
    modified_text: str        # ç”¨æˆ·ä¿®æ”¹å
    context: str              # ä¸Šä¸‹æ–‡

    # åˆ†æç»“æœ
    intents: List[str]        # ä¿®æ”¹æ„å›¾
    features: List[str]       # é£æ ¼ç‰¹å¾
    confidence: float         # å¯ä¿¡åº¦

    # å…ƒæ•°æ®
    timestamp: str
    artifact_id: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return asdict(self)


class StyleMemory:
    """
    é£æ ¼å‘é‡åº“

    ä½¿ç”¨ Milvus å­˜å‚¨ç”¨æˆ·ç¼–è¾‘è¿‡çš„é£æ ¼ç‰‡æ®µ
    Collection: user_style_collection
    """

    def __init__(self, milvus_client=None, embedding_client=None):
        """
        åˆå§‹åŒ–é£æ ¼å‘é‡åº“

        Args:
            milvus_client: Milvuså®¢æˆ·ç«¯
            embedding_client: åµŒå…¥å‘é‡å®¢æˆ·ç«¯
        """
        self.milvus_client = milvus_client
        self.embedding_client = embedding_client
        self.logger = logger
        self.collection_name = "user_style_collection"
        self.dimension = 768  # é»˜è®¤å‘é‡ç»´åº¦

        # åˆå§‹åŒ–é›†åˆ
        self._initialized = False

    async def _ensure_collection(self):
        """ç¡®ä¿é›†åˆå­˜åœ¨"""
        if self._initialized or not self.milvus_client:
            return

        try:
            from pymilvus import Collection, FieldSchema, CollectionSchema, DataType

            # æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨
            from pymilvus import utility
            if utility.has_collection(self.collection_name):
                self.collection = Collection(self.collection_name)
                self.logger.info(f"âœ… åŠ è½½ç°æœ‰é›†åˆ: {self.collection_name}")
            else:
                # åˆ›å»ºé›†åˆ
                fields = [
                    FieldSchema(name="id", dtype=DataType.VARCHAR, max_length=100, is_primary=True),
                    FieldSchema(name="user_id", dtype=DataType.VARCHAR, max_length=100),
                    FieldSchema(name="session_id", dtype=DataType.VARCHAR, max_length=100),
                    FieldSchema(name="original_text", dtype=DataType.VARCHAR, max_length=8192),
                    FieldSchema(name="modified_text", dtype=DataType.VARCHAR, max_length=8192),
                    FieldSchema(name="context", dtype=DataType.VARCHAR, max_length=4096),
                    FieldSchema(name="intents", dtype=DataType.VARCHAR, max_length=500),
                    FieldSchema(name="features", dtype=DataType.VARCHAR, max_length=500),
                    FieldSchema(name="confidence", dtype=DataType.FLOAT),
                    FieldSchema(name="timestamp", dtype=DataType.VARCHAR, max_length=50),
                    FieldSchema(name="artifact_id", dtype=DataType.VARCHAR, max_length=100),
                    FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=self.dimension)
                ]

                schema = CollectionSchema(fields, description="ç”¨æˆ·é£æ ¼ç‰‡æ®µå‘é‡åº“")
                self.collection = Collection(
                    name=self.collection_name,
                    schema=schema
                )

                # åˆ›å»ºç´¢å¼•
                index_params = {
                    "index_type": "IVF_FLAT",
                    "metric_type": "IP",  # å†…ç§¯
                    "params": {"nlist": 128}
                }
                self.collection.create_index(field_name="embedding", index_params=index_params)

                self.logger.info(f"âœ… åˆ›å»ºæ–°é›†åˆ: {self.collection_name}")

            self._initialized = True

        except ImportError:
            self.logger.warning("pymilvusæœªå®‰è£…ï¼Œé£æ ¼å‘é‡åº“åŠŸèƒ½å°†ä¸å¯ç”¨")
        except Exception as e:
            self.logger.error(f"åˆå§‹åŒ–Milvusé›†åˆå¤±è´¥: {e}")

    async def save_fragment(
        self,
        fragment: StyleFragment
    ) -> bool:
        """
        ä¿å­˜é£æ ¼ç‰‡æ®µ

        Args:
            fragment: é£æ ¼ç‰‡æ®µ

        Returns:
            bool: æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            await self._ensure_collection()

            if not self.embedding_client or not self.milvus_client:
                self.logger.warning("åµŒå…¥å‘é‡æˆ–Milvuså®¢æˆ·ç«¯æœªé…ç½®ï¼Œè·³è¿‡ä¿å­˜")
                return False

            # ç”ŸæˆåµŒå…¥å‘é‡
            embedding = await self._generate_embedding(fragment.modified_text)
            if embedding is None:
                return False

            # æ’å…¥æ•°æ®
            data = [
                [fragment.fragment_id],
                [fragment.user_id],
                [fragment.session_id],
                [fragment.original_text],
                [fragment.modified_text],
                [fragment.context],
                [",".join(fragment.intents)],
                [",".join(fragment.features)],
                [fragment.confidence],
                [fragment.timestamp],
                [fragment.artifact_id or ""],
                [embedding]
            ]

            self.collection.insert(data)
            self.collection.flush()

            self.logger.info(f"âœ… ä¿å­˜é£æ ¼ç‰‡æ®µ (fragment: {fragment.fragment_id}, user: {fragment.user_id})")
            return True

        except Exception as e:
            self.logger.error(f"ä¿å­˜é£æ ¼ç‰‡æ®µå¤±è´¥: {e}")
            return False

    async def search_similar(
        self,
        query_text: str,
        user_id: str,
        top_k: int = 3
    ) -> List[StyleFragment]:
        """
        æœç´¢ç›¸ä¼¼çš„é£æ ¼ç‰‡æ®µ

        Args:
            query_text: æŸ¥è¯¢æ–‡æœ¬
            user_id: ç”¨æˆ·ID
            top_k: è¿”å›æ•°é‡

        Returns:
            List[StyleFragment]: ç›¸ä¼¼çš„é£æ ¼ç‰‡æ®µåˆ—è¡¨
        """
        try:
            await self._ensure_collection()

            if not self.embedding_client or not self.milvus_client:
                return []

            # ç”ŸæˆæŸ¥è¯¢å‘é‡
            query_embedding = await self._generate_embedding(query_text)
            if query_embedding is None:
                return []

            # åŠ è½½é›†åˆ
            self.collection.load()

            # æ„å»ºæœç´¢è¿‡æ»¤å™¨ï¼ˆä»…æœç´¢è¯¥ç”¨æˆ·çš„ç‰‡æ®µï¼‰
            from pymilvus import AnnSearchRequest
            search_param = {
                "metric_type": "IP",
                "params": {"nprobe": 10}
            }

            # æ‰§è¡Œæœç´¢
            results = self.collection.search(
                data=[query_embedding],
                anns_field="embedding",
                param=search_param,
                limit=top_k,
                expr=f"user_id == '{user_id}'",
                output_fields=["user_id", "modified_text", "context", "intents", "features", "confidence"]
            )

            # è½¬æ¢ç»“æœ
            fragments = []
            for hit in results[0]:
                fragments.append(StyleFragment(
                    fragment_id=hit.id,
                    user_id=hit.entity.get("user_id"),
                    session_id=hit.entity.get("session_id", ""),
                    original_text=hit.entity.get("original_text", ""),
                    modified_text=hit.entity.get("modified_text", ""),
                    context=hit.entity.get("context", ""),
                    intents=hit.entity.get("intents", "").split(","),
                    features=hit.entity.get("features", "").split(","),
                    confidence=hit.entity.get("confidence", 0.0),
                    timestamp=hit.entity.get("timestamp", ""),
                    artifact_id=hit.entity.get("artifact_id")
                ))

            self.logger.info(f"âœ… æœç´¢åˆ° {len(fragments)} ä¸ªç›¸ä¼¼ç‰‡æ®µ (user: {user_id})")
            return fragments

        except Exception as e:
            self.logger.error(f"æœç´¢ç›¸ä¼¼ç‰‡æ®µå¤±è´¥: {e}")
            return []

    async def _generate_embedding(self, text: str) -> Optional[List[float]]:
        """ç”Ÿæˆæ–‡æœ¬åµŒå…¥å‘é‡"""
        try:
            # è¿™é‡Œä½¿ç”¨åµŒå…¥å‘é‡å®¢æˆ·ç«¯
            # å¦‚æœæ²¡æœ‰é…ç½®ï¼Œè¿”å›None
            if not self.embedding_client:
                self.logger.warning("åµŒå…¥å‘é‡å®¢æˆ·ç«¯æœªé…ç½®")
                return None

            # è°ƒç”¨åµŒå…¥å‘é‡API
            embedding = await self.embedding_client.embed(text)
            return embedding

        except Exception as e:
            self.logger.error(f"ç”ŸæˆåµŒå…¥å‘é‡å¤±è´¥: {e}")
            return None

    async def get_user_fragments(
        self,
        user_id: str,
        limit: int = 10
    ) -> List[StyleFragment]:
        """
        è·å–ç”¨æˆ·çš„æ‰€æœ‰é£æ ¼ç‰‡æ®µ

        Args:
            user_id: ç”¨æˆ·ID
            limit: è¿”å›æ•°é‡

        Returns:
            List[StyleFragment]: é£æ ¼ç‰‡æ®µåˆ—è¡¨
        """
        try:
            await self._ensure_collection()

            if not self.milvus_client:
                return []

            self.collection.load()

            # æŸ¥è¯¢ç”¨æˆ·çš„æ‰€æœ‰ç‰‡æ®µ
            results = self.collection.query(
                expr=f"user_id == '{user_id}'",
                output_fields=["*"],
                limit=limit
            )

            fragments = []
            for item in results:
                fragments.append(StyleFragment(
                    fragment_id=item.get("id", ""),
                    user_id=item.get("user_id", ""),
                    session_id=item.get("session_id", ""),
                    original_text=item.get("original_text", ""),
                    modified_text=item.get("modified_text", ""),
                    context=item.get("context", ""),
                    intents=item.get("intents", "").split(","),
                    features=item.get("features", "").split(","),
                    confidence=item.get("confidence", 0.0),
                    timestamp=item.get("timestamp", ""),
                    artifact_id=item.get("artifact_id")
                ))

            return fragments

        except Exception as e:
            self.logger.error(f"è·å–ç”¨æˆ·ç‰‡æ®µå¤±è´¥: {e}")
            return []


# ==================== å…¨å±€å®ä¾‹ ====================

_user_profile_manager: Optional[UserProfileManager] = None
_style_memory: Optional[StyleMemory] = None


def get_user_profile_manager(redis_client=None) -> UserProfileManager:
    """è·å–ç”¨æˆ·ç”»åƒç®¡ç†å™¨å•ä¾‹"""
    global _user_profile_manager
    if _user_profile_manager is None:
        _user_profile_manager = UserProfileManager(redis_client=redis_client)
    return _user_profile_manager


def get_style_memory(milvus_client=None, embedding_client=None) -> StyleMemory:
    """è·å–é£æ ¼å‘é‡åº“å•ä¾‹"""
    global _style_memory
    if _style_memory is None:
        _style_memory = StyleMemory(
            milvus_client=milvus_client,
            embedding_client=embedding_client
        )
    return _style_memory



# ==================== ä¾¿æ·å‡½æ•° ====================

async def save_user_style_edit(
    user_id: str,
    session_id: str,
    original_text: str,
    modified_text: str,
    context: str,
    analysis_result: Dict[str, Any],
    artifact_id: Optional[str] = None
) -> bool:
    """
    ä¿å­˜ç”¨æˆ·é£æ ¼ç¼–è¾‘ï¼ˆä¾¿æ·å‡½æ•°ï¼‰

    Args:
        user_id: ç”¨æˆ·ID
        session_id: ä¼šè¯ID
        original_text: AIåŸæ–‡
        modified_text: ç”¨æˆ·ä¿®æ”¹æ–‡
        context: ä¸Šä¸‹æ–‡
        analysis_result: é£æ ¼åˆ†æç»“æœ
        artifact_id: Artifact ID

    Returns:
        bool: æ˜¯å¦ä¿å­˜æˆåŠŸ
    """
    import uuid
    style_memory = get_style_memory()

    fragment = StyleFragment(
        fragment_id=f"frag_{uuid.uuid4().hex[:16]}",
        user_id=user_id,
        session_id=session_id,
        original_text=original_text,
        modified_text=modified_text,
        context=context,
        intents=analysis_result.get("detected_intents", []),
        features=analysis_result.get("style_features", []),
        confidence=analysis_result.get("confidence_score", 0.0),
        timestamp=datetime.now().isoformat(),
        artifact_id=artifact_id
    )

    return await style_memory.save_fragment(fragment)


async def get_user_style_examples(
    user_id: str,
    query_text: str,
    count: int = 3
) -> List[str]:
    """
    è·å–ç”¨æˆ·é£æ ¼ç¤ºä¾‹ï¼ˆä¾¿æ·å‡½æ•°ï¼‰

    Args:
        user_id: ç”¨æˆ·ID
        query_text: æŸ¥è¯¢æ–‡æœ¬
        count: ç¤ºä¾‹æ•°é‡

    Returns:
        List[str]: é£æ ¼ç¤ºä¾‹æ–‡æœ¬åˆ—è¡¨
    """
    style_memory = get_style_memory()
    fragments = await style_memory.search_similar(query_text, user_id, top_k=count)
    return [frag.modified_text for frag in fragments]


# ==================== ğŸ†• åŒå±‚è®°å¿†ç³»ç»Ÿ ====================

@dataclass
class ShortTermMemoryContext:
    """çŸ­æœŸè®°å¿†ä¸Šä¸‹æ–‡"""
    messages: List[Dict[str, Any]]  # æœ€è¿‘çš„æ¶ˆæ¯åˆ—è¡¨
    formatted_context: str  # æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡æ–‡æœ¬
    message_count: int  # æ¶ˆæ¯æ•°é‡


@dataclass
class MiddleTermMemory:
    """ä¸­æœŸè®°å¿†ï¼ˆAgentå®Œæˆä»»åŠ¡åçš„æ€»ç»“ï¼‰"""
    memory_id: str
    user_id: str
    session_id: str
    agent_type: str  # Agentç±»å‹ (moved before optional fields)
    task_summary: str  # ä»»åŠ¡æ€»ç»“
    compressed_summary: str  # å‹ç¼©åçš„æ‘˜è¦
    timestamp: datetime
    project_id: Optional[str] = None
    embedding: Optional[List[float]] = None  # å‘é‡åµŒå…¥ï¼ˆç”¨äºæ£€ç´¢ï¼‰

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        data = asdict(self)
        data['timestamp'] = self.timestamp.isoformat()
        return data

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'MiddleTermMemory':
        """ä»å­—å…¸åˆ›å»º"""
        if isinstance(data.get('timestamp'), str):
            data['timestamp'] = datetime.fromisoformat(data['timestamp'])
        return cls(**data)


class UnifiedMemoryManager:
    """
    ğŸ†• ç»Ÿä¸€è®°å¿†ç®¡ç†å™¨ - åŒå±‚è®°å¿†ç³»ç»Ÿ

    ï¼Œæä¾›ï¼š
    1. çŸ­æœŸè®°å¿†ï¼šæœ€è¿‘çš„æ¶ˆæ¯å†å²ï¼ˆä»Redisè·å–ï¼‰
    2. ä¸­æœŸè®°å¿†ï¼šAgentå®Œæˆä»»åŠ¡åçš„æ€»ç»“ï¼ˆä»å‘é‡åº“æ£€ç´¢ï¼‰

    ä½¿ç”¨åœºæ™¯ï¼š
    - Agentå¤„ç†å‰è°ƒç”¨ build_agent_context() è·å–å®Œæ•´ä¸Šä¸‹æ–‡
    - Agentå®Œæˆåè°ƒç”¨ process_agent_completion() ä¿å­˜ä¸­æœŸè®°å¿†
    """

    def __init__(self, storage_manager=None, redis_client=None, embedding_client=None):
        """
        åˆå§‹åŒ–ç»Ÿä¸€è®°å¿†ç®¡ç†å™¨

        Args:
            storage_manager: å­˜å‚¨ç®¡ç†å™¨ï¼ˆç”¨äºè·å–çŸ­æœŸè®°å¿†ï¼‰
            redis_client: Rediså®¢æˆ·ç«¯ï¼ˆå¤‡ç”¨ï¼‰
            embedding_client: åµŒå…¥å‘é‡å®¢æˆ·ç«¯ï¼ˆç”¨äºä¸­æœŸè®°å¿†æ£€ç´¢ï¼‰
        """
        from utils.storage_manager import get_storage
        self.storage_manager = storage_manager or get_storage()
        self.redis_client = redis_client or getattr(self.storage_manager, "redis_client", None)
        self.embedding_client = embedding_client
        self.logger = logger

    async def save_middle_term_memory(self, memory: MiddleTermMemory) -> bool:
        """ä¿å­˜ä¸­æœŸè®°å¿†"""
        if not self.redis_client:
            self.logger.warning("Rediså®¢æˆ·ç«¯æœªé…ç½®ï¼Œæ— æ³•ä¿å­˜ä¸­æœŸè®°å¿†")
            return False

        try:
            from utils.memory_settings import get_memory_settings_manager
            settings = get_memory_settings_manager().get_settings(memory.user_id, memory.project_id)
            if not settings.effective_enabled:
                self.logger.info(f"è®°å¿†å·²å…³é—­ï¼Œè·³è¿‡ä¿å­˜: user={memory.user_id}, project={memory.project_id}")
                return False
        except Exception:
            pass

        try:
            key = f"juben:middle_memory:{memory.user_id}:{memory.session_id}"
            await self.redis_client.lpush(key, json.dumps(memory.to_dict(), ensure_ascii=False))
            await self.redis_client.ltrim(key, 0, 199)  # ä»…ä¿ç•™æœ€è¿‘200æ¡
            return True
        except Exception as e:
            self.logger.error(f"ä¿å­˜ä¸­æœŸè®°å¿†å¤±è´¥: {e}")
            return False

    async def process_agent_completion(
        self,
        user_id: str,
        session_id: str,
        agent_type: str,
        task_summary: str,
        compressed_summary: Optional[str] = None,
        project_id: Optional[str] = None,
    ) -> bool:
        """å¤„ç†Agentå®Œæˆä»»åŠ¡åçš„ä¸­æœŸè®°å¿†ä¿å­˜"""
        try:
            memory = MiddleTermMemory(
                memory_id=f"mem_{uuid.uuid4().hex[:16]}",
                user_id=user_id,
                session_id=session_id,
                project_id=project_id,
                agent_type=agent_type,
                task_summary=task_summary,
                compressed_summary=compressed_summary or task_summary[:300],
                timestamp=datetime.now(),
            )
            return await self.save_middle_term_memory(memory)
        except Exception as e:
            self.logger.error(f"å¤„ç†Agentå®Œæˆä»»åŠ¡å¤±è´¥: {e}")
            return False

    async def overwrite_middle_term_memories(
        self,
        user_id: str,
        session_id: str,
        memories: List[Dict[str, Any]]
    ) -> bool:
        """è¦†ç›–ä¸­æœŸè®°å¿†ï¼ˆç”¨äºå¿«ç…§å›æ»šï¼‰"""
        if not self.redis_client:
            return False
        try:
            key = f"juben:middle_memory:{user_id}:{session_id}"
            await self.redis_client.delete(key)
            if not memories:
                return True
            # æŒ‰æ—¶é—´ä»æ—§åˆ°æ–°å†™å…¥
            ordered = list(reversed(memories))
            for item in ordered:
                await self.redis_client.lpush(key, json.dumps(item, ensure_ascii=False))
            await self.redis_client.ltrim(key, 0, 199)
            return True
        except Exception as e:
            self.logger.error(f"è¦†ç›–ä¸­æœŸè®°å¿†å¤±è´¥: {e}")
            return False

    async def clear_middle_term_memories(self, user_id: str, session_id: str) -> bool:
        if not self.redis_client:
            return False
        try:
            key = f"juben:middle_memory:{user_id}:{session_id}"
            await self.redis_client.delete(key)
            return True
        except Exception as e:
            self.logger.error(f"æ¸…ç†ä¸­æœŸè®°å¿†å¤±è´¥: {e}")
            return False

    async def build_agent_context(
        self,
        user_id: str,
        session_id: str,
        current_query: str,
        agent_type: str,
        short_term_limit: int = 10,
        middle_term_limit: int = 5
    ) -> Dict[str, Any]:
        """
        æ„å»ºAgentä¸Šä¸‹æ–‡ - åŒå±‚è®°å¿†ç³»ç»Ÿ

        åŠŸèƒ½ï¼š
        - çŸ­æœŸè®°å¿†ï¼šè·å–æœ€è¿‘çš„Næ¡æ¶ˆæ¯
        - ä¸­æœŸè®°å¿†ï¼šæ ¹æ®queryæ£€ç´¢ç›¸å…³çš„å†å²ä»»åŠ¡æ€»ç»“
        - æ•´åˆä¸ºå®Œæ•´çš„ä¸Šä¸‹æ–‡è¿”å›ç»™Agent

        Args:
            user_id: ç”¨æˆ·ID
            session_id: ä¼šè¯ID
            current_query: å½“å‰æŸ¥è¯¢
            agent_type: Agentç±»å‹
            short_term_limit: çŸ­æœŸè®°å¿†æ¡æ•°
            middle_term_limit: ä¸­æœŸè®°å¿†æ¡æ•°

        Returns:
            Dict: åŒ…å«çŸ­æœŸè®°å¿†å’Œä¸­æœŸè®°å¿†çš„ä¸Šä¸‹æ–‡
        """
        try:
            self.logger.info(f"ğŸ”„ æ„å»ºåŒå±‚è®°å¿†ä¸Šä¸‹æ–‡: {agent_type} - {user_id}")

            # 1. è·å–çŸ­æœŸè®°å¿†ï¼ˆæœ€è¿‘çš„æ¶ˆæ¯ï¼‰
            short_term_context = await self._get_short_term_memory(
                user_id, session_id, short_term_limit
            )

            # 2. è·å–ä¸­æœŸè®°å¿†ï¼ˆç›¸å…³çš„å†å²ä»»åŠ¡ï¼‰
            middle_term_memories = await self._get_middle_term_memory(
                user_id, session_id, current_query, middle_term_limit
            )

            # 3. æ„å»ºå®Œæ•´ä¸Šä¸‹æ–‡
            context = {
                "short_term_memory": {
                    "formatted_context": short_term_context.formatted_context,
                    "message_count": short_term_context.message_count,
                    "messages": short_term_context.messages
                },
                "middle_term_memory": {
                    "formatted_context": self._format_middle_memories(middle_term_memories),
                    "memory_count": len(middle_term_memories),
                    "memories": [m.to_dict() for m in middle_term_memories]
                },
                "stats": {
                    "short_term_count": short_term_context.message_count,
                    "middle_term_count": len(middle_term_memories),
                    "agent_type": agent_type,
                    "generated_at": datetime.now().isoformat()
                }
            }

            self.logger.info(f"âœ… åŒå±‚è®°å¿†ä¸Šä¸‹æ–‡æ„å»ºå®Œæˆ: æ¶ˆæ¯:{short_term_context.message_count}æ¡, è®°å¿†:{len(middle_term_memories)}æ¡")

            return context

        except Exception as e:
            self.logger.error(f"âŒ æ„å»ºåŒå±‚è®°å¿†ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            return self._get_empty_context()

    async def get_memory_metrics(
        self,
        user_id: str,
        session_id: str,
        current_query: str = "",
        short_term_limit: int = 10,
        middle_term_limit: int = 5
    ) -> Dict[str, Any]:
        """
        è¯„ä¼°è®°å¿†è´¨é‡ä¸è¦†ç›–æƒ…å†µï¼ˆè½»é‡æŒ‡æ ‡ï¼‰
        """
        try:
            short_term = await self._get_short_term_memory(user_id, session_id, short_term_limit)
            middle_term = await self._get_middle_term_memory(user_id, session_id, current_query, middle_term_limit)

            last_mid_ts = middle_term[0].timestamp.isoformat() if middle_term else None
            avg_mid_len = 0
            if middle_term:
                avg_mid_len = int(sum(len(m.task_summary or "") for m in middle_term) / len(middle_term))

            health = "healthy"
            warnings = []
            if short_term.message_count > 0 and len(middle_term) == 0:
                health = "degraded"
                warnings.append("å­˜åœ¨å¯¹è¯ä½†æ— ä¸­æœŸè®°å¿†")
            if short_term.message_count > 30 and len(middle_term) < 3:
                health = "degraded"
                warnings.append("å¯¹è¯è¾ƒé•¿ä½†ä¸­æœŸè®°å¿†åå°‘")

            return {
                "health": health,
                "warnings": warnings,
                "short_term": {
                    "message_count": short_term.message_count,
                },
                "middle_term": {
                    "memory_count": len(middle_term),
                    "latest_timestamp": last_mid_ts,
                    "avg_summary_length": avg_mid_len
                }
            }
        except Exception as e:
            self.logger.error(f"è·å–è®°å¿†æŒ‡æ ‡å¤±è´¥: {e}")
            return {
                "health": "unknown",
                "warnings": ["è·å–æŒ‡æ ‡å¤±è´¥"],
                "short_term": {"message_count": 0},
                "middle_term": {"memory_count": 0}
            }

    async def _get_short_term_memory(
        self,
        user_id: str,
        session_id: str,
        limit: int
    ) -> ShortTermMemoryContext:
        """è·å–çŸ­æœŸè®°å¿†"""
        try:
            # ä»å­˜å‚¨ç®¡ç†å™¨è·å–æœ€è¿‘çš„æ¶ˆæ¯
            messages = await self.storage_manager.get_chat_messages(
                user_id=user_id,
                session_id=session_id,
                limit=limit
            )

            # æ ¼å¼åŒ–ä¸Šä¸‹æ–‡
            formatted_lines = []
            for msg in messages:
                role = msg.get('message_type', msg.get('role', 'unknown'))
                content = msg.get('content', '')
                if role == 'user':
                    formatted_lines.append(f"ç”¨æˆ·: {content}")
                elif role == 'assistant':
                    agent_name = msg.get('agent_name', 'AI')
                    formatted_lines.append(f"{agent_name}: {content}")

            formatted_context = "\n".join(formatted_lines) if formatted_lines else "æš‚æ— å†å²å¯¹è¯"

            return ShortTermMemoryContext(
                messages=messages,
                formatted_context=formatted_context,
                message_count=len(messages)
            )

        except Exception as e:
            self.logger.error(f"è·å–çŸ­æœŸè®°å¿†å¤±è´¥: {e}")
            return ShortTermMemoryContext(
                messages=[],
                formatted_context="æš‚æ— å†å²å¯¹è¯",
                message_count=0
            )

    async def _get_middle_term_memory(
        self,
        user_id: str,
        session_id: str,
        query: str,
        limit: int
    ) -> List[MiddleTermMemory]:
        """è·å–ä¸­æœŸè®°å¿†"""
        try:
            if not self.redis_client:
                return []

            key = f"juben:middle_memory:{user_id}:{session_id}"
            raw_items = await self.redis_client.lrange(key, 0, 200)
            if not raw_items:
                return []

            memories = []
            for raw in raw_items:
                try:
                    data = json.loads(raw)
                    memories.append(MiddleTermMemory.from_dict(data))
                except Exception:
                    continue

            if not query:
                return memories[:limit]

            query_terms = [t for t in query.lower().split() if t]

            def score(mem: MiddleTermMemory) -> int:
                text = f"{mem.task_summary} {mem.compressed_summary}".lower()
                return sum(1 for t in query_terms if t in text)

            memories.sort(key=score, reverse=True)
            return memories[:limit]

        except Exception as e:
            self.logger.error(f"è·å–ä¸­æœŸè®°å¿†å¤±è´¥: {e}")
            return []

    async def get_middle_term_context(
        self,
        user_id: str,
        session_id: str,
        query: str,
        limit: int = 5
    ) -> Dict[str, Any]:
        """
        è·å–ä¸­æœŸè®°å¿†ä¸Šä¸‹æ–‡ï¼ˆæ ¼å¼åŒ–ï¼‰

        Returns:
            Dict: { formatted_context, memory_count, memories }
        """
        memories = await self._get_middle_term_memory(user_id, session_id, query, limit)
        return {
            "formatted_context": self._format_middle_memories(memories),
            "memory_count": len(memories),
            "memories": [m.to_dict() for m in memories]
        }

    def _format_middle_memories(self, memories: List[MiddleTermMemory]) -> str:
        """æ ¼å¼åŒ–ä¸­æœŸè®°å¿†ä¸ºæ–‡æœ¬"""
        if not memories:
            return "æš‚æ— ç›¸å…³å†å²ä»»åŠ¡è®°å½•"

        formatted_lines = ["ğŸ§  **ä¸­æœŸè®°å¿†** (ç›¸å…³å†å²ä»»åŠ¡):"]

        for i, memory in enumerate(memories, 1):
            agent_type = memory.agent_type
            summary = memory.compressed_summary
            time_str = memory.timestamp.strftime("%m-%d %H:%M")

            formatted_lines.append(f"\n{i}. **{agent_type}** ({time_str})")
            formatted_lines.append(f"   {summary}")

        return "\n".join(formatted_lines)

    def _get_empty_context(self) -> Dict[str, Any]:
        """è·å–ç©ºä¸Šä¸‹æ–‡"""
        return {
            "short_term_memory": {
                "formatted_context": "æš‚æ— å†å²å¯¹è¯",
                "message_count": 0,
                "messages": []
            },
            "middle_term_memory": {
                "formatted_context": "æš‚æ— ç›¸å…³å†å²ä»»åŠ¡è®°å½•",
                "memory_count": 0,
                "memories": []
            },
            "stats": {
                "short_term_count": 0,
                "middle_term_count": 0,
                "agent_type": "unknown",
                "generated_at": datetime.now().isoformat()
            }
        }


# ==================== ğŸ†• ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†å™¨ ====================

@dataclass
class TaskItem:
    """ä»»åŠ¡é¡¹æ•°æ®ç»“æ„"""
    id: str
    action: str  # Agentç±»å‹æˆ–æ“ä½œç±»å‹
    input: str
    status: str = "pending"  # pending, running, completed, failed
    result: Optional[str] = None
    created_at: str = ""
    completed_at: Optional[str] = None
    metadata: Dict[str, Any] = field(default_factory=dict)

    def __post_init__(self):
        if not self.created_at:
            self.created_at = datetime.now().isoformat()


@dataclass
class TaskQueue:
    """ä»»åŠ¡é˜Ÿåˆ—æ•°æ®ç»“æ„"""
    queue_key: str  # user_id::session_id æ ¼å¼
    user_id: str
    session_id: str
    tasks: List[TaskItem]
    current_task_index: int = 0
    created_at: str = ""
    last_accessed: str = ""
    original_user_query: str = ""  # ç”¨æˆ·åŸå§‹è¾“å…¥

    def __post_init__(self):
        if not self.created_at:
            self.created_at = datetime.now().isoformat()
        if not self.last_accessed:
            self.last_accessed = datetime.now().isoformat()

    def get_current_task(self) -> Optional[TaskItem]:
        """è·å–å½“å‰ä»»åŠ¡"""
        self.last_accessed = datetime.now().isoformat()
        if self.current_task_index < len(self.tasks):
            return self.tasks[self.current_task_index]
        return None

    def mark_current_completed(self, result: str = ""):
        """æ ‡è®°å½“å‰ä»»åŠ¡å®Œæˆ"""
        self.last_accessed = datetime.now().isoformat()
        if self.current_task_index < len(self.tasks):
            task = self.tasks[self.current_task_index]
            task.status = "completed"
            task.result = result
            task.completed_at = datetime.now().isoformat()
            self.current_task_index += 1

    def has_pending_tasks(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¿˜æœ‰å¾…æ‰§è¡Œä»»åŠ¡"""
        return self.current_task_index < len(self.tasks)

    def is_empty(self) -> bool:
        """æ£€æŸ¥é˜Ÿåˆ—æ˜¯å¦ä¸ºç©º"""
        return len(self.tasks) == 0

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "queue_key": self.queue_key,
            "user_id": self.user_id,
            "session_id": self.session_id,
            "tasks": [asdict(task) for task in self.tasks],
            "current_task_index": self.current_task_index,
            "created_at": self.created_at,
            "last_accessed": self.last_accessed,
            "original_user_query": self.original_user_query
        }


class TaskQueueManager:
    """
    ğŸ†• ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†å™¨

    ï¼Œæ”¯æŒï¼š
    1. ä»»åŠ¡é˜Ÿåˆ—åˆ›å»ºå’Œç®¡ç†
    2. å†…å­˜ç¼“å­˜å’Œæ–‡ä»¶æŒä¹…åŒ–
    3. ä»»åŠ¡æ‰§è¡ŒçŠ¶æ€è¿½è¸ª

    ä½¿ç”¨åœºæ™¯ï¼š
    - å¤šAgentå·¥ä½œæµç¼–æ’
    - å¼‚æ­¥ä»»åŠ¡è°ƒåº¦
    - ä»»åŠ¡æ‰§è¡Œè¿›åº¦è¿½è¸ª
    """

    def __init__(self, persist_dir: str = "data/task_queues"):
        """
        åˆå§‹åŒ–ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†å™¨

        Args:
            persist_dir: æŒä¹…åŒ–ç›®å½•
        """
        self.persist_dir = Path(persist_dir)
        self.persist_dir.mkdir(parents=True, exist_ok=True)

        # å†…å­˜ç¼“å­˜
        self.memory_cache: Dict[str, TaskQueue] = {}
        self.cache_lock = threading.RLock()

        # é…ç½®
        self.max_cache_size = 100  # æœ€å¤§ç¼“å­˜é˜Ÿåˆ—æ•°
        self.cache_ttl_hours = 2   # ç¼“å­˜TTLï¼ˆå°æ—¶ï¼‰
        self.logger = logger

    def _generate_queue_key(self, user_id: str, session_id: str) -> str:
        """ç”Ÿæˆé˜Ÿåˆ—å”¯ä¸€é”®"""
        return f"{user_id}::{session_id}"

    def _get_file_path(self, queue_key: str) -> Path:
        """è·å–é˜Ÿåˆ—æ–‡ä»¶è·¯å¾„"""
        safe_key = queue_key.replace("::", "_").replace("/", "_").replace("\\", "_")
        return self.persist_dir / f"{safe_key}.json"

    def _save_to_file(self, queue: TaskQueue):
        """ä¿å­˜é˜Ÿåˆ—åˆ°æ–‡ä»¶"""
        try:
            file_path = self._get_file_path(queue.queue_key)
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(queue.to_dict(), f, ensure_ascii=False, indent=2)
        except Exception as e:
            self.logger.error(f"ä¿å­˜é˜Ÿåˆ—æ–‡ä»¶å¤±è´¥: {e}")

    def _load_from_file(self, queue_key: str) -> Optional[TaskQueue]:
        """ä»æ–‡ä»¶åŠ è½½é˜Ÿåˆ—"""
        try:
            file_path = self._get_file_path(queue_key)
            if file_path.exists():
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)

                # é‡å»ºTaskItemå¯¹è±¡
                tasks = []
                for task_data in data.get('tasks', []):
                    tasks.append(TaskItem(**task_data))

                data['tasks'] = tasks
                return TaskQueue(**data)
        except Exception as e:
            self.logger.error(f"åŠ è½½é˜Ÿåˆ—æ–‡ä»¶å¤±è´¥: {e}")
        return None

    def get_queue(self, user_id: str, session_id: str) -> Optional[TaskQueue]:
        """è·å–é˜Ÿåˆ—"""
        queue_key = self._generate_queue_key(user_id, session_id)

        with self.cache_lock:
            # å…ˆæ£€æŸ¥å†…å­˜ç¼“å­˜
            if queue_key in self.memory_cache:
                queue = self.memory_cache[queue_key]
                queue.last_accessed = datetime.now().isoformat()
                return queue

            # ä»æ–‡ä»¶åŠ è½½
            queue = self._load_from_file(queue_key)
            if queue:
                self._add_to_cache(queue_key, queue)
                queue.last_accessed = datetime.now().isoformat()

            return queue

    def save_queue(self, queue: TaskQueue):
        """ä¿å­˜é˜Ÿåˆ—"""
        with self.cache_lock:
            self._add_to_cache(queue.queue_key, queue)
            self._save_to_file(queue)

    def create_queue(
        self,
        user_id: str,
        session_id: str,
        tasks: List[TaskItem],
        original_user_query: str = ""
    ) -> TaskQueue:
        """åˆ›å»ºæ–°é˜Ÿåˆ—"""
        queue_key = self._generate_queue_key(user_id, session_id)
        queue = TaskQueue(
            queue_key=queue_key,
            user_id=user_id,
            session_id=session_id,
            tasks=tasks,
            original_user_query=original_user_query
        )

        self.save_queue(queue)
        return queue

    async def execute_queue(
        self,
        user_id: str,
        session_id: str,
        task_executor: Optional[Any] = None
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        æ‰§è¡Œé˜Ÿåˆ—ä¸­çš„ä»»åŠ¡

        Args:
            user_id: ç”¨æˆ·ID
            session_id: ä¼šè¯ID

        Yields:
            Dict: ä»»åŠ¡æ‰§è¡ŒçŠ¶æ€äº‹ä»¶
        """
        queue = self.get_queue(user_id, session_id)
        if not queue:
            yield {
                "event_type": "error",
                "content": "ä»»åŠ¡é˜Ÿåˆ—ä¸å­˜åœ¨"
            }
            return

        try:
            while queue.has_pending_tasks():
                task = queue.get_current_task()
                if not task:
                    break

                # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                task.status = "running"
                self.save_queue(queue)

                yield {
                    "event_type": "task_start",
                    "content": f"å¼€å§‹æ‰§è¡Œä»»åŠ¡: {task.action}",
                    "metadata": {
                        "task_id": task.id,
                        "action": task.action,
                        "total_tasks": len(queue.tasks),
                        "current_index": queue.current_task_index + 1
                    }
                }

                # æ‰§è¡Œä»»åŠ¡ï¼ˆå¯æ³¨å…¥æ‰§è¡Œå™¨ï¼‰
                result = ""
                if task_executor:
                    result = await task_executor(task)

                # æ ‡è®°ä»»åŠ¡å®Œæˆ
                queue.mark_current_completed(result)
                self.save_queue(queue)

                yield {
                    "event_type": "task_complete",
                    "content": f"ä»»åŠ¡å®Œæˆ: {task.action}",
                    "metadata": {
                        "task_id": task.id,
                        "action": task.action,
                        "total_tasks": len(queue.tasks),
                        "current_index": queue.current_task_index
                    }
                }

            yield {
                "event_type": "queue_complete",
                "content": "æ‰€æœ‰ä»»åŠ¡æ‰§è¡Œå®Œæˆ"
            }

        except Exception as e:
            self.logger.error(f"æ‰§è¡Œä»»åŠ¡é˜Ÿåˆ—å¤±è´¥: {e}")
            yield {
                "event_type": "error",
                "content": f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}"
            }

    def _add_to_cache(self, queue_key: str, queue: TaskQueue):
        """æ·»åŠ åˆ°å†…å­˜ç¼“å­˜"""
        if len(self.memory_cache) >= self.max_cache_size:
            # ç®€å•çš„LRUç­–ç•¥ï¼šåˆ é™¤ç¬¬ä¸€ä¸ª
            first_key = next(iter(self.memory_cache))
            del self.memory_cache[first_key]

        self.memory_cache[queue_key] = queue


# ==================== ğŸ†• å…¨å±€å®ä¾‹ ====================

_unified_memory_manager: Optional[UnifiedMemoryManager] = None
_task_queue_manager: Optional[TaskQueueManager] = None


def get_unified_memory_manager() -> UnifiedMemoryManager:
    """è·å–ç»Ÿä¸€è®°å¿†ç®¡ç†å™¨å•ä¾‹"""
    global _unified_memory_manager
    if _unified_memory_manager is None:
        _unified_memory_manager = UnifiedMemoryManager()
    return _unified_memory_manager


def get_task_queue_manager() -> TaskQueueManager:
    """è·å–ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†å™¨å•ä¾‹"""
    global _task_queue_manager
    if _task_queue_manager is None:
        _task_queue_manager = TaskQueueManager()
    return _task_queue_manager
