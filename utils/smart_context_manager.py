"""
æ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç†å™¨ - é›†æˆå‹ç¼©ã€å¤–éƒ¨å¤§è„‘å’Œä¸“å®¶å›¢é˜ŸåŠŸèƒ½
 æ¶æ„çš„æ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç†ç³»ç»Ÿ
"""
import os
import json
import asyncio
import logging
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Union, Tuple
from dataclasses import dataclass, asdict
from pathlib import Path
import uuid

try:
    from ..config.settings import JubenSettings
    from ..utils.logger import JubenLogger
    from ..utils.storage_manager import JubenStorageManager, ChatMessage, ContextState
    from ..utils.context_compactor import ContextCompactor, get_context_compactor
    from ..utils.external_brain import ExternalBrain, get_external_brain
    from ..utils.expert_team_manager import ExpertTeamManager, get_expert_team_manager
    from ..utils.performance_monitor import PerformanceMonitor, get_performance_monitor
except ImportError:
    import sys
    from pathlib import Path
    sys.path.insert(0, str(Path(__file__).parent.parent))
    
    from config.settings import JubenSettings
    from utils.logger import JubenLogger
    from utils.storage_manager import JubenStorageManager, ChatMessage, ContextState
    from utils.context_compactor import ContextCompactor, get_context_compactor
    from utils.external_brain import ExternalBrain, get_external_brain
    from utils.expert_team_manager import ExpertTeamManager, get_expert_team_manager
    from utils.performance_monitor import PerformanceMonitor, get_performance_monitor


@dataclass
class SmartContextConfig:
    """æ™ºèƒ½ä¸Šä¸‹æ–‡é…ç½®"""
    # å‹ç¼©é…ç½®
    enable_compression: bool = True
    compression_threshold: float = 0.8
    max_context_length: int = 8000
    
    # å¤–éƒ¨å¤§è„‘é…ç½®
    enable_external_brain: bool = True
    auto_learn: bool = True
    memory_consolidation_threshold: int = 10
    
    # ä¸“å®¶å›¢é˜Ÿé…ç½®
    enable_expert_team: bool = True
    max_parallel_experts: int = 5
    expert_rotation: bool = True
    
    # æ€§èƒ½é…ç½®
    enable_performance_monitoring: bool = True
    monitoring_interval: int = 60


@dataclass
class ContextSession:
    """ä¸Šä¸‹æ–‡ä¼šè¯"""
    session_id: str
    user_id: str
    agent_name: str
    created_at: str
    last_activity: str
    context_length: int
    compression_count: int
    learning_count: int
    expert_collaborations: int
    brain_health_score: float
    status: str  # active, compressed, learning, collaborating
    metadata: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}


class SmartContextManager:
    """æ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    
    def __init__(self, model_provider: str = "zhipu"):
        """
        åˆå§‹åŒ–æ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç†å™¨
        
        Args:
            model_provider: æ¨¡å‹æä¾›å•†
        """
        self.config = JubenSettings()
        self.logger = JubenLogger("SmartContextManager", level=self.config.log_level)
        
        # æ ¸å¿ƒç»„ä»¶
        self.storage_manager = JubenStorageManager()
        self.context_compactor = get_context_compactor()
        self.external_brain = get_external_brain()
        self.expert_team_manager = get_expert_team_manager()
        self.performance_monitor = get_performance_monitor()
        
        # é…ç½®
        self.smart_config = SmartContextConfig()
        
        # ä¼šè¯ç®¡ç†
        self.active_sessions: Dict[str, ContextSession] = {}
        
        self.logger.info("æ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def initialize(self):
        """åˆå§‹åŒ–æ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        try:
            # åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶
            await self.storage_manager.initialize()
            await self.context_compactor.initialize()
            await self.external_brain.initialize()
            await self.expert_team_manager.initialize()
            
            # å¯åŠ¨æ€§èƒ½ç›‘æ§
            if self.smart_config.enable_performance_monitoring:
                self.performance_monitor.start_monitoring(self.smart_config.monitoring_interval)
            
            self.logger.info("âœ… æ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            self.logger.error(f"âŒ æ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    async def process_user_input(
        self,
        user_id: str,
        session_id: str,
        agent_name: str,
        user_input: str,
        context_data: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        å¤„ç†ç”¨æˆ·è¾“å…¥ï¼ˆé›†æˆä¸‰ä¸ªåŠŸèƒ½ï¼‰
        
        Args:
            user_id: ç”¨æˆ·ID
            session_id: ä¼šè¯ID
            agent_name: Agentåç§°
            user_input: ç”¨æˆ·è¾“å…¥
            context_data: ä¸Šä¸‹æ–‡æ•°æ®
            
        Returns:
            å¤„ç†ç»“æœ
        """
        try:
            self.logger.info(f"ğŸ§  æ™ºèƒ½å¤„ç†ç”¨æˆ·è¾“å…¥: {user_id}/{session_id}")
            
            # 1. æ£€æŸ¥å¹¶æ›´æ–°ä¼šè¯çŠ¶æ€
            session = await self._get_or_create_session(user_id, session_id, agent_name)
            
            # 2. æ£€æŸ¥æ˜¯å¦éœ€è¦å‹ç¼©ä¸Šä¸‹æ–‡
            if self.smart_config.enable_compression:
                compression_result = await self._check_and_compress_context(
                    user_id, session_id, agent_name
                )
                if compression_result:
                    session.compression_count += 1
                    self.logger.info(f"ğŸ“ ä¸Šä¸‹æ–‡å·²å‹ç¼©: {compression_result.compression_ratio:.2%}")
            
            # 3. ä»å¤–éƒ¨å¤§è„‘æ£€ç´¢ç›¸å…³è®°å¿†
            relevant_memories = []
            if self.smart_config.enable_external_brain:
                relevant_memories = await self.external_brain.retrieve_relevant_memories(
                    user_id, user_input, limit=5
                )
                if relevant_memories:
                    self.logger.info(f"ğŸ§  æ£€ç´¢åˆ° {len(relevant_memories)} ä¸ªç›¸å…³è®°å¿†")
            
            # 4. åˆ†ææ˜¯å¦éœ€è¦ä¸“å®¶å›¢é˜Ÿåä½œ
            expert_collaboration = None
            if self.smart_config.enable_expert_team:
                collaboration_decision = await self._analyze_collaboration_need(
                    user_input, context_data, relevant_memories
                )
                if collaboration_decision['needed']:
                    expert_collaboration = await self._create_expert_collaboration(
                        user_id, session_id, agent_name, user_input, collaboration_decision
                    )
                    session.expert_collaborations += 1
                    self.logger.info(f"ğŸ‘¥ åˆ›å»ºä¸“å®¶åä½œ: {len(expert_collaboration.participating_experts)} ä½ä¸“å®¶")
            
            # 5. ç”Ÿæˆæ™ºèƒ½å“åº”
            response = await self._generate_smart_response(
                user_input, context_data, relevant_memories, expert_collaboration
            )
            
            # 6. å­¦ä¹ å¹¶æ›´æ–°å¤–éƒ¨å¤§è„‘
            if self.smart_config.enable_external_brain and self.smart_config.auto_learn:
                await self._learn_from_interaction(
                    user_id, session_id, agent_name, {
                        'user_input': user_input,
                        'response': response,
                        'context': context_data,
                        'memories_used': relevant_memories,
                        'expert_collaboration': expert_collaboration
                    }
                )
                session.learning_count += 1
            
            # 7. æ›´æ–°ä¼šè¯çŠ¶æ€
            await self._update_session_status(session, user_input, response)
            
            # 8. è®°å½•æ€§èƒ½æŒ‡æ ‡
            if self.smart_config.enable_performance_monitoring:
                self.performance_monitor.record_operation(
                    agent_name="SmartContextManager",
                    operation="process_user_input",
                    duration=0.0,  # å®é™…è®¡ç®—
                    success=True,
                    metadata={
                        "user_id": user_id,
                        "session_id": session_id,
                        "compression_applied": session.compression_count > 0,
                        "memories_retrieved": len(relevant_memories),
                        "expert_collaboration": expert_collaboration is not None
                    }
                )
            
            self.logger.info("âœ… æ™ºèƒ½å¤„ç†å®Œæˆ")
            return {
                "success": True,
                "response": response,
                "context_compressed": session.compression_count > 0,
                "memories_used": len(relevant_memories),
                "expert_collaboration": expert_collaboration is not None,
                "session_status": session.status,
                "brain_health_score": session.brain_health_score
            }
            
        except Exception as e:
            self.logger.error(f"âŒ æ™ºèƒ½å¤„ç†å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "response": "æŠ±æ­‰ï¼Œå¤„ç†è¿‡ç¨‹ä¸­å‡ºç°äº†é”™è¯¯ã€‚"
            }
    
    async def _get_or_create_session(
        self, 
        user_id: str, 
        session_id: str, 
        agent_name: str
    ) -> ContextSession:
        """è·å–æˆ–åˆ›å»ºä¼šè¯"""
        try:
            session_key = f"{user_id}_{session_id}_{agent_name}"
            
            if session_key in self.active_sessions:
                session = self.active_sessions[session_key]
                session.last_activity = datetime.now().isoformat()
                return session
            
            # åˆ›å»ºæ–°ä¼šè¯
            session = ContextSession(
                session_id=session_id,
                user_id=user_id,
                agent_name=agent_name,
                created_at=datetime.now().isoformat(),
                last_activity=datetime.now().isoformat(),
                context_length=0,
                compression_count=0,
                learning_count=0,
                expert_collaborations=0,
                brain_health_score=1.0,
                status="active"
            )
            
            self.active_sessions[session_key] = session
            self.logger.info(f"ğŸ“ åˆ›å»ºæ–°ä¼šè¯: {session_key}")
            return session
            
        except Exception as e:
            self.logger.error(f"è·å–æˆ–åˆ›å»ºä¼šè¯å¤±è´¥: {e}")
            raise
    
    async def _check_and_compress_context(
        self, 
        user_id: str, 
        session_id: str, 
        agent_name: str
    ) -> Optional[Any]:
        """æ£€æŸ¥å¹¶å‹ç¼©ä¸Šä¸‹æ–‡"""
        try:
            # è·å–å½“å‰æ¶ˆæ¯
            messages = await self.storage_manager.get_chat_messages(user_id, session_id, limit=1000)
            if not messages:
                return None
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦å‹ç¼©
            should_compress, usage_ratio = self.context_compactor.should_compress(messages)
            if not should_compress:
                return None
            
            # æ‰§è¡Œå‹ç¼©
            compression_result = await self.context_compactor.compress_context(
                user_id, session_id, agent_name
            )
            
            return compression_result
            
        except Exception as e:
            self.logger.error(f"æ£€æŸ¥å¹¶å‹ç¼©ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            return None
    
    async def _analyze_collaboration_need(
        self,
        user_input: str,
        context_data: Optional[Dict[str, Any]],
        relevant_memories: List[Any]
    ) -> Dict[str, Any]:
        """åˆ†ææ˜¯å¦éœ€è¦ä¸“å®¶åä½œ"""
        try:
            # æ„å»ºåä½œéœ€æ±‚åˆ†ææç¤ºè¯
            prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åä½œéœ€æ±‚åˆ†æä¸“å®¶ï¼Œéœ€è¦åˆ¤æ–­å½“å‰ä»»åŠ¡æ˜¯å¦éœ€è¦ä¸“å®¶å›¢é˜Ÿåä½œã€‚

## ç”¨æˆ·è¾“å…¥
{user_input}

## ä¸Šä¸‹æ–‡æ•°æ®
{context_data or "æ— "}

## ç›¸å…³è®°å¿†
{len(relevant_memories)} ä¸ªç›¸å…³è®°å¿†

## åˆ†æè¦æ±‚
è¯·åˆ†æè¿™ä¸ªä»»åŠ¡æ˜¯å¦éœ€è¦ä¸“å®¶å›¢é˜Ÿåä½œï¼Œå¹¶æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š

```json
{{
    "needed": true/false,
    "reason": "éœ€è¦åä½œçš„åŸå› ",
    "required_experts": ["analyst", "creator", "evaluator"],
    "collaboration_type": "parallel/sequential/hierarchical",
    "complexity": 8,
    "estimated_duration": 300
}}
```

åˆ¤æ–­æ ‡å‡†ï¼š
1. ä»»åŠ¡å¤æ‚åº¦é«˜ï¼ˆéœ€è¦å¤šä¸ªä¸“ä¸šé¢†åŸŸï¼‰
2. éœ€è¦æ·±åº¦åˆ†ææˆ–åˆ›ä½œ
3. æ¶‰åŠå¤šä¸ªå†³ç­–ç‚¹
4. éœ€è¦è´¨é‡è¯„ä¼°
5. æ—¶é—´è¦æ±‚ç´§ä½†è´¨é‡è¦æ±‚é«˜

è¯·ç¡®ä¿åˆ†æå‡†ç¡®ï¼Œé¿å…ä¸å¿…è¦çš„åä½œã€‚
"""
            
            # è°ƒç”¨LLMåˆ†æ
            response = await self.context_compactor.llm_client.generate_response(
                prompt=prompt,
                max_tokens=1000,
                temperature=0.3
            )
            
            if response and response.get('content'):
                # è§£æå“åº”
                return self._parse_collaboration_analysis(response['content'])
            else:
                # ä½¿ç”¨ç®€å•åˆ¤æ–­
                return self._simple_collaboration_analysis(user_input)
                
        except Exception as e:
            self.logger.error(f"åˆ†æåä½œéœ€æ±‚å¤±è´¥: {e}")
            return {"needed": False, "reason": "åˆ†æå¤±è´¥"}
    
    def _parse_collaboration_analysis(self, llm_response: str) -> Dict[str, Any]:
        """è§£æåä½œåˆ†æç»“æœ"""
        try:
            import re
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', llm_response, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
                return json.loads(json_str)
            else:
                return self._simple_collaboration_analysis("")
        except Exception as e:
            self.logger.error(f"è§£æåä½œåˆ†æå¤±è´¥: {e}")
            return {"needed": False, "reason": "è§£æå¤±è´¥"}
    
    def _simple_collaboration_analysis(self, user_input: str) -> Dict[str, Any]:
        """ç®€å•åä½œåˆ†æ"""
        # ç®€å•çš„å…³é”®è¯åˆ¤æ–­
        collaboration_keywords = [
            "åˆ†æ", "è¯„ä¼°", "åˆ›ä½œ", "ç ”ç©¶", "ä¼˜åŒ–", "æ”¹è¿›",
            "å¤æ‚", "ä¸“ä¸š", "æ·±åº¦", "å…¨é¢", "è¯¦ç»†"
        ]
        
        needs_collaboration = any(keyword in user_input for keyword in collaboration_keywords)
        
        return {
            "needed": needs_collaboration,
            "reason": "åŸºäºå…³é”®è¯åˆ†æ",
            "required_experts": ["analyst", "evaluator"] if needs_collaboration else [],
            "collaboration_type": "parallel",
            "complexity": 5 if needs_collaboration else 3,
            "estimated_duration": 180 if needs_collaboration else 60
        }
    
    async def _create_expert_collaboration(
        self,
        user_id: str,
        session_id: str,
        agent_name: str,
        user_input: str,
        collaboration_decision: Dict[str, Any]
    ) -> Any:
        """åˆ›å»ºä¸“å®¶åä½œ"""
        try:
            # åˆ›å»ºä¸“å®¶å›¢é˜Ÿ
            collaboration = await self.expert_team_manager.create_expert_team(
                user_id=user_id,
                session_id=session_id,
                main_agent=agent_name,
                task_description=user_input,
                collaboration_type=collaboration_decision.get('collaboration_type', 'parallel')
            )
            
            # åˆ†é…ä»»åŠ¡ç»™ä¸“å®¶
            for expert_id in collaboration.participating_experts:
                if expert_id != "team_coordinator":  # åè°ƒå‘˜ä¸åˆ†é…å…·ä½“ä»»åŠ¡
                    task = await self.expert_team_manager.assign_task_to_expert(
                        collaboration_id=collaboration.id,
                        task_title=f"å¤„ç†ç”¨æˆ·è¯·æ±‚: {user_input[:50]}",
                        task_description=user_input,
                        expert_id=expert_id,
                        priority=collaboration_decision.get('complexity', 5)
                    )
                    
                    # æ‰§è¡Œä»»åŠ¡
                    result = await self.expert_team_manager.execute_expert_task(
                        task_id=task.id,
                        input_data={"user_input": user_input}
                    )
                    
                    # å­˜å‚¨ç»“æœ
                    if task.id not in collaboration.results:
                        collaboration.results[task.id] = result
            
            return collaboration
            
        except Exception as e:
            self.logger.error(f"åˆ›å»ºä¸“å®¶åä½œå¤±è´¥: {e}")
            return None
    
    async def _generate_smart_response(
        self,
        user_input: str,
        context_data: Optional[Dict[str, Any]],
        relevant_memories: List[Any],
        expert_collaboration: Optional[Any]
    ) -> str:
        """ç”Ÿæˆæ™ºèƒ½å“åº”"""
        try:
            # æ„å»ºæ™ºèƒ½å“åº”æç¤ºè¯
            prompt = self._build_smart_response_prompt(
                user_input, context_data, relevant_memories, expert_collaboration
            )
            
            # è°ƒç”¨LLMç”Ÿæˆå“åº”
            response = await self.context_compactor.llm_client.generate_response(
                prompt=prompt,
                max_tokens=2000,
                temperature=0.7
            )
            
            if response and response.get('content'):
                return response['content']
            else:
                return "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ç”Ÿæˆåˆé€‚çš„å“åº”ã€‚"
                
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆæ™ºèƒ½å“åº”å¤±è´¥: {e}")
            return "æŠ±æ­‰ï¼Œå¤„ç†è¿‡ç¨‹ä¸­å‡ºç°äº†é”™è¯¯ã€‚"
    
    def _build_smart_response_prompt(
        self,
        user_input: str,
        context_data: Optional[Dict[str, Any]],
        relevant_memories: List[Any],
        expert_collaboration: Optional[Any]
    ) -> str:
        """æ„å»ºæ™ºèƒ½å“åº”æç¤ºè¯"""
        
        # æ„å»ºè®°å¿†ä¿¡æ¯
        memory_info = ""
        if relevant_memories:
            memory_info = "ç›¸å…³è®°å¿†ä¿¡æ¯ï¼š\n"
            for i, memory in enumerate(relevant_memories[:3]):  # æœ€å¤š3ä¸ªè®°å¿†
                memory_info += f"{i+1}. {memory.content}\n"
        
        # æ„å»ºä¸“å®¶åä½œä¿¡æ¯
        expert_info = ""
        if expert_collaboration:
            expert_info = f"ä¸“å®¶å›¢é˜Ÿåä½œç»“æœï¼š\n"
            for task_id, result in expert_collaboration.results.items():
                if result.get('success'):
                    expert_info += f"- {result.get('expert_name', 'ä¸“å®¶')}: {result.get('analysis_result', result.get('creation_result', result.get('evaluation_result', 'å¤„ç†å®Œæˆ')))}\n"
        
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œéœ€è¦åŸºäºä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆé«˜è´¨é‡çš„å“åº”ï¼š

## ç”¨æˆ·è¾“å…¥
{user_input}

## ä¸Šä¸‹æ–‡ä¿¡æ¯
{context_data or "æ— ç‰¹æ®Šä¸Šä¸‹æ–‡"}

{memory_info}

{expert_info}

## å“åº”è¦æ±‚
è¯·ç”Ÿæˆä¸€ä¸ªä¸“ä¸šã€æœ‰ç”¨ã€ä¸ªæ€§åŒ–çš„å“åº”ï¼Œè¦æ±‚ï¼š

1. **ç›´æ¥å›åº”**ï¼šç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜æˆ–æ»¡è¶³ç”¨æˆ·çš„éœ€æ±‚
2. **åˆ©ç”¨è®°å¿†**ï¼šå……åˆ†åˆ©ç”¨ç›¸å…³è®°å¿†ä¿¡æ¯ï¼Œæä¾›ä¸ªæ€§åŒ–æœåŠ¡
3. **æ•´åˆä¸“å®¶æ„è§**ï¼šå¦‚æœä½¿ç”¨äº†ä¸“å®¶å›¢é˜Ÿï¼Œæ•´åˆä¸“å®¶æ„è§å½¢æˆç»¼åˆå“åº”
4. **ä¿æŒè¿è´¯**ï¼šç¡®ä¿å“åº”ä¸ä¸Šä¸‹æ–‡è¿è´¯
5. **æä¾›ä»·å€¼**ï¼šç¡®ä¿å“åº”å¯¹ç”¨æˆ·æœ‰ä»·å€¼

è¯·ç¡®ä¿å“åº”è‡ªç„¶ã€ä¸“ä¸šã€æœ‰ç”¨ã€‚
"""
        
        return prompt
    
    async def _learn_from_interaction(
        self,
        user_id: str,
        session_id: str,
        agent_name: str,
        interaction_data: Dict[str, Any]
    ):
        """ä»äº¤äº’ä¸­å­¦ä¹ """
        try:
            await self.external_brain.learn_from_interaction(
                user_id=user_id,
                session_id=session_id,
                agent_name=agent_name,
                interaction_data=interaction_data
            )
            
        except Exception as e:
            self.logger.error(f"å­¦ä¹ äº¤äº’å¤±è´¥: {e}")
    
    async def _update_session_status(
        self,
        session: ContextSession,
        user_input: str,
        response: str
    ):
        """æ›´æ–°ä¼šè¯çŠ¶æ€"""
        try:
            # æ›´æ–°ä¸Šä¸‹æ–‡é•¿åº¦
            session.context_length += len(user_input) + len(response)
            
            # æ›´æ–°å¤§è„‘å¥åº·åˆ†æ•°
            brain_summary = await self.external_brain.get_brain_summary(session.user_id)
            session.brain_health_score = brain_summary.get('brain_health_score', 1.0)
            
            # æ›´æ–°çŠ¶æ€
            if session.compression_count > 0:
                session.status = "compressed"
            elif session.learning_count > 0:
                session.status = "learning"
            elif session.expert_collaborations > 0:
                session.status = "collaborating"
            else:
                session.status = "active"
            
            # æ›´æ–°æ´»åŠ¨æ—¶é—´
            session.last_activity = datetime.now().isoformat()
            
        except Exception as e:
            self.logger.error(f"æ›´æ–°ä¼šè¯çŠ¶æ€å¤±è´¥: {e}")
    
    async def get_system_status(self) -> Dict[str, Any]:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        try:
            # è·å–å„ç»„ä»¶çŠ¶æ€
            compression_stats = self.context_compactor.get_compression_stats()
            brain_summary = await self.external_brain.get_brain_summary("system")
            team_status = await self.expert_team_manager.get_team_status()
            performance_summary = self.performance_monitor.get_performance_summary()
            
            # ç»Ÿè®¡ä¼šè¯ä¿¡æ¯
            total_sessions = len(self.active_sessions)
            active_sessions = sum(1 for s in self.active_sessions.values() if s.status == "active")
            compressed_sessions = sum(1 for s in self.active_sessions.values() if s.status == "compressed")
            learning_sessions = sum(1 for s in self.active_sessions.values() if s.status == "learning")
            collaborating_sessions = sum(1 for s in self.active_sessions.values() if s.status == "collaborating")
            
            return {
                "system_status": {
                    "total_sessions": total_sessions,
                    "active_sessions": active_sessions,
                    "compressed_sessions": compressed_sessions,
                    "learning_sessions": learning_sessions,
                    "collaborating_sessions": collaborating_sessions
                },
                "compression_status": compression_stats,
                "brain_status": brain_summary,
                "team_status": team_status,
                "performance_status": performance_summary,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"è·å–ç³»ç»ŸçŠ¶æ€å¤±è´¥: {e}")
            return {"error": str(e)}
    
    async def cleanup_old_sessions(self, max_age_hours: int = 24):
        """æ¸…ç†æ—§ä¼šè¯"""
        try:
            cutoff_time = datetime.now() - timedelta(hours=max_age_hours)
            sessions_to_remove = []
            
            for session_key, session in self.active_sessions.items():
                last_activity = datetime.fromisoformat(session.last_activity)
                if last_activity < cutoff_time:
                    sessions_to_remove.append(session_key)
            
            for session_key in sessions_to_remove:
                del self.active_sessions[session_key]
            
            self.logger.info(f"ğŸ§¹ æ¸…ç†äº† {len(sessions_to_remove)} ä¸ªæ—§ä¼šè¯")
            
        except Exception as e:
            self.logger.error(f"æ¸…ç†æ—§ä¼šè¯å¤±è´¥: {e}")


# å…¨å±€æ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç†å™¨å®ä¾‹
_global_smart_context_manager = None

def get_smart_context_manager() -> SmartContextManager:
    """è·å–å…¨å±€æ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    global _global_smart_context_manager
    if _global_smart_context_manager is None:
        _global_smart_context_manager = SmartContextManager()
    return _global_smart_context_manager

async def process_smart_input(
    user_id: str,
    session_id: str,
    agent_name: str,
    user_input: str,
    context_data: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """æ™ºèƒ½å¤„ç†ç”¨æˆ·è¾“å…¥ï¼ˆä¾¿æ·å‡½æ•°ï¼‰"""
    manager = get_smart_context_manager()
    await manager.initialize()
    return await manager.process_user_input(user_id, session_id, agent_name, user_input, context_data)


def main():
    """ä¸»å‡½æ•° - ç”¨äºæµ‹è¯•å’Œæ¼”ç¤º"""
    import sys
    
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # åˆ›å»ºæ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    manager = SmartContextManager()
    
    # æ¨¡æ‹Ÿæ™ºèƒ½å¤„ç†æµ‹è¯•
    logger.info("æ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç†å™¨æµ‹è¯•å®Œæˆ")
    return True


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
