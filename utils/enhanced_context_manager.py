"""
å¢å¼ºå‹ä¸Šä¸‹æ–‡çª—å£ç®¡ç†å™¨ - ä¸“ä¸ºé•¿å‰§æœ¬è®¾è®¡
=====================================

åŸºäº2026å¹´æœ€æ–°ç ”ç©¶çš„ä¸Šä¸‹æ–‡ç®¡ç†æŠ€æœ¯ï¼š
1. Rolling Window + æ™ºèƒ½æ‘˜è¦æœºåˆ¶
2. è¯­ä¹‰åˆ†å— (Semantic Chunking)
3. åˆ†å±‚è®°å¿†æ¶æ„ (Hierarchical Memory)
4. Tokenæ„ŸçŸ¥å‹ç¼©
5. å…³é”®ä¿¡æ¯é”šå®š

å‚è€ƒèµ„æ–™ï¼š
- Best LLMs for Extended Context Windows in 2026 (AI Multiple)
- Context Window Overflow in 2026: Fix LLM Errors Fast (Redis Blog)
- Autonomous Memory Management in LLM Agents (arXiv 2026)
- Top techniques to Manage Context Lengths in LLMs (Agenta AI)
"""
import asyncio
import json
import logging
import re
from collections import deque
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from typing import Any, Callable, Deque, Dict, List, Optional, Tuple
from enum import Enum
import hashlib
from pathlib import Path

try:
    from ..config.settings import JubenSettings
    from ..utils.logger import JubenLogger
    from ..utils.llm_client import get_llm_client
    from ..utils.storage_manager import JubenStorageManager
except ImportError:
    import sys
    sys.path.insert(0, str(Path(__file__).parent.parent))
    from config.settings import JubenSettings
    from utils.logger import JubenLogger
    from utils.llm_client import get_llm_client
    from utils.storage_manager import JubenStorageManager


class MemoryLevel(Enum):
    """è®°å¿†å±‚çº§"""
    IMMEDIATE = "immediate"      # å³æ—¶è®°å¿† (å½“å‰å¯¹è¯ï¼Œçº¦2K tokens)
    RECENT = "recent"            # è¿‘æœŸè®°å¿† (æœ€è¿‘å‡ è½®ï¼Œçº¦5K tokens)
    WORKING = "working"          # å·¥ä½œè®°å¿† (å½“å‰ä¼šè¯ï¼Œçº¦10K tokens)
    LONG_TERM = "long_term"      # é•¿æœŸè®°å¿† (é‡è¦ä¿¡æ¯ï¼ŒæŒä¹…åŒ–)


class ChunkType(Enum):
    """åˆ†å—ç±»å‹"""
    DIALOGUE = "dialogue"        # å¯¹è¯å—
    ACTION = "action"            # åŠ¨ä½œæè¿°
    SCENE = "scene"              # åœºæ™¯åˆ‡æ¢
    PLOT_POINT = "plot_point"    # æƒ…èŠ‚ç‚¹
    CHARACTER = "character"      # è§’è‰²æè¿°
    SUMMARY = "summary"          # æ‘˜è¦å—


class EmotionalPointType(Enum):
    """æƒ…ç»ªç‚¹ç±»å‹ï¼ˆä¸“ä¸ºçŸ­å‰§è®¾è®¡ï¼‰"""
    TENSION = "tension"          # å‹å¼¹ç°§ï¼ˆç´§å¼ ã€å‹æŠ‘ã€æ„¤æ€’ã€æ†‹å±ˆï¼‰
    RELEASE = "release"          # æ”¾å¼¹ç°§ï¼ˆé‡Šæ”¾ã€æ‰“è„¸ã€åè½¬ã€çˆ½å¿«ï¼‰
    HOOK = "hook"                # é’©å­ï¼ˆæ‚¬å¿µã€å†²çªã€å¸å¼•ï¼‰
    CLIMAX = "climax"            # é«˜æ½®ï¼ˆçˆ†å‘ã€å†³æˆ˜ã€é«˜æ½®ï¼‰
    TWIST = "twist"              # è½¬æŠ˜ï¼ˆåè½¬ã€æ„å¤–ã€çœŸç›¸ï¼‰


@dataclass
class EmotionalPoint:
    """æƒ…ç»ªç‚¹æ•°æ®ç»“æ„"""
    content: str                 # æƒ…ç»ªç‚¹å†…å®¹
    point_type: EmotionalPointType  # æƒ…ç»ªç‚¹ç±»å‹
    importance: float            # é‡è¦æ€§è¯„åˆ† (0-1)
    position: int                # åœ¨åŸæ–‡ä¸­çš„ä½ç½®
    metadata: Dict[str, Any] = field(default_factory=dict)  # å…ƒæ•°æ®


@dataclass
class TokenBudget:
    """Tokené¢„ç®—é…ç½®"""
    max_context_tokens: int = 128000       # æœ€å¤§ä¸Šä¸‹æ–‡ (GLM-4-Flashæ”¯æŒ)
    safety_margin: int = 10000             # å®‰å…¨è¾¹ç•Œ
    system_prompt_tokens: int = 2000       # ç³»ç»Ÿæç¤ºè¯
    immediate_budget: int = 2000           # å³æ—¶è®°å¿†é¢„ç®—
    recent_budget: int = 5000              # è¿‘æœŸè®°å¿†é¢„ç®—
    working_budget: int = 10000            # å·¥ä½œè®°å¿†é¢„ç®—
    long_term_budget: int = 5000           # é•¿æœŸè®°å¿†é¢„ç®—
    response_budget: int = 8000            # å“åº”é¢„ç®—

    def available_for_input(self) -> int:
        """å¯ç”¨äºè¾“å…¥çš„tokenæ•°"""
        total_reserved = (
            self.system_prompt_tokens +
            self.immediate_budget +
            self.recent_budget +
            self.working_budget +
            self.long_term_budget +
            self.response_budget
        )
        return self.max_context_tokens - total_reserved


@dataclass
class ContextWindow:
    """
    ä¸Šä¸‹æ–‡çª—å£çŠ¶æ€ï¼ˆå¢å¼ºç‰ˆï¼šå¸¦ç»“æ„åŒ–éš”ç¦»ï¼‰

    éš”ç¦»å±‚çº§ï¼š
    - messages: å‘é€ç»™LLMçš„å¯¹è¯æ¶ˆæ¯
    - internal_notes: å†…éƒ¨ç¬”è®°ï¼Œä¸å‘é€ç»™LLMï¼Œç”¨äºï¼š
      * å­ä»»åŠ¡ç»“æœç¼“å­˜
      * ä¸­é—´å¤„ç†çŠ¶æ€
      * è°ƒè¯•ä¿¡æ¯
      * æ€§èƒ½ç»Ÿè®¡
    - scratchpad: è‰ç¨¿çº¸ï¼Œç”¨äºä¸´æ—¶å­˜å‚¨å’Œç­›é€‰
    """
    # ========== æ¶ˆæ¯å±‚ï¼ˆå‘é€ç»™LLMï¼‰ ==========
    immediate: List[Dict[str, Any]] = field(default_factory=list)  # å³æ—¶å¯¹è¯
    recent: Deque[Dict[str, Any]] = field(default_factory=deque)  # è¿‘æœŸå¯¹è¯
    working: List[Dict[str, Any]] = field(default_factory=list)  # å·¥ä½œè®°å¿†
    long_term_summary: str = ""  # é•¿æœŸæ‘˜è¦
    key_anchors: List[str] = field(default_factory=list)  # å…³é”®é”šç‚¹

    # ========== å†…éƒ¨ç¬”è®°å±‚ï¼ˆä¸å‘é€ç»™LLMï¼‰ ==========
    internal_notes: List[Dict[str, Any]] = field(default_factory=list)  # å†…éƒ¨ç¬”è®°
    subtask_results: Dict[str, Any] = field(default_factory=dict)  # å­ä»»åŠ¡ç»“æœ
    scratchpad: List[Dict[str, Any]] = field(default_factory=list)  # è‰ç¨¿çº¸

    # ========== å…ƒæ•°æ® ==========
    total_tokens: int = 0
    last_compression: str = ""
    compression_count: int = 0
    is_healthy: bool = True
    version: int = 0
    last_updated: str = ""

    # ç»Ÿè®¡
    message_count: int = 0
    character_mentions: Dict[str, int] = field(default_factory=dict)
    plot_points: List[str] = field(default_factory=list)

    # ========== æ–°å¢ï¼šéš”ç¦»æ§åˆ¶ ==========
    max_internal_notes: int = 100  # å†…éƒ¨ç¬”è®°æœ€å¤§æ•°é‡
    max_scratchpad_size: int = 50  # è‰ç¨¿çº¸æœ€å¤§å¤§å°


@dataclass
class SemanticChunk:
    """è¯­ä¹‰åˆ†å—"""
    id: str
    content: str
    chunk_type: ChunkType
    token_count: int
    importance: float  # 0-1
    keywords: List[str] = field(default_factory=list)
    characters: List[str] = field(default_factory=list)
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class ScriptMemory:
    """å‰§æœ¬è®°å¿†"""
    session_id: str
    user_id: str

    # è§’è‰²è®°å¿†
    characters: Dict[str, Dict[str, Any]] = field(default_factory=dict)

    # æƒ…èŠ‚çº¿è®°å¿†
    plot_threads: List[Dict[str, Any]] = field(default_factory=list)

    # å…³é”®å†³ç­–
    key_decisions: List[Dict[str, Any]] = field(default_factory=list)

    # åœºæ™¯è®°å¿†
    scenes: List[Dict[str, Any]] = field(default_factory=list)

    # å…ƒæ•°æ®
    created_at: str = field(default_factory=lambda: datetime.now().isoformat())
    updated_at: str = field(default_factory=lambda: datetime.now().isoformat())
    version: int = 1


@dataclass
class GraphMemory:
    """å›¾ç»“æ„è®°å¿†ï¼ˆé¢å‘å‰§æƒ…ä¸è§’è‰²å…³ç³»ï¼‰"""
    nodes: Dict[str, Dict[str, Any]] = field(default_factory=dict)
    edges: List[Dict[str, Any]] = field(default_factory=list)
    updated_at: str = field(default_factory=lambda: datetime.now().isoformat())

    def upsert_node(self, node_id: str, node_type: str, label: str, meta: Optional[Dict[str, Any]] = None):
        self.nodes[node_id] = {
            "id": node_id,
            "type": node_type,
            "label": label,
            "meta": meta or {},
            "updated_at": datetime.now().isoformat()
        }
        self.updated_at = datetime.now().isoformat()

    def add_edge(self, source: str, target: str, edge_type: str, meta: Optional[Dict[str, Any]] = None):
        self.edges.append({
            "source": source,
            "target": target,
            "type": edge_type,
            "meta": meta or {},
            "created_at": datetime.now().isoformat()
        })
        self.updated_at = datetime.now().isoformat()


class EnhancedContextManager:
    """
    å¢å¼ºå‹ä¸Šä¸‹æ–‡ç®¡ç†å™¨

    æ ¸å¿ƒç‰¹æ€§ï¼š
    1. æ»šåŠ¨çª—å£æœºåˆ¶ (Rolling Window)
    2. æ™ºèƒ½æ‘˜è¦å‹ç¼© (Intelligent Summary)
    3. è¯­ä¹‰åˆ†å— (Semantic Chunking)
    4. å…³é”®ä¿¡æ¯é”šå®š (Key Information Anchoring)
    5. Tokené¢„ç®—ç®¡ç† (Token Budgeting)
    """

    def __init__(self, model_provider: str = "zhipu", model: str = "glm-4-flash"):
        self.config = JubenSettings()
        self.logger = JubenLogger("EnhancedContextManager", level=self.config.log_level)

        # Tokené¢„ç®—
        self.budget = TokenBudget()

        # LLMå®¢æˆ·ç«¯
        self.llm_client = get_llm_client(model_provider, model=model)

        # å­˜å‚¨ç®¡ç†å™¨
        from utils.storage_manager import get_storage
        self.storage_manager = get_storage()

        # ä¸Šä¸‹æ–‡çª—å£
        self.context_windows: Dict[str, ContextWindow] = {}

        # å‰§æœ¬è®°å¿†
        self.script_memories: Dict[str, ScriptMemory] = {}
        # å›¾ç»“æ„è®°å¿†
        self.graph_memories: Dict[str, GraphMemory] = {}

        # é…ç½®
        self.rolling_window_size = 10  # æ»šåŠ¨çª—å£å¤§å°ï¼ˆæ¶ˆæ¯æ•°ï¼‰
        self.compression_threshold = 0.85  # å‹ç¼©é˜ˆå€¼
        self.summary_target_ratio = 0.3  # æ‘˜è¦ç›®æ ‡æ¯”ä¾‹

    def _touch_window(self, window: ContextWindow):
        """æ›´æ–°çª—å£ç‰ˆæœ¬ä¸æ—¶é—´æˆ³"""
        window.version += 1
        window.last_updated = datetime.now().isoformat()

        # ğŸ†• ã€æ–°å¢ã€‘æƒ…ç»ªç‚¹æ£€æµ‹å…³é”®è¯ï¼ˆä¸“ä¸ºçŸ­å‰§è®¾è®¡ï¼‰
        self.emotional_keywords = {
            EmotionalPointType.TENSION: [
                "å‹æŠ‘", "æ†‹å±ˆ", "æ„¤æ€’", "ä¸ç”˜", "ç»æœ›", "ç—›è‹¦", "æŒ£æ‰",
                "å±æœº", "å¨èƒ", "é€¼è¿«", "æ¬ºå‡Œ", "ç¾è¾±", "é™·å®³", "è¯¯ä¼š",
                "ç´§ç»·", "çª’æ¯", "æ²‰é‡", "ç…ç†¬", "ç…ç†¬", "ç…ç†¬",
                "å‹å¼¹ç°§", "ç§¯è“„", "ç´§å¼ ", "æƒŠé™©", "å±æ€¥"
            ],
            EmotionalPointType.RELEASE: [
                "çˆ†å‘", "åå‡»", "æ‰“è„¸", "åè½¬", "çˆ½å¿«", "ç—›å¿«", "è§£æ°”",
                "çœŸç›¸å¤§ç™½", "é€†è¢­", "æˆåŠŸ", "èƒœåˆ©", "å‡»è´¥", "æˆ˜èƒœ",
                "æ”¾å¼¹ç°§", "é‡Šæ”¾", "ç—›å¿«", "é…£ç•…æ·‹æ¼“", "æ‰¬çœ‰åæ°”",
                "ç—›å¿«", "èˆ’ç•…", "æ»¡è¶³", "æ¬£å–œ", "æŒ¯å¥‹"
            ],
            EmotionalPointType.HOOK: [
                "çªç„¶", "æ„å¤–", "éœ‡æƒŠ", "æƒŠå‘†", "ä¸æ•¢ç›¸ä¿¡", "ç«Ÿç„¶",
                "å±…ç„¶", "æ„æƒ³ä¸åˆ°", "çªå‘", "çŒ›ç„¶", "ç¬é—´",
                "æ‚¬å¿µ", "ç–‘æƒ‘", "è°œå›¢", "ç–‘é—®", "å›°æƒ‘",
                "ç­‰ç­‰", "æ…¢ç€", "ä¸å¯¹", "å¥‡æ€ª"
            ],
            EmotionalPointType.CLIMAX: [
                "é«˜æ½®", "å·…å³°", "å†³æˆ˜", "ç”Ÿæ­»", "å…³é”®æ—¶åˆ»", "æœ€å",
                "ç»ˆæ", "æœ€ç»ˆ", "çˆ†å‘", "å†³æˆ˜", "å¯¹å†³", "å¯¹å†³",
                "æœ€é«˜æ½®", "æœ€æ¿€çƒˆ", "å†³å®šæ€§", "å…³é”®æ—¶åˆ»"
            ],
            EmotionalPointType.TWIST: [
                "åè½¬", "è½¬æŠ˜", "çœŸç›¸", "åŸæ¥", "ç«Ÿç„¶æ˜¯", "å±…ç„¶æ˜¯",
                "æ²¡æƒ³åˆ°", "æ„å¤–çš„æ˜¯", "å‡ºäººæ„æ–™", "å³°å›è·¯è½¬",
                "çœŸç›¸å¤§ç™½", "æç„¶å¤§æ‚Ÿ", "åŸæ¥å¦‚æ­¤", "æ„æƒ³ä¸åˆ°"
            ]
        }

        # æƒ…ç»ªç‚¹ä¿æŠ¤æƒé‡ï¼ˆå‹ç¼©æ—¶çš„ä¿æŠ¤çº§åˆ«ï¼‰
        self.emotion_protection_weights = {
            EmotionalPointType.CLIMAX: 1.0,    # æœ€é«˜ä¿æŠ¤
            EmotionalPointType.TWIST: 0.9,     # é«˜ä¿æŠ¤
            EmotionalPointType.RELEASE: 0.8,   # è¾ƒé«˜ä¿æŠ¤
            EmotionalPointType.TENSION: 0.7,   # ä¸­ç­‰ä¿æŠ¤
            EmotionalPointType.HOOK: 0.6       # åŸºç¡€ä¿æŠ¤
        }

        self.logger.info("å¢å¼ºå‹ä¸Šä¸‹æ–‡ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")

    async def initialize(self):
        """åˆå§‹åŒ–ç®¡ç†å™¨"""
        await self.storage_manager.initialize()
        self.logger.info("âœ… å¢å¼ºå‹ä¸Šä¸‹æ–‡ç®¡ç†å™¨å·²åˆå§‹åŒ–")

    # ==================== Token è®¡ç®— ====================

    def count_tokens(self, text: str) -> int:
        """
        æ›´å‡†ç¡®çš„Tokenè®¡æ•°

        åŸºäºGLM-4-Flashçš„å®é™…tokenizerç‰¹æ€§ä¼˜åŒ–
        """
        if not text:
            return 0

        # ä¸­æ–‡ï¼šçº¦1å­—ç¬¦=1token
        chinese_chars = sum(1 for c in text if '\u4e00' <= c <= '\u9fff')
        # è‹±æ–‡/æ•°å­—ï¼šçº¦4å­—ç¬¦=1token
        other_chars = len(text) - chinese_chars

        return chinese_chars + max(1, other_chars // 4)

    def count_message_tokens(self, message: Dict[str, Any]) -> int:
        """è®¡ç®—æ¶ˆæ¯çš„tokenæ•°"""
        content = message.get("content", "")
        role = message.get("role", "")
        # è§’è‰²æ ‡è®°çº¦5 tokens
        return self.count_tokens(content) + 5

    def count_context_tokens(self, messages: List[Dict[str, Any]]) -> int:
        """è®¡ç®—ä¸Šä¸‹æ–‡æ€»tokenæ•°"""
        return sum(self.count_message_tokens(msg) for msg in messages)

    # ==================== è¯­ä¹‰åˆ†å— ====================

    async def semantic_chunk(
        self,
        text: str,
        chunk_type: ChunkType = ChunkType.DIALOGUE
    ) -> List[SemanticChunk]:
        """
        è¯­ä¹‰åˆ†å— - å°†é•¿æ–‡æœ¬æŒ‰è¯­ä¹‰è¾¹ç•Œåˆ†å‰²

        å‚è€ƒï¼šRAGè¯­ä¹‰åˆ†å—æœ€ä½³å®è·µ
        """
        chunks = []
        chunk_id = 0

        # æ ¹æ®ç±»å‹ä½¿ç”¨ä¸åŒçš„åˆ†å‰²ç­–ç•¥
        if chunk_type == ChunkType.DIALOGUE:
            chunks = await self._chunk_dialogue(text)
        elif chunk_type == ChunkType.SCENE:
            chunks = await self._chunk_by_scene(text)
        elif chunk_type == ChunkType.PLOT_POINT:
            chunks = await self._chunk_by_plot_point(text)
        else:
            chunks = await self._chunk_by_size(text)

        # ä¸ºæ¯ä¸ªåˆ†å—æ·»åŠ å…ƒæ•°æ®
        for chunk in chunks:
            chunk.chunk_type = chunk_type
            chunk.token_count = self.count_tokens(chunk.content)
            chunk.importance = await self._calculate_importance(chunk)
            chunk.keywords = self._extract_keywords(chunk.content)
            chunk.characters = self._extract_characters(chunk.content)

        self.logger.info(f"è¯­ä¹‰åˆ†å—å®Œæˆ: {len(chunks)} ä¸ªå—")
        return chunks

    async def _chunk_dialogue(self, text: str) -> List[SemanticChunk]:
        """æŒ‰å¯¹è¯åˆ†å‰²"""
        chunks = []
        # åŒ¹é…å¯¹è¯æ¨¡å¼ï¼šè§’è‰²å: å¯¹è¯å†…å®¹
        pattern = r'([^\n:]+):\s*([^\n]+)'
        matches = re.findall(pattern, text)

        current_chunk = ""
        chunk_id = 0

        for speaker, dialogue in matches:
            entry = f"{speaker}: {dialogue}\n"
            if len(current_chunk) + len(entry) > 500:  # çº¦500å­—ç¬¦ä¸€å—
                if current_chunk:
                    chunks.append(SemanticChunk(
                        id=f"dialogue_{chunk_id}",
                        content=current_chunk.strip()
                    ))
                    chunk_id += 1
                current_chunk = entry
            else:
                current_chunk += entry

        if current_chunk:
            chunks.append(SemanticChunk(
                id=f"dialogue_{chunk_id}",
                content=current_chunk.strip()
            ))

        return chunks if chunks else [SemanticChunk(id="dialogue_0", content=text)]

    async def _chunk_by_scene(self, text: str) -> List[SemanticChunk]:
        """æŒ‰åœºæ™¯åˆ†å‰²"""
        # æ£€æµ‹åœºæ™¯æ ‡è®°
        scene_markers = [
            r'\[åœºæ™¯[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+\]',
            r'\[.*?åœº.*?\]',
            r'ç¬¬.*?åœº',
            r'SCENE\s*\d+',
            r'INT\.|EXT\.',
            r'å†…æ™¯|å¤–æ™¯',
        ]

        # åˆå¹¶æ‰€æœ‰æ¨¡å¼
        combined_pattern = '|'.join(f'({pattern})' for pattern in scene_markers)
        parts = re.split(combined_pattern, text, flags=re.IGNORECASE)

        chunks = []
        chunk_id = 0
        current_chunk = ""

        for part in parts:
            if part:
                if len(current_chunk) + len(part) > 1000:
                    if current_chunk:
                        chunks.append(SemanticChunk(
                            id=f"scene_{chunk_id}",
                            content=current_chunk.strip()
                        ))
                        chunk_id += 1
                    current_chunk = part
                else:
                    current_chunk += part

        if current_chunk:
            chunks.append(SemanticChunk(id=f"scene_{chunk_id}", content=current_chunk.strip()))

        return chunks if chunks else [SemanticChunk(id="scene_0", content=text)]

    async def _chunk_by_plot_point(self, text: str) -> List[SemanticChunk]:
        """æŒ‰æƒ…èŠ‚ç‚¹åˆ†å‰²"""
        # æ£€æµ‹æƒ…èŠ‚æ ‡è®°
        plot_patterns = [
            r'æƒ…èŠ‚[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+',
            r'ç¬¬.*?èŠ‚',
            r'ã€.*?ã€‘',
            r'Plot\s*Point',
        ]

        combined_pattern = '|'.join(f'({pattern})' for pattern in plot_patterns)
        parts = re.split(combined_pattern, text, flags=re.IGNORECASE)

        chunks = []
        chunk_id = 0

        for part in parts:
            if part and len(part.strip()) > 50:
                chunks.append(SemanticChunk(
                    id=f"plot_{chunk_id}",
                    content=part.strip()
                ))
                chunk_id += 1

        return chunks if chunks else [SemanticChunk(id="plot_0", content=text)]

    async def _chunk_by_size(self, text: str, max_size: int = 800) -> List[SemanticChunk]:
        """æŒ‰å¤§å°åˆ†å‰²ï¼ˆä¿ç•™è¯­ä¹‰å®Œæ•´æ€§ï¼‰"""
        chunks = []
        sentences = re.split(r'([ã€‚ï¼ï¼Ÿ\n])', text)

        current_chunk = ""
        chunk_id = 0

        for i in range(0, len(sentences), 2):
            sentence = sentences[i]
            delimiter = sentences[i + 1] if i + 1 < len(sentences) else ""

            full_sentence = sentence + delimiter
            if len(current_chunk) + len(full_sentence) > max_size:
                if current_chunk:
                    chunks.append(SemanticChunk(
                        id=f"chunk_{chunk_id}",
                        content=current_chunk.strip()
                    ))
                    chunk_id += 1
                current_chunk = full_sentence
            else:
                current_chunk += full_sentence

        if current_chunk:
            chunks.append(SemanticChunk(id=f"chunk_{chunk_id}", content=current_chunk.strip()))

        return chunks

    def _extract_keywords(self, text: str) -> List[str]:
        """æå–å…³é”®è¯"""
        # ç®€å•çš„å…³é”®è¯æå–ï¼ˆå¯ä»¥å‡çº§ä¸ºä½¿ç”¨NLPæ¨¡å‹ï¼‰
        important_words = re.findall(r'[\u4e00-\u9fff]{2,}|[a-zA-Z]{3,}', text)
        # å»é‡å¹¶è¿”å›å‰10ä¸ª
        return list(set(important_words))[:10]

    def _extract_characters(self, text: str) -> List[str]:
        """æå–è§’è‰²å"""
        # åŒ¹é…å¸¸è§çš„è§’è‰²åæ¨¡å¼
        patterns = [
            r'([A-Z][a-z]+):',  # è‹±æ–‡å:
            r'([\u4e00-\u9fff]{2,4})[:ï¼š]',  # ä¸­æ–‡åï¼š
        ]

        characters = set()
        for pattern in patterns:
            matches = re.findall(pattern, text)
            characters.update(matches)

        # è¿‡æ»¤å¸¸è§éè§’è‰²è¯
        common_words = {'ç³»ç»Ÿ', 'ç”¨æˆ·', 'åŠ©æ‰‹', 'æ—ç™½', 'ç”»å¤–éŸ³'}
        return [c for c in characters if c not in common_words]

    async def _calculate_importance(self, chunk: SemanticChunk) -> float:
        """è®¡ç®—åˆ†å—é‡è¦æ€§"""
        importance = 0.5  # åŸºç¡€é‡è¦æ€§

        content = chunk.content.lower()

        # é‡è¦å…³é”®è¯åŠ åˆ†
        important_keywords = [
            'å†³å®š', 'å…³é”®', 'è½¬æŠ˜', 'é«˜æ½®', 'å†²çª', 'è§£å†³',
            'é‡è¦', 'æ ¸å¿ƒ', 'ä¸»è¦', 'å¿…é¡»', 'ç»ˆäº'
        ]
        for keyword in important_keywords:
            if keyword in content:
                importance += 0.05

        # å¯¹è¯é€šå¸¸æ¯”æè¿°é‡è¦
        if ':' in chunk.content or 'ï¼š' in chunk.content:
            importance += 0.1

        # é•¿åº¦é€‚ä¸­çš„å†…å®¹æ›´é‡è¦
        if 100 < len(chunk.content) < 500:
            importance += 0.1

        return min(1.0, importance)

    # ==================== æ»šåŠ¨çª—å£ç®¡ç† ====================

    async def add_to_context(
        self,
        session_id: str,
        user_id: str,
        message: Dict[str, Any]
    ) -> bool:
        """
        æ·»åŠ æ¶ˆæ¯åˆ°ä¸Šä¸‹æ–‡ï¼ˆå¸¦æ»šåŠ¨çª—å£ï¼‰

        å®ç°ï¼šå½“ä¸Šä¸‹æ–‡æ¥è¿‘ä¸Šé™æ—¶ï¼Œå°†æ—§æ¶ˆæ¯å‹ç¼©ä¸ºæ‘˜è¦
        """
        try:
            # è·å–æˆ–åˆ›å»ºä¸Šä¸‹æ–‡çª—å£
            window = self.context_windows.get(f"{user_id}_{session_id}")
            if not window:
                window = ContextWindow()
                self.context_windows[f"{user_id}_{session_id}"] = window

            # è®¡ç®—å½“å‰token
            message_tokens = self.count_message_tokens(message)
            window.total_tokens += message_tokens
            window.message_count += 1

            # æ·»åŠ åˆ°å³æ—¶è®°å¿†
            window.immediate.append(message)

            # æ£€æŸ¥æ˜¯å¦éœ€è¦å‹ç¼©
            usage_ratio = window.total_tokens / self.budget.max_context_tokens

            if usage_ratio > self.compression_threshold:
                await self._apply_rolling_window(window, session_id, user_id)

            # æ›´æ–°ç»Ÿè®¡
            self._update_window_stats(window, message)
            self._touch_window(window)

            return True

        except Exception as e:
            self.logger.error(f"æ·»åŠ åˆ°ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            return False

    async def _apply_rolling_window(
        self,
        window: ContextWindow,
        session_id: str,
        user_id: str
    ):
        """
        åº”ç”¨æ»šåŠ¨çª—å£æœºåˆ¶

        ç­–ç•¥ï¼š
        1. å°†immediateä¸­æœ€æ—§çš„æ¶ˆæ¯ç§»åˆ°recent
        2. å°†recentä¸­è¿‡æœŸçš„æ¶ˆæ¯å‹ç¼©ä¸ºæ‘˜è¦
        3. å°†æ‘˜è¦åˆå¹¶åˆ°working memory
        """
        self.logger.info(f"åº”ç”¨æ»šåŠ¨çª—å£: å½“å‰token={window.total_tokens}")

        # 1. ä»immediateç§»åˆ°recentï¼ˆä¿ç•™æœ€è¿‘5æ¡åœ¨immediateï¼‰
        while len(window.immediate) > 5:
            old_message = window.immediate.pop(0)
            window.recent.append(old_message)
            window.total_tokens -= self.count_message_tokens(old_message)

        # 2. ä»recentå‹ç¼©åˆ°working
        while len(window.recent) > self.rolling_window_size:
            old_messages = []
            for _ in range(min(3, len(window.recent))):  # æ¯æ¬¡å‹ç¼©3æ¡
                if window.recent:
                    old_messages.append(window.recent.popleft())

            if old_messages:
                summary = await self._compress_messages(old_messages, user_id, session_id)
                window.working.append({
                    "role": "system",
                    "content": f"[å†å²å¯¹è¯æ‘˜è¦] {summary}",
                    "compressed": True,
                    "timestamp": datetime.now().isoformat()
                })
                window.compression_count += 1
                window.last_compression = datetime.now().isoformat()
                self._touch_window(window)

        # 3. å¦‚æœworkingä»ç„¶è¿‡å¤§ï¼Œç”Ÿæˆæ€»ä½“æ‘˜è¦
        working_tokens = self.count_context_tokens(window.working)
        if working_tokens > self.budget.working_budget:
            overall_summary = await self._generate_overall_summary(window, user_id, session_id)
            window.long_term_summary = overall_summary
            window.working = []  # æ¸…ç©ºworkingï¼Œä¿ç•™æ‘˜è¦

        self.logger.info(f"æ»šåŠ¨çª—å£å®Œæˆ: compression_count={window.compression_count}")

    async def _compress_messages(
        self,
        messages: List[Dict[str, Any]],
        user_id: str,
        session_id: str
    ) -> str:
        """å‹ç¼©æ¶ˆæ¯ä¸ºæ‘˜è¦"""
        try:
            # æ„å»ºæ¶ˆæ¯æ–‡æœ¬
            messages_text = "\n".join([
                f"{msg.get('role', '')}: {msg.get('content', '')[:200]}"
                for msg in messages
            ])

            prompt = f"""è¯·å°†ä»¥ä¸‹å¯¹è¯å‹ç¼©ä¸ºç®€æ´çš„æ‘˜è¦ï¼ˆä¸è¶…è¿‡100å­—ï¼‰ï¼Œä¿ç•™å…³é”®ä¿¡æ¯ï¼š

{messages_text}

æ‘˜è¦ï¼š"""

            response = await self.llm_client.chat([{"role": "user", "content": prompt}])
            return response[:200] if response else "å¯¹è¯å†…å®¹å·²å‹ç¼©"

        except Exception as e:
            self.logger.error(f"æ¶ˆæ¯å‹ç¼©å¤±è´¥: {e}")
            # å¤‡ç”¨ï¼šç®€å•æ‹¼æ¥
            return f"åŒ…å«{len(messages)}æ¡å†å²æ¶ˆæ¯çš„æ‘˜è¦"

    async def _generate_overall_summary(
        self,
        window: ContextWindow,
        user_id: str,
        session_id: str
    ) -> str:
        """ç”Ÿæˆæ€»ä½“æ‘˜è¦"""
        try:
            all_content = []

            # æ·»åŠ key anchors
            if window.key_anchors:
                all_content.append("å…³é”®ä¿¡æ¯ï¼š\n" + "\n".join(window.key_anchors))

            # æ·»åŠ è§’è‰²æåŠ
            if window.character_mentions:
                chars = sorted(window.character_mentions.items(), key=lambda x: x[1], reverse=True)
                all_content.append("ä¸»è¦è§’è‰²ï¼š\n" + "\n".join([f"{c}: {count}æ¬¡" for c, count in chars[:5]]))

            # æ·»åŠ æƒ…èŠ‚ç‚¹
            if window.plot_points:
                all_content.append("å…³é”®æƒ…èŠ‚ï¼š\n" + "\n".join(window.plot_points[-5:]))

            # å¦‚æœæœ‰é•¿æœŸæ‘˜è¦ï¼Œåˆå¹¶å®ƒ
            if window.long_term_summary:
                all_content.append(f"ä¹‹å‰æ‘˜è¦ï¼š\n{window.long_term_summary}")

            # ä½¿ç”¨LLMç”Ÿæˆæ›´ç²¾ç‚¼çš„æ‘˜è¦
            if len(all_content) > 0:
                content_text = "\n\n".join(all_content)
                prompt = f"""è¯·å°†ä»¥ä¸‹ä¸Šä¸‹æ–‡ä¿¡æ¯æ•´åˆä¸ºä¸€ä¸ªç®€æ´çš„æ‘˜è¦ï¼ˆä¸è¶…è¿‡150å­—ï¼‰ï¼š

{content_text}

æ•´åˆæ‘˜è¦ï¼š"""

                response = await self.llm_client.chat([{"role": "user", "content": prompt}])
                return response[:300] if response else "ä¸Šä¸‹æ–‡å·²å‹ç¼©"

            return "ä¼šè¯ä¸Šä¸‹æ–‡æ‘˜è¦"

        except Exception as e:
            self.logger.error(f"ç”Ÿæˆæ€»ä½“æ‘˜è¦å¤±è´¥: {e}")
            return f"åŒ…å«{window.message_count}æ¡æ¶ˆæ¯çš„ä¼šè¯æ‘˜è¦"

    def _update_window_stats(self, window: ContextWindow, message: Dict[str, Any]):
        """æ›´æ–°çª—å£ç»Ÿè®¡ä¿¡æ¯"""
        content = message.get("content", "")

        # æ›´æ–°è§’è‰²æåŠ
        characters = self._extract_characters(content)
        for char in characters:
            window.character_mentions[char] = window.character_mentions.get(char, 0) + 1

        # æ£€æµ‹å…³é”®æƒ…èŠ‚
        if any(keyword in content for keyword in ['å†³å®š', 'è½¬æŠ˜', 'å†²çª', 'è§£å†³', 'å‘ç°']):
            window.plot_points.append(content[:50])

        # æ£€æµ‹éœ€è¦é”šå®šçš„ä¿¡æ¯
        if any(keyword in content for keyword in ['è®°ä½', 'é‡è¦', 'å…³é”®', 'å¿…é¡»']):
            window.key_anchors.append(content[:100])
            if len(window.key_anchors) > 10:  # æœ€å¤šä¿ç•™10ä¸ªé”šç‚¹
                window.key_anchors.pop(0)

    # ==================== æƒ…ç»ªç‚¹æ£€æµ‹ä¸ä¿æŠ¤ï¼ˆä¸“ä¸ºçŸ­å‰§è®¾è®¡ï¼‰====================

    def detect_emotional_points(self, text: str) -> List[EmotionalPoint]:
        """
        æ£€æµ‹æ–‡æœ¬ä¸­çš„æƒ…ç»ªç‚¹

        Args:
            text: å¾…æ£€æµ‹çš„æ–‡æœ¬

        Returns:
            List[EmotionalPoint]: æ£€æµ‹åˆ°çš„æƒ…ç»ªç‚¹åˆ—è¡¨
        """
        if not text:
            return []

        emotional_points = []
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]', text)
        position = 0

        for sentence in sentences:
            if not sentence.strip():
                continue

            sentence = sentence.strip()
            sentence_start = text.find(sentence, position)
            if sentence_start == -1:
                sentence_start = position

            # æ£€æµ‹æ¯ç§ç±»å‹çš„æƒ…ç»ªç‚¹
            for point_type, keywords in self.emotional_keywords.items():
                # è®¡ç®—åŒ¹é…çš„å…³é”®è¯æ•°é‡
                matched_keywords = [kw for kw in keywords if kw in sentence]

                if matched_keywords:
                    # è®¡ç®—é‡è¦æ€§ï¼ˆåŸºäºåŒ¹é…å…³é”®è¯æ•°é‡å’Œæƒé‡ï¼‰
                    base_importance = min(1.0, len(matched_keywords) * 0.3)

                    # è€ƒè™‘å¥å­é•¿åº¦ï¼ˆè¾ƒçŸ­çš„å¥å­å¯èƒ½æ˜¯æ›´æœ‰åŠ›çš„è¡¨è¾¾ï¼‰
                    length_factor = max(0.5, 1.0 - len(sentence) / 200)

                    # ç»¼åˆé‡è¦æ€§
                    importance = base_importance * length_factor

                    emotional_points.append(EmotionalPoint(
                        content=sentence,
                        point_type=point_type,
                        importance=importance,
                        position=sentence_start,
                        metadata={
                            "matched_keywords": matched_keywords,
                            "sentence_length": len(sentence)
                        }
                    ))

            position = sentence_start + len(sentence)

        # æŒ‰é‡è¦æ€§æ’åº
        emotional_points.sort(key=lambda ep: ep.importance, reverse=True)

        return emotional_points

    def should_protect_emotional_point(
        self,
        emotional_point: EmotionalPoint,
        protection_threshold: float = 0.5
    ) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥ä¿æŠ¤æŸä¸ªæƒ…ç»ªç‚¹

        Args:
            emotional_point: æƒ…ç»ªç‚¹
            protection_threshold: ä¿æŠ¤é˜ˆå€¼

        Returns:
            bool: æ˜¯å¦åº”è¯¥ä¿æŠ¤
        """
        # è·å–è¯¥ç±»å‹æƒ…ç»ªç‚¹çš„ä¿æŠ¤æƒé‡
        type_weight = self.emotion_protection_weights.get(
            emotional_point.point_type,
            0.5
        )

        # è®¡ç®—ç»¼åˆä¿æŠ¤åˆ†æ•°
        protection_score = emotional_point.importance * type_weight

        return protection_score >= protection_threshold

    def extract_protected_content(
        self,
        text: str,
        max_length: int = 500
    ) -> Tuple[str, List[EmotionalPoint]]:
        """
        æå–å—ä¿æŠ¤çš„æƒ…ç»ªç‚¹å†…å®¹

        åœ¨å‹ç¼©æ—¶ä¼˜å…ˆä¿ç•™æƒ…ç»ªç‚¹ï¼Œç¡®ä¿æ ¸å¿ƒæƒ…ç»ªä¸ä¸¢å¤±

        Args:
            text: åŸå§‹æ–‡æœ¬
            max_length: æœ€å¤§é•¿åº¦é™åˆ¶

        Returns:
            Tuple[str, List[EmotionalPoint]]: (å‹ç¼©åçš„æ–‡æœ¬, ä¿ç•™çš„æƒ…ç»ªç‚¹)
        """
        # æ£€æµ‹æ‰€æœ‰æƒ…ç»ªç‚¹
        all_emotional_points = self.detect_emotional_points(text)

        # è¿‡æ»¤å‡ºéœ€è¦ä¿æŠ¤çš„ç‚¹
        protected_points = [
            ep for ep in all_emotional_points
            if self.should_protect_emotional_point(ep)
        ]

        if not protected_points:
            # æ²¡æœ‰éœ€è¦ä¿æŠ¤çš„ç‚¹ï¼Œç›´æ¥æˆªæ–­
            return text[:max_length], []

        # æŒ‰ä½ç½®æ’åº
        protected_points.sort(key=lambda ep: ep.position)

        # æ„å»ºå—ä¿æŠ¤çš„å†…å®¹
        protected_content_parts = []
        current_length = 0

        for ep in protected_points:
            content = ep.content
            if current_length + len(content) <= max_length:
                protected_content_parts.append(content)
                current_length += len(content)
            else:
                # å‰©ä½™ç©ºé—´ä¸è¶³ï¼Œæˆªæ–­å½“å‰æƒ…ç»ªç‚¹
                remaining = max_length - current_length
                if remaining > 20:  # è‡³å°‘ä¿ç•™20ä¸ªå­—ç¬¦
                    protected_content_parts.append(content[:remaining] + "...")
                break

        protected_text = " ".join(protected_content_parts)

        return protected_text, protected_points

    async def compress_with_emotion_protection(
        self,
        messages: List[Dict[str, Any]],
        user_id: str,
        session_id: str,
        max_length: int = 500
    ) -> str:
        """
        å¸¦æƒ…ç»ªç‚¹ä¿æŠ¤çš„å‹ç¼©æ–¹æ³•

        æ”¹è¿›åŸ `_compress_messages` æ–¹æ³•ï¼Œåœ¨å‹ç¼©æ—¶ä¿æŠ¤æƒ…ç»ªç‚¹

        Args:
            messages: å¾…å‹ç¼©çš„æ¶ˆæ¯åˆ—è¡¨
            user_id: ç”¨æˆ·ID
            session_id: ä¼šè¯ID
            max_length: æœ€å¤§é•¿åº¦

        Returns:
            str: å‹ç¼©åçš„æ–‡æœ¬
        """
        try:
            # æå–æ‰€æœ‰æ–‡æœ¬å†…å®¹
            all_text = []
            for msg in messages:
                content = msg.get("content", "")
                all_text.append(content)

            combined_text = "\n".join(all_text)

            # å¦‚æœæ€»é•¿åº¦å°äºé™åˆ¶ï¼Œç›´æ¥è¿”å›
            if len(combined_text) <= max_length:
                return combined_text

            # ä½¿ç”¨æƒ…ç»ªç‚¹ä¿æŠ¤çš„æå–
            protected_text, protected_points = self.extract_protected_content(
                combined_text,
                max_length
            )

            # å¦‚æœå—ä¿æŠ¤çš„å†…å®¹å¤ªå°‘ï¼Œè¡¥å……LLMæ‘˜è¦
            if len(protected_text) < max_length * 0.3:
                # ä½¿ç”¨LLMç”Ÿæˆæ‘˜è¦
                llm_summary = await self._compress_messages(messages, user_id, session_id)

                # åˆå¹¶æƒ…ç»ªç‚¹å’Œæ‘˜è¦
                if protected_points:
                    summary = f"[æƒ…ç»ªç‚¹ä¿æŠ¤]\n{protected_text}\n\n[æ‘˜è¦]\n{llm_summary}"
                    return summary[:max_length]
                return llm_summary[:max_length]

            return protected_text

        except Exception as e:
            self.logger.error(f"æƒ…ç»ªä¿æŠ¤å‹ç¼©å¤±è´¥: {e}")
            # é™çº§åˆ°æ™®é€šå‹ç¼©
            return await self._compress_messages(messages, user_id, session_id)

    # ==================== ä¸Šä¸‹æ–‡é‡å»º ====================

    async def rebuild_context_for_llm(
        self,
        session_id: str,
        user_id: str,
        system_prompt: str,
        new_message: str,
        extra_messages: Optional[List[Dict[str, Any]]] = None
    ) -> List[Dict[str, Any]]:
        """
        ä¸ºLLMé‡å»ºå®Œæ•´çš„ä¸Šä¸‹æ–‡

        è¿”å›æŒ‰ä¼˜å…ˆçº§æ’åˆ—çš„æ¶ˆæ¯åˆ—è¡¨ï¼š
        1. System Prompt
        2. Long-term Summary (å¦‚æœå­˜åœ¨)
        3. Key Anchors (é‡è¦ä¿¡æ¯é”šç‚¹)
        4. Working Memory (å·¥ä½œè®°å¿†)
        5. Recent Messages (è¿‘æœŸå¯¹è¯)
        6. Immediate Messages (å½“å‰å¯¹è¯)
        7. New Message
        """
        window = self.context_windows.get(f"{user_id}_{session_id}")
        if not window:
            window = ContextWindow()
            self.context_windows[f"{user_id}_{session_id}"] = window

        messages = []
        token_count = 0

        # 1. System Prompt
        system_msg = {"role": "system", "content": system_prompt}
        system_tokens = self.count_message_tokens(system_msg)
        if token_count + system_tokens < self.budget.max_context_tokens:
            messages.append(system_msg)
            token_count += system_tokens

        # 2. é¢å¤–ä¸Šä¸‹æ–‡å—ï¼ˆç³»ç»Ÿ/ç¤ºä¾‹æ¶ˆæ¯ï¼‰
        if extra_messages:
            for msg in extra_messages:
                msg_tokens = self.count_message_tokens(msg)
                if token_count + msg_tokens < self.budget.max_context_tokens - self.budget.response_budget:
                    messages.append(msg)
                    token_count += msg_tokens

        # 3. Long-term Summary
        if window.long_term_summary:
            summary_msg = {
                "role": "system",
                "content": f"ã€ä¸Šä¸‹æ–‡æ‘˜è¦ã€‘{window.long_term_summary}"
            }
            summary_tokens = self.count_message_tokens(summary_msg)
            if token_count + summary_tokens < self.budget.max_context_tokens - self.budget.response_budget:
                messages.append(summary_msg)
                token_count += summary_tokens

        # 4. Key Anchors (å¦‚æœæœ‰)
        if window.key_anchors:
            anchors_text = "\n".join([f"â€¢ {anchor}" for anchor in window.key_anchors[-5:]])
            anchor_msg = {
                "role": "system",
                "content": f"ã€é‡è¦ä¿¡æ¯ã€‘\n{anchors_text}"
            }
            anchor_tokens = self.count_message_tokens(anchor_msg)
            if token_count + anchor_tokens < self.budget.max_context_tokens - self.budget.response_budget:
                messages.append(anchor_msg)
                token_count += anchor_tokens

        # 5. Working Memory
        for msg in window.working:
            msg_tokens = self.count_message_tokens(msg)
            if token_count + msg_tokens < self.budget.max_context_tokens - self.budget.response_budget:
                messages.append(msg)
                token_count += msg_tokens

        # 6. Recent Messages (ä¿ç•™æœ€è¿‘)
        for msg in list(window.recent)[-self.rolling_window_size:]:
            msg_tokens = self.count_message_tokens(msg)
            if token_count + msg_tokens < self.budget.max_context_tokens - self.budget.response_budget:
                messages.append(msg)
                token_count += msg_tokens

        # 7. Immediate Messages
        for msg in window.immediate:
            msg_tokens = self.count_message_tokens(msg)
            if token_count + msg_tokens < self.budget.max_context_tokens - self.budget.response_budget:
                messages.append(msg)
                token_count += msg_tokens

        # 8. New Message
        new_msg = {"role": "user", "content": new_message}
        messages.append(new_msg)

        self.logger.info(f"é‡å»ºä¸Šä¸‹æ–‡: {len(messages)}æ¡æ¶ˆæ¯, çº¦{token_count}tokens")
        return messages

    # ==================== å†…éƒ¨ç¬”è®°ç®¡ç†ï¼ˆéš”ç¦»å±‚ï¼‰ ====================

    async def add_internal_note(
        self,
        session_id: str,
        user_id: str,
        note_type: str,
        content: Any,
        metadata: Optional[Dict[str, Any]] = None
    ) -> bool:
        """
        æ·»åŠ å†…éƒ¨ç¬”è®°ï¼ˆä¸å‘é€ç»™LLMï¼‰

        ç”¨äºï¼š
        - å­ä»»åŠ¡ç»“æœç¼“å­˜
        - ä¸­é—´å¤„ç†çŠ¶æ€
        - è°ƒè¯•ä¿¡æ¯
        - æ€§èƒ½ç»Ÿè®¡

        Args:
            session_id: ä¼šè¯ID
            user_id: ç”¨æˆ·ID
            note_type: ç¬”è®°ç±»å‹ (subtask_result|debug|performance|state)
            content: ç¬”è®°å†…å®¹
            metadata: å…ƒæ•°æ®

        Returns:
            æ˜¯å¦æ·»åŠ æˆåŠŸ
        """
        try:
            window = self.context_windows.get(f"{user_id}_{session_id}")
            if not window:
                window = ContextWindow()
                self.context_windows[f"{user_id}_{session_id}"] = window

            note = {
                "type": note_type,
                "content": content,
                "timestamp": datetime.now().isoformat(),
                "metadata": metadata or {}
            }

            # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™åˆ¶
            if len(window.internal_notes) >= window.max_internal_notes:
                # ç§»é™¤æœ€æ—§çš„ç¬”è®°
                window.internal_notes.pop(0)

            window.internal_notes.append(note)
            return True

        except Exception as e:
            self.logger.error(f"æ·»åŠ å†…éƒ¨ç¬”è®°å¤±è´¥: {e}")
            return False

    async def get_internal_notes(
        self,
        session_id: str,
        user_id: str,
        note_type: Optional[str] = None,
        limit: int = 10
    ) -> List[Dict[str, Any]]:
        """
        è·å–å†…éƒ¨ç¬”è®°

        Args:
            session_id: ä¼šè¯ID
            user_id: ç”¨æˆ·ID
            note_type: ç¬”è®°ç±»å‹è¿‡æ»¤ï¼ˆNoneè¡¨ç¤ºå…¨éƒ¨ï¼‰
            limit: è¿”å›æ•°é‡é™åˆ¶

        Returns:
            ç¬”è®°åˆ—è¡¨
        """
        window = self.context_windows.get(f"{user_id}_{session_id}")
        if not window:
            return []

        notes = window.internal_notes

        # ç±»å‹è¿‡æ»¤
        if note_type:
            notes = [n for n in notes if n.get("type") == note_type]

        # è¿”å›æœ€è¿‘çš„
        return notes[-limit:]

    async def clear_internal_notes(
        self,
        session_id: str,
        user_id: str,
        note_type: Optional[str] = None
    ) -> int:
        """
        æ¸…é™¤å†…éƒ¨ç¬”è®°

        Args:
            session_id: ä¼šè¯ID
            user_id: ç”¨æˆ·ID
            note_type: ç¬”è®°ç±»å‹ï¼ˆNoneè¡¨ç¤ºå…¨éƒ¨ï¼‰

        Returns:
            æ¸…é™¤çš„æ•°é‡
        """
        window = self.context_windows.get(f"{user_id}_{session_id}")
        if not window:
            return 0

        if note_type:
            # åªæ¸…é™¤ç‰¹å®šç±»å‹
            original_count = len(window.internal_notes)
            window.internal_notes = [n for n in window.internal_notes if n.get("type") != note_type]
            return original_count - len(window.internal_notes)
        else:
            # æ¸…é™¤å…¨éƒ¨
            count = len(window.internal_notes)
            window.internal_notes = []
            return count

    # ==================== è‰ç¨¿çº¸ç®¡ç†ï¼ˆé€‰æ‹©æœºåˆ¶ï¼‰ ====================

    async def add_to_scratchpad(
        self,
        session_id: str,
        user_id: str,
        content: Any,
        importance: float = 0.5,
        tags: Optional[List[str]] = None,
        metadata: Optional[Dict[str, Any]] = None
    ) -> bool:
        """
        æ·»åŠ åˆ°è‰ç¨¿çº¸

        è‰ç¨¿çº¸ç”¨äºä¸´æ—¶å­˜å‚¨ä¸­é—´ç»“æœï¼Œç„¶åè¿›è¡Œç­›é€‰

        Args:
            session_id: ä¼šè¯ID
            user_id: ç”¨æˆ·ID
            content: å†…å®¹
            importance: é‡è¦æ€§ (0-1)
            tags: æ ‡ç­¾
            metadata: å…ƒæ•°æ®

        Returns:
            æ˜¯å¦æ·»åŠ æˆåŠŸ
        """
        try:
            window = self.context_windows.get(f"{user_id}_{session_id}")
            if not window:
                window = ContextWindow()
                self.context_windows[f"{user_id}_{session_id}"] = window

            entry = {
                "content": content,
                "importance": importance,
                "tags": tags or [],
                "timestamp": datetime.now().isoformat(),
                "metadata": metadata or {}
            }

            # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™åˆ¶
            if len(window.scratchpad) >= window.max_scratchpad_size:
                # ç§»é™¤é‡è¦æ€§æœ€ä½çš„
                window.scratchpad.sort(key=lambda x: x.get("importance", 0))
                window.scratchpad.pop(0)

            window.scratchpad.append(entry)
            return True

        except Exception as e:
            self.logger.error(f"æ·»åŠ åˆ°è‰ç¨¿çº¸å¤±è´¥: {e}")
            return False

    async def select_from_scratchpad(
        self,
        session_id: str,
        user_id: str,
        current_task: str,
        max_items: int = 5,
        min_importance: float = 0.3
    ) -> List[Dict[str, Any]]:
        """
        ä»è‰ç¨¿çº¸é€‰æ‹©ç›¸å…³ä¿¡æ¯ï¼ˆæ ¸å¿ƒé€‰æ‹©æœºåˆ¶ï¼‰

        é€‰æ‹©ç­–ç•¥ï¼š
        1. é‡è¦æ€§è¿‡æ»¤ï¼ˆä½äºmin_importanceçš„å¿½ç•¥ï¼‰
        2. ç›¸å…³æ€§è¯„åˆ†ï¼ˆä¸current_taskçš„ç›¸ä¼¼åº¦ï¼‰
        3. ç»¼åˆæ’åºï¼ˆimportance * relevanceï¼‰
        4. æ•°é‡é™åˆ¶ï¼ˆæœ€å¤šmax_itemsä¸ªï¼‰

        Args:
            session_id: ä¼šè¯ID
            user_id: ç”¨æˆ·ID
            current_task: å½“å‰ä»»åŠ¡æè¿°
            max_items: æœ€å¤§è¿”å›æ•°é‡
            min_importance: æœ€å°é‡è¦æ€§é˜ˆå€¼

        Returns:
            é€‰ä¸­çš„è‰ç¨¿çº¸æ¡ç›®
        """
        window = self.context_windows.get(f"{user_id}_{session_id}")
        if not window:
            return []

        try:
            # 1. é‡è¦æ€§è¿‡æ»¤
            filtered = [item for item in window.scratchpad if item.get("importance", 0) >= min_importance]

            # 2. è®¡ç®—ç›¸å…³æ€§
            for item in filtered:
                item["relevance_score"] = self._calculate_relevance(item, current_task)

            # 3. ç»¼åˆæ’åº
            for item in filtered:
                importance = item.get("importance", 0.5)
                relevance = item.get("relevance_score", 0.5)
                item["combined_score"] = importance * 0.4 + relevance * 0.6

            filtered.sort(key=lambda x: x.get("combined_score", 0), reverse=True)

            # 4. æ•°é‡é™åˆ¶
            selected = filtered[:max_items]

            self.logger.info(f"ä»è‰ç¨¿çº¸é€‰æ‹©äº†{len(selected)}/{len(window.scratchpad)}ä¸ªæ¡ç›®")
            return selected

        except Exception as e:
            self.logger.error(f"ä»è‰ç¨¿çº¸é€‰æ‹©å¤±è´¥: {e}")
            return []

    def _calculate_relevance(self, item: Dict[str, Any], query: str) -> float:
        """è®¡ç®—ç›¸å…³æ€§åˆ†æ•°"""
        try:
            content = str(item.get("content", ""))
            tags = item.get("tags", [])

            # ç®€å•çš„å…³é”®è¯åŒ¹é…
            query_lower = query.lower()
            content_lower = content.lower()

            # ç›´æ¥åŒ¹é…
            direct_match = 1.0 if query_lower in content_lower else 0.0

            # æ ‡ç­¾åŒ¹é…
            tag_match = 0.0
            for tag in tags:
                if tag.lower() in query_lower:
                    tag_match = 0.8
                    break

            # å…³é”®è¯é‡å 
            query_words = set(query_lower.split())
            content_words = set(content_lower.split())
            overlap = len(query_words & content_words) / max(len(query_words), 1)

            return max(direct_match, tag_match, overlap * 0.5)

        except Exception:
            return 0.0

    async def clear_scratchpad(
        self,
        session_id: str,
        user_id: str
    ) -> int:
        """
        æ¸…ç©ºè‰ç¨¿çº¸

        Args:
            session_id: ä¼šè¯ID
            user_id: ç”¨æˆ·ID

        Returns:
            æ¸…é™¤çš„æ•°é‡
        """
        window = self.context_windows.get(f"{user_id}_{session_id}")
        if not window:
            return 0

        count = len(window.scratchpad)
        window.scratchpad = []
        return count

    # ==================== å­ä»»åŠ¡éš”ç¦» ====================

    async def store_subtask_result(
        self,
        session_id: str,
        user_id: str,
        subtask_id: str,
        result: Any,
        metadata: Optional[Dict[str, Any]] = None
    ) -> bool:
        """
        å­˜å‚¨å­ä»»åŠ¡ç»“æœï¼ˆéš”ç¦»ï¼‰

        å­ä»»åŠ¡ç»“æœå­˜å‚¨åœ¨internal_notesä¸­ï¼Œä¸å‘é€ç»™LLM
        å¯ä»¥é€šè¿‡æŸ¥è¯¢è·å–ç‰¹å®šå­ä»»åŠ¡çš„ç»“æœ

        Args:
            session_id: ä¼šè¯ID
            user_id: ç”¨æˆ·ID
            subtask_id: å­ä»»åŠ¡ID
            result: ç»“æœ
            metadata: å…ƒæ•°æ®

        Returns:
            æ˜¯å¦å­˜å‚¨æˆåŠŸ
        """
        try:
            window = self.context_windows.get(f"{user_id}_{session_id}")
            if not window:
                window = ContextWindow()
                self.context_windows[f"{user_id}_{session_id}"] = window

            window.subtask_results[subtask_id] = {
                "result": result,
                "timestamp": datetime.now().isoformat(),
                "metadata": metadata or {}
            }

            return True

        except Exception as e:
            self.logger.error(f"å­˜å‚¨å­ä»»åŠ¡ç»“æœå¤±è´¥: {e}")
            return False

    async def get_subtask_result(
        self,
        session_id: str,
        user_id: str,
        subtask_id: str
    ) -> Optional[Dict[str, Any]]:
        """
        è·å–å­ä»»åŠ¡ç»“æœ

        Args:
            session_id: ä¼šè¯ID
            user_id: ç”¨æˆ·ID
            subtask_id: å­ä»»åŠ¡ID

        Returns:
            å­ä»»åŠ¡ç»“æœï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        """
        window = self.context_windows.get(f"{user_id}_{session_id}")
        if not window:
            return None

        return window.subtask_results.get(subtask_id)

    async def list_subtask_results(
        self,
        session_id: str,
        user_id: str
    ) -> Dict[str, Any]:
        """
        åˆ—å‡ºæ‰€æœ‰å­ä»»åŠ¡ç»“æœ

        Args:
            session_id: ä¼šè¯ID
            user_id: ç”¨æˆ·ID

        Returns:
            æ‰€æœ‰å­ä»»åŠ¡ç»“æœ
        """
        window = self.context_windows.get(f"{user_id}_{session_id}")
        if not window:
            return {}

        return window.subtask_results.copy()

    # ==================== å‰§æœ¬è®°å¿†ç®¡ç† ====================

    async def create_script_memory(self, user_id: str, session_id: str) -> ScriptMemory:
        """åˆ›å»ºå‰§æœ¬è®°å¿†"""
        memory = ScriptMemory(session_id=session_id, user_id=user_id)
        self.script_memories[f"{user_id}_{session_id}"] = memory
        return memory

    async def get_or_create_graph_memory(self, user_id: str, session_id: str) -> GraphMemory:
        """è·å–æˆ–åˆ›å»ºå›¾ç»“æ„è®°å¿†"""
        key = f"{user_id}_{session_id}"
        memory = self.graph_memories.get(key)
        if not memory:
            memory = GraphMemory()
            self.graph_memories[key] = memory
        return memory

    async def update_graph_from_script_memory(self, user_id: str, session_id: str) -> GraphMemory:
        """ä»å‰§æœ¬è®°å¿†æ„å»º/æ›´æ–°å›¾ç»“æ„"""
        graph = await self.get_or_create_graph_memory(user_id, session_id)
        memory = self.script_memories.get(f"{user_id}_{session_id}")
        if not memory:
            return graph

        # è§’è‰²èŠ‚ç‚¹
        for char_name, char_info in memory.characters.items():
            node_id = f"char:{char_name}"
            graph.upsert_node(node_id, "character", char_name, {"info": char_info})

        # æƒ…èŠ‚çº¿èŠ‚ç‚¹
        for plot in memory.plot_threads:
            plot_id = plot.get("id") or f"plot:{plot.get('description','')[:20]}"
            node_id = f"plot:{plot_id}"
            graph.upsert_node(node_id, "plot", plot.get("description", ""), {"status": plot.get("status")})

        # ç®€å•å…³ç³»ï¼šæ‰€æœ‰è§’è‰² -> æ‰€æœ‰æƒ…èŠ‚çº¿
        for char_name in memory.characters.keys():
            for plot in memory.plot_threads:
                plot_id = plot.get("id") or f"plot:{plot.get('description','')[:20]}"
                graph.add_edge(f"char:{char_name}", f"plot:{plot_id}", "appears_in")

        return graph

    async def get_graph_context_summary(self, user_id: str, session_id: str) -> str:
        """è·å–å›¾ç»“æ„æ‘˜è¦"""
        graph = await self.update_graph_from_script_memory(user_id, session_id)
        if not graph.nodes:
            return "æš‚æ— å›¾ç»“æ„è®°å¿†"

        characters = [n for n in graph.nodes.values() if n.get("type") == "character"]
        plots = [n for n in graph.nodes.values() if n.get("type") == "plot"]
        edges = graph.edges[-20:]

        parts = []
        if characters:
            parts.append("ã€è§’è‰²èŠ‚ç‚¹ã€‘" + "ã€".join([c.get("label", "") for c in characters[:10]]))
        if plots:
            parts.append("ã€æƒ…èŠ‚çº¿ã€‘" + "ã€".join([p.get("label", "") for p in plots[:10]]))
        if edges:
            edge_text = "; ".join([f"{e['source']}â†’{e['target']}" for e in edges[:10]])
            parts.append("ã€å…³ç³»ã€‘" + edge_text)

        return "\n".join(parts)

    async def update_character_info(
        self,
        user_id: str,
        session_id: str,
        character_name: str,
        info: Dict[str, Any]
    ):
        """æ›´æ–°è§’è‰²ä¿¡æ¯"""
        memory = self.script_memories.get(f"{user_id}_{session_id}")
        if not memory:
            memory = await self.create_script_memory(user_id, session_id)

        if character_name not in memory.characters:
            memory.characters[character_name] = {
                "name": character_name,
                "first_appearance": datetime.now().isoformat(),
                "mentions": 0
            }

        memory.characters[character_name].update(info)
        memory.characters[character_name]["mentions"] += 1
        memory.characters[character_name]["last_updated"] = datetime.now().isoformat()
        memory.updated_at = datetime.now().isoformat()

    async def add_plot_thread(
        self,
        user_id: str,
        session_id: str,
        plot_description: str,
        status: str = "active"
    ):
        """æ·»åŠ æƒ…èŠ‚çº¿"""
        memory = self.script_memories.get(f"{user_id}_{session_id}")
        if not memory:
            memory = await self.create_script_memory(user_id, session_id)

        plot_thread = {
            "id": f"plot_{len(memory.plot_threads)}",
            "description": plot_description,
            "status": status,
            "created_at": datetime.now().isoformat()
        }
        memory.plot_threads.append(plot_thread)
        memory.updated_at = datetime.now().isoformat()

    async def get_script_context_summary(
        self,
        user_id: str,
        session_id: str
    ) -> str:
        """è·å–å‰§æœ¬ä¸Šä¸‹æ–‡æ‘˜è¦"""
        memory = self.script_memories.get(f"{user_id}_{session_id}")
        if not memory:
            return "æš‚æ— å‰§æœ¬è®°å¿†"

        parts = []

        # è§’è‰²ä¿¡æ¯
        if memory.characters:
            parts.append("ã€è§’è‰²æ¡£æ¡ˆã€‘")
            for char_name, char_info in memory.characters.items():
                parts.append(f"- {char_name}: {char_info.get('description', 'æ— æè¿°')}")

        # æƒ…èŠ‚çº¿
        if memory.plot_threads:
            parts.append("\nã€æƒ…èŠ‚çº¿ã€‘")
            for plot in memory.plot_threads:
                parts.append(f"- {plot['description']} ({plot['status']})")

        # å…³é”®å†³ç­–
        if memory.key_decisions:
            parts.append("\nã€å…³é”®å†³ç­–ã€‘")
            for decision in memory.key_decisions[-5:]:
                parts.append(f"- {decision.get('description', '')}")

        return "\n".join(parts) if parts else "æš‚æ— è¯¦ç»†ä¿¡æ¯"

    # ==================== RAGè‡ªåŠ¨åŠ è½½ä¸æ··åˆæ£€ç´¢ï¼ˆæ–°å¢ï¼‰ ====================

    async def auto_load_rag_context(
        self,
        session_id: str,
        user_id: str,
        query: str,
        enable_rag: bool = True,
        enable_hybrid: bool = True,
        top_k: int = 3,
        collection: str = "script_segments"
    ) -> List[Dict[str, Any]]:
        """
        è‡ªåŠ¨åŠ è½½RAGä¸Šä¸‹æ–‡ï¼ˆæ ¸å¿ƒRAGè‡ªåŠ¨åŠ è½½æœºåˆ¶ï¼‰

        åœ¨è°ƒç”¨LLMå‰è‡ªåŠ¨ï¼š
        1. æ£€æµ‹æŸ¥è¯¢æ„å›¾
        2. æ‰§è¡Œå‘é‡æ£€ç´¢ï¼ˆå¦‚æœenable_ragï¼‰
        3. æ‰§è¡Œæ··åˆæ£€ç´¢ï¼ˆå¦‚æœenable_hybridï¼‰
        4. è¿‡æ»¤å’Œæ’åºç»“æœ
        5. è¿”å›æœ€ç›¸å…³çš„ä¸Šä¸‹æ–‡

        Args:
            session_id: ä¼šè¯ID
            user_id: ç”¨æˆ·ID
            query: æŸ¥è¯¢å†…å®¹
            enable_rag: æ˜¯å¦å¯ç”¨RAGæ£€ç´¢
            enable_hybrid: æ˜¯å¦å¯ç”¨æ··åˆæ£€ç´¢
            top_k: è¿”å›ç»“æœæ•°é‡
            collection: çŸ¥è¯†åº“é›†åˆåç§°

        Returns:
            RAGæ£€ç´¢ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å«ï¼š
            - content: å†…å®¹
            - similarity: ç›¸ä¼¼åº¦
            - source: æ¥æº
            - type: ç±»å‹ (vector/text/hybrid)
        """
        try:
            # å»¶è¿Ÿå¯¼å…¥ï¼Œé¿å…å¾ªç¯ä¾èµ–
            from .vector_store import VectorStore
            from .knowledge_base_client import KnowledgeBaseClient

            results = []

            # 1. å‘é‡æ£€ç´¢
            if enable_rag:
                try:
                    vector_store = VectorStore()
                    if not vector_store._initialized:
                        await vector_store.initialize()

                    vector_results = await vector_store.search_similar(
                        collection_name=f"{collection}_collection",
                        query=query,
                        top_k=top_k,
                        score_threshold=0.6
                    )

                    # æ ¼å¼åŒ–ç»“æœ
                    for item in vector_results.get("results", []):
                        results.append({
                            "content": item.get("content", ""),
                            "similarity": item.get("score", 0.0),
                            "source": item.get("source", "vector_db"),
                            "type": "vector"
                        })

                    self.logger.info(f"å‘é‡æ£€ç´¢: æ‰¾åˆ°{len(results)}ä¸ªç»“æœ")

                except Exception as e:
                    self.logger.warning(f"å‘é‡æ£€ç´¢å¤±è´¥: {e}")

            # 2. æ–‡æœ¬/å…³é”®è¯æ£€ç´¢ï¼ˆæ··åˆï¼‰
            if enable_hybrid:
                try:
                    knowledge_client = KnowledgeBaseClient()
                    text_results = await knowledge_client.search(query, collection=collection, top_k=top_k)

                    # æ ¼å¼åŒ–ç»“æœ
                    for item in text_results.get("results", []):
                        results.append({
                            "content": item.get("content", ""),
                            "similarity": item.get("similarity", 0.0),
                            "source": item.get("source", "knowledge_base"),
                            "type": "text"
                        })

                    self.logger.info(f"æ–‡æœ¬æ£€ç´¢: æ‰¾åˆ°{len(text_results.get('results', []))}ä¸ªç»“æœ")

                except Exception as e:
                    self.logger.warning(f"æ–‡æœ¬æ£€ç´¢å¤±è´¥: {e}")

            # 3. æ··åˆæ£€ç´¢ç»“æœå»é‡å’Œæ’åº
            if results:
                results = await self._deduplicate_and_rank(results)

                # é™åˆ¶è¿”å›æ•°é‡
                results = results[:top_k]

                # å°†ç»“æœå­˜å‚¨åˆ°è‰ç¨¿çº¸ï¼ˆä¾›åç»­é€‰æ‹©ä½¿ç”¨ï¼‰
                for result in results:
                    await self.add_to_scratchpad(
                        session_id, user_id,
                        result["content"],
                        importance=result["similarity"],
                        tags=["rag", result["type"], collection],
                        metadata={
                            "source": result["source"],
                            "similarity": result["similarity"]
                        }
                    )

            return results

        except Exception as e:
            self.logger.error(f"RAGè‡ªåŠ¨åŠ è½½å¤±è´¥: {e}")
            return []

    async def _deduplicate_and_rank(
        self,
        results: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        å»é‡å’Œæ’åºæ··åˆæ£€ç´¢ç»“æœ

        Args:
            results: æ··åˆæ£€ç´¢ç»“æœåˆ—è¡¨

        Returns:
            å»é‡å’Œæ’åºåçš„ç»“æœ
        """
        # å»é‡ï¼ˆåŸºäºå†…å®¹ç›¸ä¼¼åº¦ï¼‰
        seen_contents = set()
        unique_results = []

        for result in results:
            content = result.get("content", "")
            # ä½¿ç”¨å†…å®¹çš„å‰100ä¸ªå­—ç¬¦ä½œä¸ºå»é‡ä¾æ®
            content_key = content[:100] if content else ""

            if content_key and content_key not in seen_contents:
                seen_contents.add(content_key)
                unique_results.append(result)

        # æ’åºï¼šæŒ‰ç›¸ä¼¼åº¦é™åº
        unique_results.sort(key=lambda x: x.get("similarity", 0), reverse=True)

        return unique_results

    async def rebuild_context_with_rag(
        self,
        session_id: str,
        user_id: str,
        system_prompt: str,
        new_message: str,
        enable_auto_rag: bool = True,
        rag_threshold: float = 0.7,
        max_rag_items: int = 3,
        extra_messages: Optional[List[Dict[str, Any]]] = None
    ) -> List[Dict[str, Any]]:
        """
        é‡å»ºä¸Šä¸‹æ–‡ï¼ˆå¸¦RAGè‡ªåŠ¨åŠ è½½ï¼‰

        è¿™æ˜¯rebuild_context_for_llmçš„å¢å¼ºç‰ˆæœ¬ï¼Œä¼šè‡ªåŠ¨ï¼š
        1. è°ƒç”¨rebuild_context_for_llmè·å–åŸºç¡€ä¸Šä¸‹æ–‡
        2. åˆ†ænew_messageï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦RAG
        3. å¦‚æœéœ€è¦ï¼Œè‡ªåŠ¨åŠ è½½ç›¸å…³RAGå†…å®¹
        4. å°†RAGå†…å®¹æ•´åˆåˆ°ä¸Šä¸‹æ–‡ä¸­

        Args:
            session_id: ä¼šè¯ID
            user_id: ç”¨æˆ·ID
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            new_message: æ–°æ¶ˆæ¯
            enable_auto_rag: æ˜¯å¦å¯ç”¨è‡ªåŠ¨RAG
            rag_threshold: RAGè§¦å‘é˜ˆå€¼ï¼ˆç›¸ä¼¼åº¦ä½äºæ­¤å€¼æ—¶è§¦å‘RAGï¼‰
            max_rag_items: æœ€å¤§RAGæ¡ç›®æ•°

        Returns:
            åŒ…å«RAGå†…å®¹çš„å®Œæ•´ä¸Šä¸‹æ–‡
        """
        # 1. è·å–åŸºç¡€ä¸Šä¸‹æ–‡
        messages = await self.rebuild_context_for_llm(
            session_id, user_id, system_prompt, new_message, extra_messages=extra_messages
        )

        # 2. åˆ¤æ–­æ˜¯å¦éœ€è¦RAG
        if not enable_auto_rag:
            return messages

        # æ£€æµ‹æ˜¯å¦éœ€è¦çŸ¥è¯†å¢å¼º
        needs_rag = await self._detect_rag_need(new_message)

        if not needs_rag:
            self.logger.info("æ— éœ€RAGå¢å¼º")
            return messages

        # 3. æ‰§è¡ŒRAGæ£€ç´¢
        rag_results = await self.auto_load_rag_context(
            session_id, user_id, new_message,
            enable_rag=True,
            enable_hybrid=True,
            top_k=max_rag_items
        )

        if not rag_results:
            return messages

        # 4. å°†RAGå†…å®¹æ•´åˆåˆ°ä¸Šä¸‹æ–‡
        # åœ¨system_promptä¹‹åæ’å…¥RAGå†…å®¹
        if rag_results:
            rag_context_parts = []
            for i, result in enumerate(rag_results):
                rag_context_parts.append(
                    f"[å‚è€ƒä¿¡æ¯{i+1}] {result['content']}\n"
                )

            rag_message = {
                "role": "system",
                "content": f"ã€ç›¸å…³çŸ¥è¯†åº“ä¿¡æ¯ã€‘\n{''.join(rag_context_parts)}"
            }

            # æ’å…¥åˆ°system_promptä¹‹å
            insert_index = 1 if len(messages) > 0 else 0
            messages.insert(insert_index, rag_message)

            self.logger.info(f"å·²æ•´åˆ{len(rag_results)}æ¡RAGå†…å®¹åˆ°ä¸Šä¸‹æ–‡")

        return messages

    async def _detect_rag_need(self, message: str) -> bool:
        """
        æ£€æµ‹æ¶ˆæ¯æ˜¯å¦éœ€è¦RAGå¢å¼º

        åˆ¤æ–­æ ‡å‡†ï¼š
        1. åŒ…å«ä¸“ä¸šçŸ¥è¯†ç›¸å…³è¯æ±‡
        2. åŒ…å«æŸ¥è¯¢/æ£€ç´¢ç›¸å…³è¯æ±‡
        3. åŒ…å«"æ€ä¹ˆ""å¦‚ä½•"ç­‰ç–‘é—®è¯

        Args:
            message: æ¶ˆæ¯å†…å®¹

        Returns:
            æ˜¯å¦éœ€è¦RAG
        """
        rag_keywords = [
            "å‰§æœ¬", "æ¡¥æ®µ", "æƒ…èŠ‚", "é«˜èƒ½", "çˆ†ç‚¹", "çˆ½ç‚¹",
            "çŸ¥è¯†", "æŸ¥è¯¢", "æ£€ç´¢", "æœç´¢",
            "æ€ä¹ˆ", "å¦‚ä½•", "ä»€ä¹ˆæ˜¯", "å“ªäº›",
            "æŠ€å·§", "æ–¹æ³•", "ç»éªŒ", "å»ºè®®"
        ]

        message_lower = message.lower()

        # æ£€æŸ¥æ˜¯å¦åŒ…å«RAGå…³é”®è¯
        for keyword in rag_keywords:
            if keyword in message_lower:
                return True

        return False

    # ==================== æ™ºèƒ½é€‰æ‹©æœºåˆ¶ï¼ˆæ–°å¢ï¼‰ ====================

    async def smart_select_context(
        self,
        session_id: str,
        user_id: str,
        current_task: str,
        sources: List[str] = None
    ) -> Dict[str, Any]:
        """
        æ™ºèƒ½é€‰æ‹©ä¸Šä¸‹æ–‡ï¼ˆç»¼åˆé€‰æ‹©æœºåˆ¶ï¼‰

        æ•´åˆæ‰€æœ‰é€‰æ‹©ç­–ç•¥ï¼š
        1. ä»è‰ç¨¿çº¸é€‰æ‹©ï¼ˆselect_from_scratchpadï¼‰
        2. ä»é•¿æœŸè®°å¿†é€‰æ‹©ï¼ˆlong_term_summary, script_memoryï¼‰
        3. ä»RAGé€‰æ‹©ï¼ˆauto_load_rag_contextï¼‰

        Args:
            session_id: ä¼šè¯ID
            user_id: ç”¨æˆ·ID
            current_task: å½“å‰ä»»åŠ¡æè¿°
            sources: æ•°æ®æºåˆ—è¡¨ (scratchpad|memory|rag|all)ï¼Œé»˜è®¤all

        Returns:
            é€‰æ‹©çš„ä¸Šä¸‹æ–‡ï¼ŒåŒ…å«ï¼š
            - from_scratchpad: æ¥è‡ªè‰ç¨¿çº¸çš„å†…å®¹
            - from_memory: æ¥è‡ªé•¿æœŸè®°å¿†çš„å†…å®¹
            - from_rag: æ¥è‡ªRAGçš„å†…å®¹
            - combined: æ•´åˆåçš„ä¸Šä¸‹æ–‡
        """
        if sources is None:
            sources = ["all"]

        result = {
            "from_scratchpad": [],
            "from_memory": "",
            "from_rag": [],
            "combined": ""
        }

        try:
            # 1. ä»è‰ç¨¿çº¸é€‰æ‹©
            if "all" in sources or "scratchpad" in sources:
                scratchpad_items = await self.select_from_scratchpad(
                    session_id, user_id, current_task,
                    max_items=3, min_importance=0.4
                )
                result["from_scratchpad"] = scratchpad_items

            # 2. ä»é•¿æœŸè®°å¿†é€‰æ‹©
            if "all" in sources or "memory" in sources:
                # è·å–å‰§æœ¬ä¸Šä¸‹æ–‡æ‘˜è¦
                memory_summary = await self.get_script_context_summary(session_id, user_id)
                result["from_memory"] = memory_summary

                # è·å–ä¸Šä¸‹æ–‡çª—å£ä¸­çš„é•¿æœŸæ‘˜è¦
                window = self.context_windows.get(f"{user_id}_{session_id}")
                if window and window.long_term_summary:
                    if result["from_memory"]:
                        result["from_memory"] += "\n\nã€å†å²å¯¹è¯æ‘˜è¦ã€‘\n" + window.long_term_summary
                    else:
                        result["from_memory"] = "ã€å†å²å¯¹è¯æ‘˜è¦ã€‘\n" + window.long_term_summary

            # 3. ä»RAGé€‰æ‹©
            if "all" in sources or "rag" in sources:
                rag_items = await self.auto_load_rag_context(
                    session_id, user_id, current_task,
                    enable_rag=True, enable_hybrid=True, top_k=2
                )
                result["from_rag"] = rag_items

            # 4. æ•´åˆä¸Šä¸‹æ–‡
            combined_parts = []

            if result["from_memory"]:
                combined_parts.append(f"ã€è®°å¿†ä¿¡æ¯ã€‘\n{result['from_memory']}")

            if result["from_scratchpad"]:
                scratchpad_content = "\n".join([
                    f"- {item.get('content', '')[:200]}"
                    for item in result["from_scratchpad"]
                ])
                combined_parts.append(f"ã€è‰ç¨¿ä¿¡æ¯ã€‘\n{scratchpad_content}")

            if result["from_rag"]:
                rag_content = "\n".join([
                    f"- {item.get('content', '')[:200]}"
                    for item in result["from_rag"]
                ])
                combined_parts.append(f"ã€çŸ¥è¯†åº“ä¿¡æ¯ã€‘\n{rag_content}")

            result["combined"] = "\n\n".join(combined_parts)

            self.logger.info(f"æ™ºèƒ½é€‰æ‹©ä¸Šä¸‹æ–‡å®Œæˆ: è‰ç¨¿çº¸{len(result['from_scratchpad'])}æ¡, RAG{len(result['from_rag'])}æ¡")

            return result

        except Exception as e:
            self.logger.error(f"æ™ºèƒ½é€‰æ‹©ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            return result

    # ==================== å¥åº·æ£€æŸ¥ ====================

    async def get_context_health(
        self,
        session_id: str,
        user_id: str
    ) -> Dict[str, Any]:
        """è·å–ä¸Šä¸‹æ–‡å¥åº·çŠ¶æ€"""
        key = f"{user_id}_{session_id}"
        window = self.context_windows.get(key)

        if not window:
            return {
                "status": "no_context",
                "message": "æ— ä¸Šä¸‹æ–‡"
            }

        usage_ratio = window.total_tokens / self.budget.max_context_tokens
        is_healthy = usage_ratio < 0.9

        return {
            "status": "healthy" if is_healthy else "warning",
            "total_tokens": window.total_tokens,
            "max_tokens": self.budget.max_context_tokens,
            "usage_ratio": f"{usage_ratio:.1%}",
            "message_count": window.message_count,
            "compression_count": window.compression_count,
            "immediate_count": len(window.immediate),
            "recent_count": len(window.recent),
            "working_count": len(window.working),
            "has_long_term_summary": bool(window.long_term_summary),
            "key_anchors_count": len(window.key_anchors),
            "character_mentions": window.character_mentions,
            "recommendations": self._get_health_recommendations(window, usage_ratio)
        }

    def _get_health_recommendations(
        self,
        window: ContextWindow,
        usage_ratio: float
    ) -> List[str]:
        """è·å–å¥åº·å»ºè®®"""
        recommendations = []

        if usage_ratio > 0.9:
            recommendations.append("âš ï¸ ä¸Šä¸‹æ–‡æ¥è¿‘ä¸Šé™ï¼Œå»ºè®®å¯åŠ¨å¼ºåˆ¶å‹ç¼©")
        elif usage_ratio > 0.75:
            recommendations.append("â„¹ï¸ ä¸Šä¸‹æ–‡ä½¿ç”¨ç‡è¾ƒé«˜ï¼Œå°†å¯ç”¨è‡ªåŠ¨å‹ç¼©")

        if window.compression_count == 0 and window.message_count > 20:
            recommendations.append("â„¹ï¸ å»ºè®®å¯ç”¨è‡ªåŠ¨æ‘˜è¦ä»¥èŠ‚çœtokens")

        if len(window.key_anchors) > 15:
            recommendations.append("â„¹ï¸ é”šç‚¹ä¿¡æ¯è¿‡å¤šï¼Œå»ºè®®æ¸…ç†æ—§çš„é”šç‚¹")

        if not window.long_term_summary and window.message_count > 30:
            recommendations.append("â„¹ï¸ å»ºè®®ç”Ÿæˆé•¿æœŸæ‘˜è¦ä»¥ä¿å­˜é‡è¦ä¿¡æ¯")

        return recommendations

    async def cleanup_old_sessions(self, max_age_hours: int = 24):
        """æ¸…ç†æ—§ä¼šè¯"""
        cutoff = datetime.now() - timedelta(hours=max_age_hours)
        to_remove = []

        for key, window in self.context_windows.items():
            # æ£€æŸ¥æœ€åæ´»åŠ¨æ—¶é—´ï¼ˆé€šè¿‡compressionæ—¶é—´åˆ¤æ–­ï¼‰
            if window.last_compression:
                try:
                    last_active = datetime.fromisoformat(window.last_compression)
                    if last_active < cutoff:
                        to_remove.append(key)
                except:
                    pass

        for key in to_remove:
            del self.context_windows[key]
            # åŒæ—¶æ¸…ç†å‰§æœ¬è®°å¿†
            if key in self.script_memories:
                del self.script_memories[key]

        if to_remove:
            self.logger.info(f"æ¸…ç†äº† {len(to_remove)} ä¸ªæ—§ä¼šè¯")


# ==================== å…¨å±€å®ä¾‹ ====================

_global_manager = None


def get_enhanced_context_manager() -> EnhancedContextManager:
    """è·å–å…¨å±€å¢å¼ºä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    global _global_manager
    if _global_manager is None:
        _global_manager = EnhancedContextManager()
    return _global_manager


async def rebuild_context(
    session_id: str,
    user_id: str,
    system_prompt: str,
    new_message: str,
    extra_messages: Optional[List[Dict[str, Any]]] = None
) -> List[Dict[str, Any]]:
    """ä¾¿æ·å‡½æ•°ï¼šé‡å»ºä¸Šä¸‹æ–‡"""
    manager = get_enhanced_context_manager()
    await manager.initialize()
    return await manager.rebuild_context_for_llm(
        session_id, user_id, system_prompt, new_message, extra_messages=extra_messages
    )


async def rebuild_context_with_rag(
    session_id: str,
    user_id: str,
    system_prompt: str,
    new_message: str,
    enable_auto_rag: bool = True,
    max_rag_items: int = 3,
    extra_messages: Optional[List[Dict[str, Any]]] = None
) -> List[Dict[str, Any]]:
    """ä¾¿æ·å‡½æ•°ï¼šé‡å»ºä¸Šä¸‹æ–‡ï¼ˆå¸¦RAGè‡ªåŠ¨åŠ è½½ï¼‰"""
    manager = get_enhanced_context_manager()
    await manager.initialize()
    return await manager.rebuild_context_with_rag(
        session_id, user_id, system_prompt, new_message,
        enable_auto_rag, max_rag_items=max_rag_items, extra_messages=extra_messages
    )


async def smart_select_context(
    session_id: str,
    user_id: str,
    current_task: str,
    sources: Optional[List[str]] = None
) -> Dict[str, Any]:
    """ä¾¿æ·å‡½æ•°ï¼šæ™ºèƒ½é€‰æ‹©ä¸Šä¸‹æ–‡"""
    manager = get_enhanced_context_manager()
    await manager.initialize()
    return await manager.smart_select_context(
        session_id, user_id, current_task, sources
    )


async def auto_load_rag(
    session_id: str,
    user_id: str,
    query: str,
    top_k: int = 3,
    collection: str = "script_segments"
) -> List[Dict[str, Any]]:
    """ä¾¿æ·å‡½æ•°ï¼šè‡ªåŠ¨åŠ è½½RAGå†…å®¹"""
    manager = get_enhanced_context_manager()
    await manager.initialize()
    return await manager.auto_load_rag_context(
        session_id, user_id, query,
        enable_rag=True, enable_hybrid=True,
        top_k=top_k, collection=collection
    )
