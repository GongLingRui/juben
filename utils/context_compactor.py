"""
æ™ºèƒ½ä¸Šä¸‹æ–‡å‹ç¼©ç³»ç»Ÿ
 æ¶æ„çš„ä¸Šä¸‹æ–‡å‹ç¼©æœºåˆ¶ï¼Œå®ç°"AIä¸ºè‡ªå·±å†™ä¼šè®®çºªè¦"çš„åŠŸèƒ½
"""
import os
import json
import asyncio
import logging
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass, asdict
from pathlib import Path
import hashlib

try:
    from ..config.settings import JubenSettings
    from ..utils.logger import JubenLogger
    from ..utils.storage_manager import JubenStorageManager, ChatMessage, ContextState
    from ..utils.llm_client import JubenLLMClient
except ImportError:
    import sys
    from pathlib import Path
    sys.path.insert(0, str(Path(__file__).parent.parent))
    
    from config.settings import JubenSettings
    from utils.logger import JubenLogger
    from utils.storage_manager import JubenStorageManager, ChatMessage, ContextState
    from utils.llm_client import JubenLLMClient


@dataclass
class CompressionConfig:
    """å‹ç¼©é…ç½®"""
    max_context_length: int = 8000  # æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦
    compression_threshold: float = 0.8  # å‹ç¼©é˜ˆå€¼ï¼ˆ80%æ—¶å¼€å§‹å‹ç¼©ï¼‰
    summary_ratio: float = 0.3  # æ‘˜è¦æ¯”ä¾‹ï¼ˆä¿ç•™30%çš„åŸå§‹ä¿¡æ¯ï¼‰
    preserve_recent: int = 10  # ä¿ç•™æœ€è¿‘Næ¡æ¶ˆæ¯
    preserve_important: bool = True  # æ˜¯å¦ä¿ç•™é‡è¦æ¶ˆæ¯
    compression_quality: str = "high"  # å‹ç¼©è´¨é‡ï¼šhigh, medium, low


@dataclass
class CompressionResult:
    """å‹ç¼©ç»“æœ"""
    original_count: int
    compressed_count: int
    compression_ratio: float
    summary: str
    preserved_messages: List[Dict[str, Any]]
    compressed_messages: List[Dict[str, Any]]
    compression_metadata: Dict[str, Any]
    created_at: str


@dataclass
class ContextSummary:
    """ä¸Šä¸‹æ–‡æ‘˜è¦"""
    session_id: str
    user_id: str
    agent_name: str
    summary_content: str
    key_points: List[str]
    important_decisions: List[str]
    action_items: List[str]
    context_hash: str
    created_at: str
    expires_at: str


class ContextCompactor:
    """æ™ºèƒ½ä¸Šä¸‹æ–‡å‹ç¼©å™¨"""
    
    def __init__(self, model_provider: str = "zhipu"):
        """
        åˆå§‹åŒ–ä¸Šä¸‹æ–‡å‹ç¼©å™¨
        
        Args:
            model_provider: æ¨¡å‹æä¾›å•†
        """
        self.config = JubenSettings()
        self.logger = JubenLogger("ContextCompactor", level=self.config.log_level)
        self.storage_manager = JubenStorageManager()
        self.llm_client = JubenLLMClient(model_provider)
        
        # å‹ç¼©é…ç½®
        self.compression_config = CompressionConfig()
        
        # å‹ç¼©å†å²è®°å½•
        self.compression_history: List[CompressionResult] = []
        
        self.logger.info("æ™ºèƒ½ä¸Šä¸‹æ–‡å‹ç¼©å™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def initialize(self):
        """åˆå§‹åŒ–å‹ç¼©å™¨"""
        try:
            await self.storage_manager.initialize()
            self.logger.info("âœ… ä¸Šä¸‹æ–‡å‹ç¼©å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            self.logger.error(f"âŒ ä¸Šä¸‹æ–‡å‹ç¼©å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def calculate_context_length(self, messages: List[Dict[str, Any]]) -> int:
        """è®¡ç®—ä¸Šä¸‹æ–‡é•¿åº¦"""
        total_length = 0
        for message in messages:
            content = message.get('content', '')
            if isinstance(content, str):
                total_length += len(content)
            elif isinstance(content, dict):
                total_length += len(str(content))
        return total_length
    
    def should_compress(self, messages: List[Dict[str, Any]]) -> Tuple[bool, float]:
        """
        åˆ¤æ–­æ˜¯å¦éœ€è¦å‹ç¼©
        
        Returns:
            (æ˜¯å¦éœ€è¦å‹ç¼©, å½“å‰ä½¿ç”¨ç‡)
        """
        current_length = self.calculate_context_length(messages)
        max_length = self.compression_config.max_context_length
        usage_ratio = current_length / max_length
        
        should_compress = usage_ratio >= self.compression_config.compression_threshold
        
        return should_compress, usage_ratio
    
    def identify_important_messages(self, messages: List[Dict[str, Any]]) -> List[int]:
        """
        è¯†åˆ«é‡è¦æ¶ˆæ¯
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            é‡è¦æ¶ˆæ¯çš„ç´¢å¼•åˆ—è¡¨
        """
        important_indices = []
        
        for i, message in enumerate(messages):
            content = message.get('content', '')
            message_type = message.get('message_type', '')
            
            # é‡è¦æ¶ˆæ¯åˆ¤æ–­æ ‡å‡†
            is_important = False
            
            # 1. ç³»ç»Ÿæ¶ˆæ¯å’Œé”™è¯¯æ¶ˆæ¯
            if message_type in ['system', 'error']:
                is_important = True
            
            # 2. åŒ…å«å…³é”®è¯çš„æ¶ˆæ¯
            important_keywords = [
                'é‡è¦', 'å…³é”®', 'å†³å®š', 'å†³ç­–', 'æ€»ç»“', 'ç»“è®º',
                'action', 'todo', 'ä»»åŠ¡', 'ç›®æ ‡', 'è®¡åˆ’'
            ]
            
            if isinstance(content, str):
                content_lower = content.lower()
                if any(keyword in content_lower for keyword in important_keywords):
                    is_important = True
            
            # 3. é•¿æ¶ˆæ¯ï¼ˆå¯èƒ½åŒ…å«é‡è¦ä¿¡æ¯ï¼‰
            if len(str(content)) > 500:
                is_important = True
            
            # 4. åŒ…å«ç»“æ„åŒ–æ•°æ®
            if isinstance(content, dict) and len(content) > 3:
                is_important = True
            
            if is_important:
                important_indices.append(i)
        
        return important_indices
    
    async def generate_context_summary(
        self, 
        messages: List[Dict[str, Any]], 
        user_id: str, 
        session_id: str, 
        agent_name: str
    ) -> str:
        """
        ç”Ÿæˆä¸Šä¸‹æ–‡æ‘˜è¦
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            user_id: ç”¨æˆ·ID
            session_id: ä¼šè¯ID
            agent_name: Agentåç§°
            
        Returns:
            ä¸Šä¸‹æ–‡æ‘˜è¦
        """
        try:
            # æ„å»ºå‹ç¼©æç¤ºè¯
            prompt = self._build_compression_prompt(messages, user_id, session_id, agent_name)
            
            # è°ƒç”¨LLMç”Ÿæˆæ‘˜è¦
            response = await self.llm_client.generate_response(
                prompt=prompt,
                max_tokens=2000,
                temperature=0.3
            )
            
            if response and response.get('content'):
                return response['content']
            else:
                # å¦‚æœLLMè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨ç®€å•æ‘˜è¦
                return self._generate_simple_summary(messages)
                
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆä¸Šä¸‹æ–‡æ‘˜è¦å¤±è´¥: {e}")
            return self._generate_simple_summary(messages)
    
    def _build_compression_prompt(
        self, 
        messages: List[Dict[str, Any]], 
        user_id: str, 
        session_id: str, 
        agent_name: str
    ) -> str:
        """æ„å»ºå‹ç¼©æç¤ºè¯"""
        
        # æ„å»ºæ¶ˆæ¯å†å²
        message_history = []
        for i, message in enumerate(messages):
            msg_type = message.get('message_type', 'unknown')
            content = message.get('content', '')
            timestamp = message.get('created_at', '')
            
            message_history.append(f"[{i+1}] {msg_type.upper()}: {content}")
        
        message_text = "\n".join(message_history)
        
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸Šä¸‹æ–‡å‹ç¼©ä¸“å®¶ï¼Œéœ€è¦ä¸ºAIç³»ç»Ÿç”Ÿæˆé«˜è´¨é‡çš„ä¸Šä¸‹æ–‡æ‘˜è¦ã€‚

## ä»»åŠ¡èƒŒæ™¯
- ç”¨æˆ·ID: {user_id}
- ä¼šè¯ID: {session_id}
- Agent: {agent_name}
- å½“å‰ä¸Šä¸‹æ–‡é•¿åº¦: {self.calculate_context_length(messages)} å­—ç¬¦

## å¯¹è¯å†å²
{message_text}

## å‹ç¼©è¦æ±‚
è¯·ç”Ÿæˆä¸€ä¸ªé«˜è´¨é‡çš„ä¸Šä¸‹æ–‡æ‘˜è¦ï¼Œè¦æ±‚ï¼š

1. **ä¿æŒæ ¸å¿ƒä¿¡æ¯å®Œæ•´æ€§**ï¼šä¿ç•™æ‰€æœ‰é‡è¦çš„å†³ç­–ã€ç»“è®ºå’Œå…³é”®ä¿¡æ¯
2. **çªå‡ºé‡è¦å†³ç­–**ï¼šæ˜ç¡®æ ‡è¯†ç”¨æˆ·çš„é‡è¦å†³å®šå’Œåå¥½
3. **æå–è¡ŒåŠ¨é¡¹**ï¼šè¯†åˆ«éœ€è¦åç»­å¤„ç†çš„ä»»åŠ¡å’Œå¾…åŠäº‹é¡¹
4. **ä¿æŒä¸Šä¸‹æ–‡è¿è´¯æ€§**ï¼šç¡®ä¿æ‘˜è¦èƒ½å¤Ÿæ”¯æŒåç»­å¯¹è¯çš„è¿è´¯æ€§
5. **ä¿ç•™å…³é”®ç»†èŠ‚**ï¼šä¸è¦ä¸¢å¤±é‡è¦çš„æŠ€æœ¯ç»†èŠ‚å’Œå…·ä½“ä¿¡æ¯

## è¾“å‡ºæ ¼å¼
è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºæ‘˜è¦ï¼š

**ä¸Šä¸‹æ–‡æ‘˜è¦ï¼š**
[ç”Ÿæˆé«˜è´¨é‡çš„ä¸Šä¸‹æ–‡æ‘˜è¦ï¼ŒåŒ…å«å¯¹è¯çš„æ ¸å¿ƒå†…å®¹å’Œé‡è¦ä¿¡æ¯]

**å…³é”®å†³ç­–ï¼š**
- [åˆ—å‡ºç”¨æˆ·çš„é‡è¦å†³ç­–å’Œåå¥½]
- [åˆ—å‡ºç³»ç»Ÿçš„é‡è¦å†³å®š]

**è¡ŒåŠ¨é¡¹ï¼š**
- [åˆ—å‡ºéœ€è¦åç»­å¤„ç†çš„ä»»åŠ¡]
- [åˆ—å‡ºå¾…åŠäº‹é¡¹]

**é‡è¦ç»†èŠ‚ï¼š**
- [åˆ—å‡ºéœ€è¦ä¿ç•™çš„æŠ€æœ¯ç»†èŠ‚]
- [åˆ—å‡ºå…·ä½“çš„å‚æ•°å’Œé…ç½®]

è¯·ç¡®ä¿æ‘˜è¦ç®€æ´ä½†ä¿¡æ¯å®Œæ•´ï¼Œèƒ½å¤Ÿæ”¯æŒåç»­å¯¹è¯çš„é¡ºåˆ©è¿›è¡Œã€‚
"""
        
        return prompt
    
    def _generate_simple_summary(self, messages: List[Dict[str, Any]]) -> str:
        """ç”Ÿæˆç®€å•æ‘˜è¦ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        total_messages = len(messages)
        user_messages = sum(1 for msg in messages if msg.get('message_type') == 'user')
        assistant_messages = sum(1 for msg in messages if msg.get('message_type') == 'assistant')
        
        summary = f"""
ä¸Šä¸‹æ–‡æ‘˜è¦ï¼š
- æ€»æ¶ˆæ¯æ•°: {total_messages}
- ç”¨æˆ·æ¶ˆæ¯: {user_messages}
- åŠ©æ‰‹æ¶ˆæ¯: {assistant_messages}
- å¯¹è¯æ—¶é—´è·¨åº¦: {messages[0].get('created_at', '')} åˆ° {messages[-1].get('created_at', '')}

å…³é”®ä¿¡æ¯ï¼š
- å¯¹è¯ä¸»è¦å›´ç»• {self._extract_main_topics(messages)} å±•å¼€
- ç”¨æˆ·ä¸»è¦å…³æ³¨ç‚¹: {self._extract_user_concerns(messages)}
"""
        
        return summary
    
    def _extract_main_topics(self, messages: List[Dict[str, Any]]) -> str:
        """æå–ä¸»è¦è¯é¢˜"""
        # ç®€å•çš„å…³é”®è¯æå–
        all_content = " ".join(str(msg.get('content', '')) for msg in messages)
        # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤æ‚çš„è¯é¢˜æå–é€»è¾‘
        return "å¯¹è¯å†…å®¹åˆ†æ"
    
    def _extract_user_concerns(self, messages: List[Dict[str, Any]]) -> str:
        """æå–ç”¨æˆ·å…³æ³¨ç‚¹"""
        user_messages = [msg for msg in messages if msg.get('message_type') == 'user']
        if not user_messages:
            return "æœªè¯†åˆ«åˆ°ç”¨æˆ·å…³æ³¨ç‚¹"
        
        # ç®€å•çš„å…³æ³¨ç‚¹æå–
        return "ç”¨æˆ·éœ€æ±‚åˆ†æ"
    
    async def compress_context(
        self, 
        user_id: str, 
        session_id: str, 
        agent_name: str,
        force_compress: bool = False
    ) -> Optional[CompressionResult]:
        """
        å‹ç¼©ä¸Šä¸‹æ–‡
        
        Args:
            user_id: ç”¨æˆ·ID
            session_id: ä¼šè¯ID
            agent_name: Agentåç§°
            force_compress: æ˜¯å¦å¼ºåˆ¶å‹ç¼©
            
        Returns:
            å‹ç¼©ç»“æœ
        """
        try:
            self.logger.info(f"ğŸ”„ å¼€å§‹å‹ç¼©ä¸Šä¸‹æ–‡: {user_id}/{session_id}/{agent_name}")
            
            # è·å–å½“å‰æ¶ˆæ¯
            messages = await self.storage_manager.get_chat_messages(user_id, session_id, limit=1000)
            if not messages:
                self.logger.warning("æ²¡æœ‰æ‰¾åˆ°éœ€è¦å‹ç¼©çš„æ¶ˆæ¯")
                return None
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦å‹ç¼©
            should_compress, usage_ratio = self.should_compress(messages)
            if not should_compress and not force_compress:
                self.logger.info(f"ä¸Šä¸‹æ–‡ä½¿ç”¨ç‡ {usage_ratio:.2%}ï¼Œæ— éœ€å‹ç¼©")
                return None
            
            self.logger.info(f"ğŸ“Š ä¸Šä¸‹æ–‡ä½¿ç”¨ç‡: {usage_ratio:.2%}ï¼Œå¼€å§‹å‹ç¼©")
            
            # è¯†åˆ«é‡è¦æ¶ˆæ¯
            important_indices = self.identify_important_messages(messages)
            self.logger.info(f"ğŸ” è¯†åˆ«åˆ° {len(important_indices)} æ¡é‡è¦æ¶ˆæ¯")
            
            # ç”Ÿæˆä¸Šä¸‹æ–‡æ‘˜è¦
            summary = await self.generate_context_summary(messages, user_id, session_id, agent_name)
            self.logger.info(f"ğŸ“ ç”Ÿæˆä¸Šä¸‹æ–‡æ‘˜è¦: {len(summary)} å­—ç¬¦")
            
            # é€‰æ‹©ä¿ç•™çš„æ¶ˆæ¯
            preserved_messages = self._select_preserved_messages(messages, important_indices)
            
            # åˆ›å»ºå‹ç¼©ç»“æœ
            compression_result = CompressionResult(
                original_count=len(messages),
                compressed_count=len(preserved_messages),
                compression_ratio=len(preserved_messages) / len(messages),
                summary=summary,
                preserved_messages=preserved_messages,
                compressed_messages=messages,
                compression_metadata={
                    "usage_ratio": usage_ratio,
                    "important_count": len(important_indices),
                    "compression_quality": self.compression_config.compression_quality,
                    "timestamp": datetime.now().isoformat()
                },
                created_at=datetime.now().isoformat()
            )
            
            # ä¿å­˜å‹ç¼©ç»“æœ
            await self._save_compression_result(compression_result, user_id, session_id, agent_name)
            
            # æ›´æ–°ä¸Šä¸‹æ–‡çŠ¶æ€
            await self._update_context_after_compression(
                user_id, session_id, agent_name, compression_result
            )
            
            self.logger.info(f"âœ… ä¸Šä¸‹æ–‡å‹ç¼©å®Œæˆ: {compression_result.compression_ratio:.2%}")
            return compression_result
            
        except Exception as e:
            self.logger.error(f"âŒ ä¸Šä¸‹æ–‡å‹ç¼©å¤±è´¥: {e}")
            return None
    
    def _select_preserved_messages(
        self, 
        messages: List[Dict[str, Any]], 
        important_indices: List[int]
    ) -> List[Dict[str, Any]]:
        """é€‰æ‹©ä¿ç•™çš„æ¶ˆæ¯"""
        preserved = []
        
        # 1. ä¿ç•™é‡è¦æ¶ˆæ¯
        for idx in important_indices:
            if idx < len(messages):
                preserved.append(messages[idx])
        
        # 2. ä¿ç•™æœ€è¿‘çš„æ¶ˆæ¯
        recent_count = self.compression_config.preserve_recent
        recent_messages = messages[-recent_count:]
        
        for msg in recent_messages:
            if msg not in preserved:
                preserved.append(msg)
        
        # 3. æŒ‰æ—¶é—´æ’åº
        preserved.sort(key=lambda x: x.get('created_at', ''))
        
        return preserved
    
    async def _save_compression_result(
        self, 
        result: CompressionResult, 
        user_id: str, 
        session_id: str, 
        agent_name: str
    ):
        """ä¿å­˜å‹ç¼©ç»“æœ"""
        try:
            # åˆ›å»ºä¸Šä¸‹æ–‡æ‘˜è¦è®°å½•
            context_hash = hashlib.md5(
                f"{user_id}_{session_id}_{agent_name}_{result.created_at}".encode()
            ).hexdigest()
            
            summary = ContextSummary(
                session_id=session_id,
                user_id=user_id,
                agent_name=agent_name,
                summary_content=result.summary,
                key_points=self._extract_key_points(result.summary),
                important_decisions=self._extract_decisions(result.summary),
                action_items=self._extract_action_items(result.summary),
                context_hash=context_hash,
                created_at=result.created_at,
                expires_at=(datetime.now() + timedelta(days=7)).isoformat()
            )
            
            # ä¿å­˜åˆ°å­˜å‚¨ç³»ç»Ÿ
            # è¿™é‡Œå¯ä»¥æ·»åŠ ä¿å­˜é€»è¾‘
            
            self.logger.info(f"ğŸ’¾ å‹ç¼©ç»“æœå·²ä¿å­˜: {context_hash}")
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜å‹ç¼©ç»“æœå¤±è´¥: {e}")
    
    def _extract_key_points(self, summary: str) -> List[str]:
        """æå–å…³é”®ç‚¹"""
        # ç®€å•çš„å…³é”®ç‚¹æå–
        lines = summary.split('\n')
        key_points = []
        for line in lines:
            if line.strip().startswith('-') or line.strip().startswith('â€¢'):
                key_points.append(line.strip())
        return key_points[:10]  # æœ€å¤š10ä¸ªå…³é”®ç‚¹
    
    def _extract_decisions(self, summary: str) -> List[str]:
        """æå–å†³ç­–"""
        # ç®€å•çš„å†³ç­–æå–
        decisions = []
        if 'å†³å®š' in summary or 'å†³ç­–' in summary:
            decisions.append("ç”¨æˆ·åšå‡ºäº†é‡è¦å†³å®š")
        return decisions
    
    def _extract_action_items(self, summary: str) -> List[str]:
        """æå–è¡ŒåŠ¨é¡¹"""
        # ç®€å•çš„è¡ŒåŠ¨é¡¹æå–
        actions = []
        if 'ä»»åŠ¡' in summary or 'å¾…åŠ' in summary:
            actions.append("æœ‰å¾…å¤„ç†çš„ä»»åŠ¡")
        return actions
    
    async def _update_context_after_compression(
        self, 
        user_id: str, 
        session_id: str, 
        agent_name: str, 
        result: CompressionResult
    ):
        """å‹ç¼©åæ›´æ–°ä¸Šä¸‹æ–‡"""
        try:
            # æ›´æ–°ä¸Šä¸‹æ–‡çŠ¶æ€ï¼Œæ·»åŠ å‹ç¼©ä¿¡æ¯
            context_data = {
                "compression_applied": True,
                "compression_time": result.created_at,
                "compression_ratio": result.compression_ratio,
                "summary_available": True,
                "original_message_count": result.original_count,
                "preserved_message_count": result.compressed_count
            }
            
            await self.storage_manager.save_context_state(
                ContextState(
                    user_id=user_id,
                    session_id=session_id,
                    agent_name=agent_name,
                    context_data=context_data
                )
            )
            
            self.logger.info("âœ… ä¸Šä¸‹æ–‡çŠ¶æ€å·²æ›´æ–°")
            
        except Exception as e:
            self.logger.error(f"æ›´æ–°ä¸Šä¸‹æ–‡çŠ¶æ€å¤±è´¥: {e}")
    
    async def get_context_summary(
        self, 
        user_id: str, 
        session_id: str, 
        agent_name: str
    ) -> Optional[ContextSummary]:
        """è·å–ä¸Šä¸‹æ–‡æ‘˜è¦"""
        try:
            # è¿™é‡Œå¯ä»¥å®ç°ä»å­˜å‚¨ä¸­è·å–æ‘˜è¦çš„é€»è¾‘
            # æš‚æ—¶è¿”å›None
            return None
        except Exception as e:
            self.logger.error(f"è·å–ä¸Šä¸‹æ–‡æ‘˜è¦å¤±è´¥: {e}")
            return None
    
    def get_compression_stats(self) -> Dict[str, Any]:
        """è·å–å‹ç¼©ç»Ÿè®¡ä¿¡æ¯"""
        if not self.compression_history:
            return {"total_compressions": 0}
        
        total_compressions = len(self.compression_history)
        avg_compression_ratio = sum(
            result.compression_ratio for result in self.compression_history
        ) / total_compressions
        
        return {
            "total_compressions": total_compressions,
            "average_compression_ratio": avg_compression_ratio,
            "last_compression": self.compression_history[-1].created_at if self.compression_history else None
        }


# å…¨å±€å‹ç¼©å™¨å®ä¾‹
_global_compactor = None

def get_context_compactor() -> ContextCompactor:
    """è·å–å…¨å±€ä¸Šä¸‹æ–‡å‹ç¼©å™¨"""
    global _global_compactor
    if _global_compactor is None:
        _global_compactor = ContextCompactor()
    return _global_compactor

async def compress_context_if_needed(
    user_id: str, 
    session_id: str, 
    agent_name: str,
    force: bool = False
) -> Optional[CompressionResult]:
    """æ™ºèƒ½å‹ç¼©ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœéœ€è¦ï¼‰"""
    compactor = get_context_compactor()
    await compactor.initialize()
    return await compactor.compress_context(user_id, session_id, agent_name, force)


def main():
    """ä¸»å‡½æ•° - ç”¨äºæµ‹è¯•å’Œæ¼”ç¤º"""
    import sys
    
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # åˆ›å»ºå‹ç¼©å™¨
    compactor = ContextCompactor()
    
    # æ¨¡æ‹Ÿå‹ç¼©æµ‹è¯•
    logger.info("æ™ºèƒ½ä¸Šä¸‹æ–‡å‹ç¼©å™¨æµ‹è¯•å®Œæˆ")
    return True


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
