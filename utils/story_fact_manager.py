"""
æ•…äº‹äº‹å®ç®¡ç†å™¨

ä»å‰§æœ¬ç‰‡æ®µä¸­æå–å¹¶ç®¡ç†å…³é”®äº‹å®ï¼ˆäººç‰©ã€é“å…·ã€åœºæ™¯ç­‰ï¼‰ã€‚
ä½¿ç”¨ Redis å­˜å‚¨äº‹å®ï¼ŒæŒ‰ session_id ç»„ç»‡ã€‚
"""
import json
import logging
from dataclasses import dataclass, field, asdict
from datetime import datetime
from typing import Dict, Any, List, Optional, Set
from enum import Enum


logger = logging.getLogger(__name__)


class FactType(Enum):
    """äº‹å®ç±»å‹"""
    CHARACTER = "character"        # æ–°ç™»åœºäººç‰©
    RELATIONSHIP = "relationship"   # äººé™…å…³ç³»å˜åŒ–
    LOCATION = "location"          # åœºæ™¯åœ°ç‚¹
    PROP = "prop"                  # é‡è¦é“å…·
    EVENT = "event"                # é‡è¦äº‹ä»¶
    DEATH = "death"                # è§’è‰²æ­»äº¡
    BIRTH = "birth"                # è§’è‰²å‡ºç”Ÿ
    ABILITY = "ability"            # ç‰¹æ®Šèƒ½åŠ›
    BACKGROUND = "background"      # èƒŒæ™¯è®¾å®š
    CONSTRAINT = "constraint"      # å…¶ä»–çº¦æŸ


@dataclass
class StoryFact:
    """æ•…äº‹äº‹å®"""
    fact_type: FactType
    content: str
    source_scene: str = ""
    confidence: float = 1.0
    extracted_at: str = field(default_factory=lambda: datetime.now().isoformat())
    metadata: Dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        data = asdict(self)
        data["fact_type"] = self.fact_type.value
        return data

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "StoryFact":
        """ä»å­—å…¸åˆ›å»º"""
        data = data.copy()
        if isinstance(data.get("fact_type"), str):
            data["fact_type"] = FactType(data["fact_type"])
        return cls(**data)


@dataclass
class FactExtractionResult:
    """äº‹å®æå–ç»“æœ"""
    facts: List[StoryFact] = field(default_factory=list)
    summary: str = ""
    model_used: str = ""
    tokens_used: int = 0

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "facts": [f.to_dict() for f in self.facts],
            "summary": self.summary,
            "model_used": self.model_used,
            "tokens_used": self.tokens_used,
            "extracted_at": datetime.now().isoformat()
        }


class StoryFactManager:
    """
    æ•…äº‹äº‹å®ç®¡ç†å™¨

    åŠŸèƒ½ï¼š
    1. ä»å‰§æœ¬ç‰‡æ®µä¸­æå–å…³é”®äº‹å®
    2. å°†äº‹å®å­˜å‚¨åˆ° Redis
    3. ç”Ÿæˆç”¨äº System Prompt çš„äº‹å®çº¦æŸæ–‡æœ¬
    """

    def __init__(self, redis_client=None):
        """
        åˆå§‹åŒ–äº‹å®ç®¡ç†å™¨

        Args:
            redis_client: Redis å®¢æˆ·ç«¯å®ä¾‹
        """
        self.logger = logging.getLogger(__name__)
        self._redis = redis_client
        self._redis_loaded = False

    def _ensure_redis(self):
        """ç¡®ä¿ Redis å®¢æˆ·ç«¯å·²åŠ è½½"""
        if not self._redis_loaded:
            if self._redis is None:
                try:
                    from utils.storage_manager import get_redis_client
                    self._redis = get_redis_client()
                except ImportError:
                    self.logger.warning("æ— æ³•å¯¼å…¥ Redis å®¢æˆ·ç«¯ï¼Œä½¿ç”¨å†…å­˜å­˜å‚¨")
                    self._redis = {}
            self._redis_loaded = True

    def _get_redis_key(self, session_id: str) -> str:
        """ç”Ÿæˆ Redis é”®"""
        return f"facts:{session_id}"

    async def extract_and_save_facts(
        self,
        session_id: str,
        text: str,
        scene_title: str = "",
        model_name: str = "glm-4-flash"
    ) -> FactExtractionResult:
        """
        ä»å‰§æœ¬ç‰‡æ®µä¸­æå–å¹¶ä¿å­˜äº‹å®

        Args:
            session_id: ä¼šè¯ ID
            text: å‰§æœ¬æ–‡æœ¬
            scene_title: åœºæ™¯æ ‡é¢˜ï¼ˆå¯é€‰ï¼‰
            model_name: ä½¿ç”¨çš„æ¨¡å‹åç§°

        Returns:
            FactExtractionResult: æå–ç»“æœ
        """
        self._ensure_redis()

        # è°ƒç”¨è½»é‡çº§æ¨¡å‹æå–äº‹å®
        facts = await self._extract_facts_with_llm(text, scene_title, model_name)

        # ä¿å­˜åˆ° Redis
        await self.save_facts(session_id, facts)

        # ç”Ÿæˆæ‘˜è¦
        summary = self._generate_summary(facts)

        self.logger.info(f"ä»å‰§æœ¬ä¸­æå– {len(facts)} ä¸ªäº‹å®: {session_id}")

        return FactExtractionResult(
            facts=facts,
            summary=summary,
            model_used=model_name
        )

    async def _extract_facts_with_llm(
        self,
        text: str,
        scene_title: str,
        model_name: str
    ) -> List[StoryFact]:
        """
        ä½¿ç”¨ LLM æå–äº‹å®

        Args:
            text: å‰§æœ¬æ–‡æœ¬
            scene_title: åœºæ™¯æ ‡é¢˜
            model_name: æ¨¡å‹åç§°

        Returns:
            List[StoryFact]: æå–çš„äº‹å®åˆ—è¡¨
        """
        from utils.llm_client import llm_client

        # æ„å»ºæå–æç¤ºè¯
        prompt = self._build_extraction_prompt(text, scene_title)

        try:
            # è°ƒç”¨ LLM
            response = await llm_client.call_llm(
                messages=[{"role": "user", "content": prompt}],
                model_name=model_name,
                temperature=0.3,
                max_tokens=2000
            )

            # è§£æå“åº”
            facts = self._parse_facts_from_response(response, scene_title)
            return facts

        except Exception as e:
            self.logger.error(f"LLM äº‹å®æå–å¤±è´¥: {e}")
            # é™çº§åˆ°æ­£åˆ™è¡¨è¾¾å¼æå–
            return self._extract_facts_with_regex(text, scene_title)

    def _build_extraction_prompt(self, text: str, scene_title: str) -> str:
        """æ„å»ºäº‹å®æå–æç¤ºè¯"""
        return f"""è¯·ä»ä»¥ä¸‹å‰§æœ¬ç‰‡æ®µä¸­æå–å…³é”®äº‹å®ï¼ˆäººç‰©ã€é“å…·ã€åœºæ™¯ã€äº‹ä»¶ç­‰ï¼‰ã€‚

ã€åœºæ™¯ã€‘{scene_title or "æœªçŸ¥åœºæ™¯"}

ã€å‰§æœ¬å†…å®¹ã€‘
{text[:3000]}

ã€æå–è¦æ±‚ã€‘
è¯·è¯†åˆ«ä»¥ä¸‹ç±»å‹çš„äº‹å®ï¼Œä»¥ JSON æ ¼å¼è¾“å‡ºï¼š
1. character: æ–°ç™»åœºäººç‰©
2. relationship: äººé™…å…³ç³»å˜åŒ–
3. location: åœºæ™¯åœ°ç‚¹
4. prop: é‡è¦é“å…·
5. event: é‡è¦äº‹ä»¶
6. death: è§’è‰²æ­»äº¡
7. birth: è§’è‰²å‡ºç”Ÿ
8. ability: ç‰¹æ®Šèƒ½åŠ›
9. background: èƒŒæ™¯è®¾å®š
10. constraint: å…¶ä»–çº¦æŸ

ã€è¾“å‡ºæ ¼å¼ã€‘
{{
  "facts": [
    {{"type": "character", "content": "å¼ ä¸‰ï¼Œ35å²ï¼Œå…¬å¸é«˜ç®¡ï¼Œæ€§æ ¼å†·é…·"}},
    {{"type": "prop", "content": "ä¸€æŠŠå¤è€çš„é’¥åŒ™ï¼Œèƒ½æ‰“å¼€å¯†å®¤"}},
    {{"type": "event", "content": "ä¸»è§’å‘ç°äº†å…¬å¸è´¦ç›®å¼‚å¸¸"}}
  ]
}}

è¯·åªè¾“å‡º JSONï¼Œä¸è¦åŒ…å«å…¶ä»–è¯´æ˜ã€‚"""

    def _parse_facts_from_response(self, response: str, scene_title: str) -> List[StoryFact]:
        """è§£æ LLM å“åº”ä¸­çš„äº‹å®"""
        facts = []

        try:
            # å°è¯•æå– JSON
            response = response.strip()
            if "```json" in response:
                response = response.split("```json")[1].split("```")[0].strip()
            elif "```" in response:
                response = response.split("```")[1].split("```")[0].strip()

            data = json.loads(response)

            for item in data.get("facts", []):
                try:
                    fact_type = FactType(item.get("type", "constraint"))
                    facts.append(StoryFact(
                        fact_type=fact_type,
                        content=item.get("content", ""),
                        source_scene=scene_title,
                        confidence=0.9
                    ))
                except (ValueError, KeyError) as e:
                    self.logger.warning(f"è·³è¿‡æ— æ•ˆäº‹å®: {item}, é”™è¯¯: {e}")
                    continue

        except json.JSONDecodeError as e:
            self.logger.warning(f"JSON è§£æå¤±è´¥: {e}")

        return facts

    def _extract_facts_with_regex(self, text: str, scene_title: str) -> List[StoryFact]:
        """ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–äº‹å®ï¼ˆé™çº§æ–¹æ¡ˆï¼‰"""
        import re

        facts = []
        patterns = {
            FactType.CHARACTER: [
                r'(?:æ–°ç™»åœº|å‡ºç°|ç™»åœº|å¼•å…¥)(?:äººç‰©|è§’è‰²)[ï¼š:]\s*([^ã€‚\n]+)',
                r'([A-Z][a-z]+)\s+(?:ç™»åœº|å‡ºç°|èµ°è¿›)',
            ],
            FactType.PROP: [
                r'(?:å‘ç°|æ‹¿èµ·|æ‹¿ç€|ä½©æˆ´)(?:é“å…·|ç‰©å“|æ­¦å™¨|é¦–é¥°)[ï¼š:]\s*([^ã€‚\n]+)',
            ],
            FactType.LOCATION: [
                r'(?:æ¥åˆ°|å‰å¾€|è¿›å…¥|æŠµè¾¾)(?:åœ°ç‚¹|åœºæ™¯|åœ°æ–¹)[ï¼š:]\s*([^ã€‚\n]+)',
            ],
        }

        for fact_type, pattern_list in patterns.items():
            for pattern in pattern_list:
                matches = re.finditer(pattern, text)
                for match in matches:
                    content = match.group(1).strip()
                    if len(content) > 2:  # è¿‡æ»¤å¤ªçŸ­çš„åŒ¹é…
                        facts.append(StoryFact(
                            fact_type=fact_type,
                            content=content,
                            source_scene=scene_title,
                            confidence=0.7
                        ))

        return facts

    async def save_facts(
        self,
        session_id: str,
        facts: List[StoryFact],
        merge: bool = True
    ) -> bool:
        """
        ä¿å­˜äº‹å®åˆ° Redis

        Args:
            session_id: ä¼šè¯ ID
            facts: äº‹å®åˆ—è¡¨
            merge: æ˜¯å¦åˆå¹¶ç°æœ‰äº‹å®

        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        self._ensure_redis()

        key = self._get_redis_key(session_id)

        try:
            if merge:
                # è·å–ç°æœ‰äº‹å®
                existing_facts = await self.get_facts(session_id)
                existing_content_set = {f.content for f in existing_facts}

                # åªæ·»åŠ æ–°äº‹å®ï¼ˆåŸºäºå†…å®¹å»é‡ï¼‰
                for fact in facts:
                    if fact.content not in existing_content_set:
                        existing_facts.append(fact)

                facts_to_save = existing_facts
            else:
                facts_to_save = facts

            # ä¿å­˜åˆ° Redis
            data = [f.to_dict() for f in facts_to_save]

            if isinstance(self._redis, dict):
                self._redis[key] = json.dumps(data)
            else:
                self._redis.set(key, json.dumps(data), ex=86400 * 7)  # 7å¤©è¿‡æœŸ

            self.logger.debug(f"ä¿å­˜ {len(facts_to_save)} ä¸ªäº‹å®åˆ° {key}")
            return True

        except Exception as e:
            self.logger.error(f"ä¿å­˜äº‹å®å¤±è´¥: {e}")
            return False

    async def get_facts(self, session_id: str) -> List[StoryFact]:
        """
        ä» Redis è·å–äº‹å®

        Args:
            session_id: ä¼šè¯ ID

        Returns:
            List[StoryFact]: äº‹å®åˆ—è¡¨
        """
        self._ensure_redis()

        key = self._get_redis_key(session_id)

        try:
            if isinstance(self._redis, dict):
                data_str = self._redis.get(key)
            else:
                data_str = self._redis.get(key)

            if not data_str:
                return []

            if isinstance(data_str, bytes):
                data_str = data_str.decode()

            data = json.loads(data_str)
            return [StoryFact.from_dict(item) for item in data]

        except Exception as e:
            self.logger.error(f"è·å–äº‹å®å¤±è´¥: {e}")
            return []

    async def generate_constraints_prompt(
        self,
        session_id: str,
        max_facts: int = 20,
        priority_types: List[FactType] = None
    ) -> str:
        """
        ç”Ÿæˆç”¨äº System Prompt çš„äº‹å®çº¦æŸæ–‡æœ¬

        Args:
            session_id: ä¼šè¯ ID
            max_facts: æœ€å¤§äº‹å®æ•°é‡
            priority_types: ä¼˜å…ˆæ˜¾ç¤ºçš„äº‹å®ç±»å‹

        Returns:
            str: äº‹å®çº¦æŸæ–‡æœ¬
        """
        facts = await self.get_facts(session_id)

        if not facts:
            return ""

        # æŒ‰ç±»å‹å’Œç½®ä¿¡åº¦æ’åº
        if priority_types:
            priority_set = set(priority_types)
            facts = sorted(
                facts,
                key=lambda f: (f.fact_type not in priority_set, -f.confidence),
            )
        else:
            facts = sorted(facts, key=lambda f: -f.confidence)

        # é™åˆ¶æ•°é‡
        facts = facts[:max_facts]

        # æŒ‰ç±»å‹åˆ†ç»„
        grouped: Dict[FactType, List[StoryFact]] = {}
        for fact in facts:
            grouped.setdefault(fact.fact_type, []).append(fact)

        # ç”Ÿæˆæ–‡æœ¬
        lines = ["ã€æ ¸å¿ƒè®¾å®šçº¦æŸã€‘"]
        lines.append("ä»¥ä¸‹æ˜¯æ•…äº‹ä¸­å·²ç¡®ç«‹çš„å…³é”®è®¾å®šï¼Œè¯·ä¸¥æ ¼éµå®ˆé¿å…å†²çªï¼š\n")

        type_names = {
            FactType.CHARACTER: "ğŸ‘¤ äººç‰©",
            FactType.RELATIONSHIP: "ğŸ”— å…³ç³»",
            FactType.LOCATION: "ğŸ“ åœºæ™¯",
            FactType.PROP: "ğŸ­ é“å…·",
            FactType.EVENT: "âš¡ äº‹ä»¶",
            FactType.DEATH: "ğŸ’€ æ­»äº¡",
            FactType.BIRTH: "ğŸ‘¶ å‡ºç”Ÿ",
            FactType.ABILITY: "âœ¨ èƒ½åŠ›",
            FactType.BACKGROUND: "ğŸ“œ èƒŒæ™¯",
            FactType.CONSTRAINT: "âš ï¸ çº¦æŸ",
        }

        for fact_type, type_facts in grouped.items():
            type_name = type_names.get(fact_type, fact_type.value)
            lines.append(f"{type_name}:")
            for fact in type_facts:
                lines.append(f"  â€¢ {fact.content}")
            lines.append("")

        return "\n".join(lines)

    def _generate_summary(self, facts: List[StoryFact]) -> str:
        """ç”Ÿæˆäº‹å®æ‘˜è¦"""
        if not facts:
            return "æœªæå–åˆ°äº‹å®"

        type_counts: Dict[FactType, int] = {}
        for fact in facts:
            type_counts[fact.fact_type] = type_counts.get(fact.fact_type, 0) + 1

        summary_parts = []
        for fact_type, count in type_counts.items():
            summary_parts.append(f"{fact_type.value}:{count}")

        return f"æå–åˆ° {len(facts)} ä¸ªäº‹å® ({', '.join(summary_parts)})"

    async def clear_facts(self, session_id: str) -> bool:
        """
        æ¸…é™¤ä¼šè¯çš„æ‰€æœ‰äº‹å®

        Args:
            session_id: ä¼šè¯ ID

        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        self._ensure_redis()

        key = self._get_redis_key(session_id)

        try:
            if isinstance(self._redis, dict):
                if key in self._redis:
                    del self._redis[key]
            else:
                self._redis.delete(key)

            self.logger.debug(f"æ¸…é™¤äº‹å®: {key}")
            return True

        except Exception as e:
            self.logger.error(f"æ¸…é™¤äº‹å®å¤±è´¥: {e}")
            return False


# å…¨å±€å®ä¾‹
_story_fact_manager: Optional[StoryFactManager] = None


def get_story_fact_manager() -> StoryFactManager:
    """è·å–æ•…äº‹äº‹å®ç®¡ç†å™¨å•ä¾‹"""
    global _story_fact_manager
    if _story_fact_manager is None:
        _story_fact_manager = StoryFactManager()
    return _story_fact_manager


# ä¾¿æ·å‡½æ•°
async def extract_and_save_facts(
    session_id: str,
    text: str,
    scene_title: str = "",
    model_name: str = "glm-4-flash"
) -> FactExtractionResult:
    """
    ä»å‰§æœ¬ç‰‡æ®µä¸­æå–å¹¶ä¿å­˜äº‹å®

    Args:
        session_id: ä¼šè¯ ID
        text: å‰§æœ¬æ–‡æœ¬
        scene_title: åœºæ™¯æ ‡é¢˜
        model_name: æ¨¡å‹åç§°

    Returns:
        FactExtractionResult: æå–ç»“æœ
    """
    manager = get_story_fact_manager()
    return await manager.extract_and_save_facts(session_id, text, scene_title, model_name)


async def get_facts(session_id: str) -> List[StoryFact]:
    """è·å–ä¼šè¯çš„äº‹å®åˆ—è¡¨"""
    manager = get_story_fact_manager()
    return await manager.get_facts(session_id)


async def generate_constraints_prompt(session_id: str, max_facts: int = 20) -> str:
    """ç”Ÿæˆäº‹å®çº¦æŸæ–‡æœ¬"""
    manager = get_story_fact_manager()
    return await manager.generate_constraints_prompt(session_id, max_facts)
