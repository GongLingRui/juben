"""
Agentè¾“å‡ºå†…å®¹å­˜å‚¨ç®¡ç†å™¨
æ”¯æŒæŒ‰æ ‡ç­¾åˆ†ç±»ä¿å­˜å„ä¸ªagentçš„è¾“å‡ºå†…å®¹åˆ°æ–‡ä»¶ç³»ç»Ÿ

æ ‡ç­¾åˆ†ç±»ï¼š
- çŸ­å‰§ç­–åˆ’ (drama_planning)
- çŸ­å‰§åˆ›ä½œ (drama_creation) 
- çŸ­å‰§è¯„ä¼° (drama_evaluation)
- å°è¯´åˆç­›è¯„ä¼° (novel_screening)
- æ•…äº‹åˆ†æ (story_analysis)
- è§’è‰²å¼€å‘ (character_development)
- æƒ…èŠ‚å¼€å‘ (plot_development)
- å‰§é›†åˆ†æ (series_analysis)
"""
import os
import json
import asyncio
from typing import Dict, Any, List, Optional, Union
from datetime import datetime
from pathlib import Path
import uuid
import hashlib

from .logger import JubenLogger
from .agent_naming import canonical_agent_id
from .storage_manager import get_storage


class AgentOutputStorage:
    """Agentè¾“å‡ºå†…å®¹å­˜å‚¨ç®¡ç†å™¨"""
    
    def __init__(self, base_storage_path: str = "juben_outputs"):
        """åˆå§‹åŒ–å­˜å‚¨ç®¡ç†å™¨"""
        self.logger = JubenLogger("agent_output_storage")
        self.base_storage_path = Path(base_storage_path)
        self.storage_manager = get_storage()
        
        # æ ‡ç­¾åˆ†ç±»é…ç½®
        self.output_tags = {
            "drama_planning": {
                "name": "çŸ­å‰§ç­–åˆ’",
                "description": "çŸ­å‰§ç­–åˆ’ç›¸å…³çš„è¾“å‡ºå†…å®¹",
                "agents": ["juben_orchestrator", "juben_concierge", "short_drama_planner_agent", "short_drama_planner"]
            },
            "drama_creation": {
                "name": "çŸ­å‰§åˆ›ä½œ", 
                "description": "çŸ­å‰§åˆ›ä½œç›¸å…³çš„è¾“å‡ºå†…å®¹",
                "agents": ["short_drama_creator_agent", "short_drama_creator", "story_outline_evaluation_agent", "character_profile_agent"]
            },
            "drama_evaluation": {
                "name": "çŸ­å‰§è¯„ä¼°",
                "description": "çŸ­å‰§è¯„ä¼°ç›¸å…³çš„è¾“å‡ºå†…å®¹", 
                "agents": ["short_drama_evaluation_agent", "short_drama_evaluation", "script_evaluation_agent", "drama_analysis_agent"]
            },
            "novel_screening": {
                "name": "å°è¯´åˆç­›è¯„ä¼°",
                "description": "å°è¯´åˆç­›è¯„ä¼°ç›¸å…³çš„è¾“å‡ºå†…å®¹",
                "agents": ["novel_screening_evaluation_agent", "ip_evaluation_agent", "ip_evaluation"]
            },
            "story_analysis": {
                "name": "æ•…äº‹åˆ†æ",
                "description": "æ•…äº‹åˆ†æç›¸å…³çš„è¾“å‡ºå†…å®¹",
                "agents": ["story_five_elements_agent", "story_five_elements", "story_outline_evaluation_agent", "story_evaluation_agent"]
            },
            "character_development": {
                "name": "è§’è‰²å¼€å‘",
                "description": "è§’è‰²å¼€å‘ç›¸å…³çš„è¾“å‡ºå†…å®¹",
                "agents": ["character_profile_agent", "character_relationship_agent", "character_profile_generator_agent"]
            },
            "plot_development": {
                "name": "æƒ…èŠ‚å¼€å‘", 
                "description": "æƒ…èŠ‚å¼€å‘ç›¸å…³çš„è¾“å‡ºå†…å®¹",
                "agents": ["plot_points_agent", "major_plot_points_agent", "detailed_plot_points_agent", "plot_points_workflow"]
            },
            "series_analysis": {
                "name": "å‰§é›†åˆ†æ",
                "description": "å‰§é›†åˆ†æç›¸å…³çš„è¾“å‡ºå†…å®¹",
                "agents": ["series_analysis_agent", "series_info_agent", "series_name_extractor_agent"]
            }
        }
        
        # æ–‡ä»¶ç±»å‹é…ç½®
        self.file_types = {
            "json": {"extension": ".json", "content_type": "application/json"},
            "markdown": {"extension": ".md", "content_type": "text/markdown"},
            "text": {"extension": ".txt", "content_type": "text/plain"},
            "html": {"extension": ".html", "content_type": "text/html"},
            "xml": {"extension": ".xml", "content_type": "application/xml"}
        }
        
        # åˆå§‹åŒ–å­˜å‚¨ç›®å½•
        self._init_storage_directories()
        
        self.logger.info("ğŸ“ Agentè¾“å‡ºå­˜å‚¨ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        self.logger.info(f"ğŸ“‚ åŸºç¡€å­˜å‚¨è·¯å¾„: {self.base_storage_path}")
        self.logger.info(f"ğŸ·ï¸ æ”¯æŒçš„æ ‡ç­¾: {list(self.output_tags.keys())}")
    
    def _init_storage_directories(self):
        """åˆå§‹åŒ–å­˜å‚¨ç›®å½•ç»“æ„"""
        try:
            # åˆ›å»ºåŸºç¡€ç›®å½•
            self.base_storage_path.mkdir(parents=True, exist_ok=True)
            
            # ä¸ºæ¯ä¸ªæ ‡ç­¾åˆ›å»ºç›®å½•
            for tag in self.output_tags.keys():
                tag_dir = self.base_storage_path / tag
                tag_dir.mkdir(parents=True, exist_ok=True)
                
                # åˆ›å»ºå­ç›®å½•
                subdirs = ["raw_outputs", "processed_outputs", "metadata", "exports"]
                for subdir in subdirs:
                    (tag_dir / subdir).mkdir(exist_ok=True)
            
            # åˆ›å»ºé€šç”¨ç›®å½•
            common_dirs = ["temp", "backup", "logs", "exports"]
            for dir_name in common_dirs:
                (self.base_storage_path / dir_name).mkdir(exist_ok=True)
            
            self.logger.info("ğŸ“ å­˜å‚¨ç›®å½•ç»“æ„åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            self.logger.error(f"âŒ åˆå§‹åŒ–å­˜å‚¨ç›®å½•å¤±è´¥: {e}")
            raise
    
    async def save_agent_output(
        self,
        agent_name: str,
        output_content: Union[str, Dict[str, Any]],
        output_tag: str,
        user_id: str,
        session_id: str,
        file_type: str = "json",
        metadata: Optional[Dict[str, Any]] = None,
        auto_export: bool = True
    ) -> Dict[str, Any]:
        """
        ä¿å­˜Agentè¾“å‡ºå†…å®¹
        
        Args:
            agent_name: Agentåç§°
            output_content: è¾“å‡ºå†…å®¹
            output_tag: è¾“å‡ºæ ‡ç­¾
            user_id: ç”¨æˆ·ID
            session_id: ä¼šè¯ID
            file_type: æ–‡ä»¶ç±»å‹
            metadata: å…ƒæ•°æ®
            auto_export: æ˜¯å¦è‡ªåŠ¨å¯¼å‡º
            
        Returns:
            Dict: ä¿å­˜ç»“æœä¿¡æ¯
        """
        try:
            # éªŒè¯æ ‡ç­¾
            if output_tag not in self.output_tags:
                raise ValueError(f"ä¸æ”¯æŒçš„è¾“å‡ºæ ‡ç­¾: {output_tag}")
            
            # éªŒè¯æ–‡ä»¶ç±»å‹
            if file_type not in self.file_types:
                raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_type}")
            
            # ç”Ÿæˆæ–‡ä»¶ä¿¡æ¯
            file_info = self._generate_file_info(
                agent_name, output_tag, user_id, session_id, file_type
            )
            
            # å¤„ç†è¾“å‡ºå†…å®¹
            processed_content = self._process_output_content(output_content, file_type)
            
            # ä¿å­˜åˆ°æ–‡ä»¶ç³»ç»Ÿ
            file_path = await self._save_to_filesystem(
                file_info, processed_content, output_tag, file_type
            )
            
            # ä¿å­˜å…ƒæ•°æ®
            metadata_info = await self._save_metadata(
                file_info, metadata, output_tag, user_id, session_id
            )
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            db_record = await self._save_to_database(
                file_info, output_tag, user_id, session_id, file_path, metadata_info
            )
            
            # è‡ªåŠ¨å¯¼å‡º
            export_info = None
            if auto_export:
                export_info = await self._auto_export_output(
                    file_info, output_tag, file_type, user_id, session_id
                )
            
            result = {
                "success": True,
                "file_info": file_info,
                "file_path": str(file_path),
                "metadata_info": metadata_info,
                "db_record": db_record,
                "export_info": export_info,
                "timestamp": datetime.now().isoformat()
            }
            
            self.logger.info(f"ğŸ’¾ ä¿å­˜Agentè¾“å‡ºæˆåŠŸ: {agent_name} -> {output_tag}")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜Agentè¾“å‡ºå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    def _generate_file_info(
        self, 
        agent_name: str, 
        output_tag: str, 
        user_id: str, 
        session_id: str, 
        file_type: str
    ) -> Dict[str, Any]:
        """ç”Ÿæˆæ–‡ä»¶ä¿¡æ¯"""
        timestamp = datetime.now()
        file_id = str(uuid.uuid4())
        
        # ç”Ÿæˆæ–‡ä»¶å
        safe_agent_name = self._sanitize_filename(agent_name)
        safe_user_id = self._sanitize_filename(user_id)
        date_str = timestamp.strftime("%Y%m%d_%H%M%S")
        
        filename = f"{safe_agent_name}_{safe_user_id}_{date_str}_{file_id[:8]}"
        filename += self.file_types[file_type]["extension"]
        
        return {
            "file_id": file_id,
            "filename": filename,
            "agent_name": agent_name,
            "output_tag": output_tag,
            "user_id": user_id,
            "session_id": session_id,
            "file_type": file_type,
            "timestamp": timestamp.isoformat(),
            "date_str": date_str
        }
    
    def _process_output_content(
        self, 
        content: Union[str, Dict[str, Any]], 
        file_type: str
    ) -> str:
        """å¤„ç†è¾“å‡ºå†…å®¹"""
        if file_type == "json":
            if isinstance(content, dict):
                return json.dumps(content, ensure_ascii=False, indent=2)
            else:
                try:
                    # å°è¯•è§£æä¸ºJSON
                    parsed = json.loads(content)
                    return json.dumps(parsed, ensure_ascii=False, indent=2)
                except:
                    return content
        elif file_type == "markdown":
            if isinstance(content, dict):
                return self._dict_to_markdown(content)
            else:
                return str(content)
        else:
            return str(content)
    
    def _dict_to_markdown(self, data: Dict[str, Any], level: int = 0) -> str:
        """å°†å­—å…¸è½¬æ¢ä¸ºMarkdownæ ¼å¼"""
        markdown = ""
        indent = "  " * level
        
        for key, value in data.items():
            if isinstance(value, dict):
                markdown += f"{indent}## {key}\n\n"
                markdown += self._dict_to_markdown(value, level + 1)
            elif isinstance(value, list):
                markdown += f"{indent}### {key}\n\n"
                for i, item in enumerate(value):
                    if isinstance(item, dict):
                        markdown += f"{indent}{i+1}. "
                        markdown += self._dict_to_markdown(item, level + 1)
                    else:
                        markdown += f"{indent}{i+1}. {item}\n"
                markdown += "\n"
            else:
                markdown += f"{indent}**{key}**: {value}\n\n"
        
        return markdown
    
    def _sanitize_filename(self, filename: str) -> str:
        """æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤ä¸å®‰å…¨å­—ç¬¦"""
        import re
        # ç§»é™¤æˆ–æ›¿æ¢ä¸å®‰å…¨å­—ç¬¦
        safe_filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
        safe_filename = re.sub(r'\s+', '_', safe_filename)
        return safe_filename[:50]  # é™åˆ¶é•¿åº¦
    
    async def _save_to_filesystem(
        self, 
        file_info: Dict[str, Any], 
        content: str, 
        output_tag: str, 
        file_type: str
    ) -> Path:
        """ä¿å­˜åˆ°æ–‡ä»¶ç³»ç»Ÿ"""
        try:
            # ç¡®å®šå­˜å‚¨è·¯å¾„
            tag_dir = self.base_storage_path / output_tag / "raw_outputs"
            file_path = tag_dir / file_info["filename"]
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            file_path.parent.mkdir(parents=True, exist_ok=True)
            
            # å†™å…¥æ–‡ä»¶
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            self.logger.info(f"ğŸ“ æ–‡ä»¶ä¿å­˜æˆåŠŸ: {file_path}")
            return file_path
            
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜åˆ°æ–‡ä»¶ç³»ç»Ÿå¤±è´¥: {e}")
            raise
    
    async def _save_metadata(
        self, 
        file_info: Dict[str, Any], 
        metadata: Optional[Dict[str, Any]], 
        output_tag: str, 
        user_id: str, 
        session_id: str
    ) -> Dict[str, Any]:
        """ä¿å­˜å…ƒæ•°æ®"""
        try:
            metadata_info = {
                "file_id": file_info["file_id"],
                "agent_name": file_info["agent_name"],
                "output_tag": output_tag,
                "user_id": user_id,
                "session_id": session_id,
                "timestamp": file_info["timestamp"],
                "file_type": file_info["file_type"],
                "custom_metadata": metadata or {},
                "tag_info": self.output_tags[output_tag]
            }
            
            # ä¿å­˜å…ƒæ•°æ®åˆ°æ–‡ä»¶
            metadata_dir = self.base_storage_path / output_tag / "metadata"
            metadata_file = metadata_dir / f"{file_info['file_id']}.json"
            
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata_info, f, ensure_ascii=False, indent=2)
            
            return metadata_info
            
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜å…ƒæ•°æ®å¤±è´¥: {e}")
            return {}
    
    async def _save_to_database(
        self, 
        file_info: Dict[str, Any], 
        output_tag: str, 
        user_id: str, 
        session_id: str, 
        file_path: Path, 
        metadata_info: Dict[str, Any]
    ) -> Optional[str]:
        """ä¿å­˜åˆ°æ•°æ®åº“"""
        try:
            # æ„å»ºæ•°æ®åº“è®°å½•
            db_record = {
                "file_id": file_info["file_id"],
                "agent_name": file_info["agent_name"],
                "output_tag": output_tag,
                "user_id": user_id,
                "session_id": session_id,
                "file_path": str(file_path),
                "file_type": file_info["file_type"],
                "file_size": file_path.stat().st_size if file_path.exists() else 0,
                "metadata": metadata_info,
                "created_at": file_info["timestamp"]
            }
            
            # ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆè¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„æ•°æ®åº“å®ç°è°ƒæ•´ï¼‰
            # å‡è®¾ä½¿ç”¨å­˜å‚¨ç®¡ç†å™¨çš„save_stream_eventæ–¹æ³•
            event_id = await self.storage_manager.save_stream_event(
                user_id=user_id,
                session_id=session_id,
                event_type="agent_output_saved",
                content_type=file_info["file_type"],
                agent_source=file_info["agent_name"],
                event_data=db_record,
                event_metadata={
                    "output_tag": output_tag,
                    "file_id": file_info["file_id"],
                    "file_path": str(file_path)
                }
            )
            
            return event_id
            
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜åˆ°æ•°æ®åº“å¤±è´¥: {e}")
            return None
    
    async def _auto_export_output(
        self, 
        file_info: Dict[str, Any], 
        output_tag: str, 
        file_type: str, 
        user_id: str, 
        session_id: str
    ) -> Optional[Dict[str, Any]]:
        """è‡ªåŠ¨å¯¼å‡ºè¾“å‡º"""
        try:
            # æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©å¯¼å‡ºæ ¼å¼
            export_formats = []
            
            if file_type == "json":
                export_formats = ["markdown", "html"]
            elif file_type == "markdown":
                export_formats = ["html", "pdf"]
            elif file_type == "text":
                export_formats = ["markdown", "html"]
            
            export_results = []
            for export_format in export_formats:
                try:
                    export_result = await self._export_to_format(
                        file_info, output_tag, export_format, user_id, session_id
                    )
                    if export_result:
                        export_results.append(export_result)
                except Exception as e:
                    self.logger.warning(f"âš ï¸ å¯¼å‡ºæ ¼å¼ {export_format} å¤±è´¥: {e}")
            
            return {
                "export_formats": export_formats,
                "export_results": export_results,
                "success": len(export_results) > 0
            }
            
        except Exception as e:
            self.logger.error(f"âŒ è‡ªåŠ¨å¯¼å‡ºå¤±è´¥: {e}")
            return None
    
    async def _export_to_format(
        self, 
        file_info: Dict[str, Any], 
        output_tag: str, 
        export_format: str, 
        user_id: str, 
        session_id: str
    ) -> Optional[Dict[str, Any]]:
        """å¯¼å‡ºåˆ°æŒ‡å®šæ ¼å¼"""
        try:
            # è¯»å–åŸå§‹æ–‡ä»¶
            raw_file_path = self.base_storage_path / output_tag / "raw_outputs" / file_info["filename"]
            if not raw_file_path.exists():
                return None
            
            with open(raw_file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æ ¹æ®å¯¼å‡ºæ ¼å¼å¤„ç†å†…å®¹
            if export_format == "markdown":
                if file_info["file_type"] == "json":
                    # JSONè½¬Markdown
                    data = json.loads(content)
                    processed_content = self._dict_to_markdown(data)
                else:
                    processed_content = content
            elif export_format == "html":
                if file_info["file_type"] == "json":
                    # JSONè½¬HTML
                    data = json.loads(content)
                    processed_content = self._dict_to_html(data)
                elif file_info["file_type"] == "markdown":
                    # Markdownè½¬HTML
                    processed_content = self._markdown_to_html(content)
                else:
                    processed_content = f"<pre>{content}</pre>"
            else:
                processed_content = content
            
            # ä¿å­˜å¯¼å‡ºæ–‡ä»¶
            export_dir = self.base_storage_path / output_tag / "exports"
            export_filename = file_info["filename"].replace(
                self.file_types[file_info["file_type"]]["extension"],
                self.file_types.get(export_format, {"extension": f".{export_format}"})["extension"]
            )
            export_path = export_dir / export_filename
            
            with open(export_path, 'w', encoding='utf-8') as f:
                f.write(processed_content)
            
            return {
                "export_format": export_format,
                "export_path": str(export_path),
                "file_size": export_path.stat().st_size
            }
            
        except Exception as e:
            self.logger.error(f"âŒ å¯¼å‡ºåˆ° {export_format} å¤±è´¥: {e}")
            return None
    
    def _dict_to_html(self, data: Dict[str, Any], level: int = 0) -> str:
        """å°†å­—å…¸è½¬æ¢ä¸ºHTMLæ ¼å¼"""
        html = "<div class='agent-output'>\n"
        html += self._dict_to_html_recursive(data, level)
        html += "</div>\n"
        return html
    
    def _dict_to_html_recursive(self, data: Dict[str, Any], level: int = 0) -> str:
        """é€’å½’è½¬æ¢å­—å…¸ä¸ºHTML"""
        html = ""
        indent = "  " * level
        
        for key, value in data.items():
            if isinstance(value, dict):
                html += f"{indent}<div class='section'>\n"
                html += f"{indent}  <h{min(level+2, 6)}>{key}</h{min(level+2, 6)}>\n"
                html += self._dict_to_html_recursive(value, level + 1)
                html += f"{indent}</div>\n"
            elif isinstance(value, list):
                html += f"{indent}<div class='list-section'>\n"
                html += f"{indent}  <h{min(level+2, 6)}>{key}</h{min(level+2, 6)}>\n"
                html += f"{indent}  <ul>\n"
                for item in value:
                    if isinstance(item, dict):
                        html += f"{indent}    <li>\n"
                        html += self._dict_to_html_recursive(item, level + 2)
                        html += f"{indent}    </li>\n"
                    else:
                        html += f"{indent}    <li>{item}</li>\n"
                html += f"{indent}  </ul>\n"
                html += f"{indent}</div>\n"
            else:
                html += f"{indent}<div class='field'>\n"
                html += f"{indent}  <strong>{key}:</strong> {value}\n"
                html += f"{indent}</div>\n"
        
        return html
    
    def _markdown_to_html(self, markdown: str) -> str:
        """ç®€å•çš„Markdownè½¬HTML"""
        # è¿™é‡Œå¯ä»¥å®ç°æ›´å¤æ‚çš„Markdownè§£æ
        # ç›®å‰ä½¿ç”¨ç®€å•çš„æ–‡æœ¬æ›¿æ¢
        html = markdown
        html = html.replace('\n## ', '\n<h2>').replace('\n### ', '\n<h3>')
        html = html.replace('\n**', '\n<strong>').replace('**', '</strong>')
        html = html.replace('\n*', '\n<em>').replace('*', '</em>')
        html = html.replace('\n', '<br>\n')
        return f"<div class='markdown-content'>{html}</div>"
    
    async def get_agent_outputs(
        self, 
        output_tag: str, 
        user_id: Optional[str] = None, 
        session_id: Optional[str] = None,
        agent_name: Optional[str] = None,
        limit: int = 50
    ) -> List[Dict[str, Any]]:
        """è·å–Agentè¾“å‡ºåˆ—è¡¨"""
        try:
            outputs = []
            tag_dir = self.base_storage_path / output_tag / "raw_outputs"
            
            if not tag_dir.exists():
                return outputs
            
            # éå†æ–‡ä»¶
            for file_path in tag_dir.iterdir():
                if file_path.is_file():
                    # è¯»å–å…ƒæ•°æ®
                    metadata_file = self.base_storage_path / output_tag / "metadata" / f"{file_path.stem}.json"
                    if metadata_file.exists():
                        with open(metadata_file, 'r', encoding='utf-8') as f:
                            metadata = json.load(f)
                        
                        # åº”ç”¨è¿‡æ»¤æ¡ä»¶
                        if user_id and metadata.get("user_id") != user_id:
                            continue
                        if session_id and metadata.get("session_id") != session_id:
                            continue
                        if agent_name and metadata.get("agent_name") != agent_name:
                            continue
                        
                        # æ·»åŠ æ–‡ä»¶ä¿¡æ¯
                        metadata["file_path"] = str(file_path)
                        metadata["file_size"] = file_path.stat().st_size
                        metadata["file_exists"] = file_path.exists()
                        
                        outputs.append(metadata)
            
            # æŒ‰æ—¶é—´æ’åº
            outputs.sort(key=lambda x: x.get("timestamp", ""), reverse=True)
            
            return outputs[:limit]
            
        except Exception as e:
            self.logger.error(f"âŒ è·å–Agentè¾“å‡ºå¤±è´¥: {e}")
            return []
    
    async def get_output_content(
        self, 
        file_id: str, 
        output_tag: str
    ) -> Optional[Dict[str, Any]]:
        """è·å–è¾“å‡ºå†…å®¹"""
        try:
            # è¯»å–å…ƒæ•°æ®
            metadata_file = self.base_storage_path / output_tag / "metadata" / f"{file_id}.json"
            if not metadata_file.exists():
                return None
            
            with open(metadata_file, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            # è¯»å–æ–‡ä»¶å†…å®¹
            file_path = self.base_storage_path / output_tag / "raw_outputs" / metadata["filename"]
            if not file_path.exists():
                return None
            
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            return {
                "metadata": metadata,
                "content": content,
                "file_path": str(file_path)
            }
            
        except Exception as e:
            self.logger.error(f"âŒ è·å–è¾“å‡ºå†…å®¹å¤±è´¥: {e}")
            return None
    
    async def cleanup_old_outputs(self, days: int = 30) -> Dict[str, Any]:
        """æ¸…ç†æ—§è¾“å‡ºæ–‡ä»¶"""
        try:
            from datetime import timedelta
            
            cutoff_date = datetime.now() - timedelta(days=days)
            cleaned_files = []
            cleaned_size = 0
            
            for output_tag in self.output_tags.keys():
                tag_dir = self.base_storage_path / output_tag
                
                # æ¸…ç†åŸå§‹è¾“å‡º
                raw_dir = tag_dir / "raw_outputs"
                if raw_dir.exists():
                    for file_path in raw_dir.iterdir():
                        if file_path.is_file():
                            file_time = datetime.fromtimestamp(file_path.stat().st_mtime)
                            if file_time < cutoff_date:
                                file_size = file_path.stat().st_size
                                file_path.unlink()
                                cleaned_files.append(str(file_path))
                                cleaned_size += file_size
                
                # æ¸…ç†å…ƒæ•°æ®
                metadata_dir = tag_dir / "metadata"
                if metadata_dir.exists():
                    for file_path in metadata_dir.iterdir():
                        if file_path.is_file():
                            file_time = datetime.fromtimestamp(file_path.stat().st_mtime)
                            if file_time < cutoff_date:
                                file_path.unlink()
            
            result = {
                "success": True,
                "cleaned_files": len(cleaned_files),
                "cleaned_size": cleaned_size,
                "cutoff_date": cutoff_date.isoformat()
            }
            
            self.logger.info(f"ğŸ§¹ æ¸…ç†å®Œæˆ: {len(cleaned_files)} ä¸ªæ–‡ä»¶, {cleaned_size} å­—èŠ‚")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ æ¸…ç†æ—§æ–‡ä»¶å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}
    
    def get_storage_stats(self) -> Dict[str, Any]:
        """è·å–å­˜å‚¨ç»Ÿè®¡ä¿¡æ¯"""
        try:
            stats = {
                "total_tags": len(self.output_tags),
                "tag_stats": {},
                "total_size": 0,
                "total_files": 0
            }
            
            for output_tag in self.output_tags.keys():
                tag_dir = self.base_storage_path / output_tag
                tag_stats = {
                    "raw_outputs": 0,
                    "metadata": 0,
                    "exports": 0,
                    "size": 0
                }
                
                # ç»Ÿè®¡åŸå§‹è¾“å‡º
                raw_dir = tag_dir / "raw_outputs"
                if raw_dir.exists():
                    for file_path in raw_dir.iterdir():
                        if file_path.is_file():
                            tag_stats["raw_outputs"] += 1
                            tag_stats["size"] += file_path.stat().st_size
                
                # ç»Ÿè®¡å…ƒæ•°æ®
                metadata_dir = tag_dir / "metadata"
                if metadata_dir.exists():
                    for file_path in metadata_dir.iterdir():
                        if file_path.is_file():
                            tag_stats["metadata"] += 1
                
                # ç»Ÿè®¡å¯¼å‡ºæ–‡ä»¶
                exports_dir = tag_dir / "exports"
                if exports_dir.exists():
                    for file_path in exports_dir.iterdir():
                        if file_path.is_file():
                            tag_stats["exports"] += 1
                
                stats["tag_stats"][output_tag] = tag_stats
                stats["total_size"] += tag_stats["size"]
                stats["total_files"] += tag_stats["raw_outputs"]

            return stats

        except Exception as e:
            self.logger.error(f"âŒ è·å–å­˜å‚¨ç»Ÿè®¡å¤±è´¥: {e}")
            return {"error": str(e)}


# å…¨å±€å­˜å‚¨ç®¡ç†å™¨å®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
agent_output_storage = None


def get_agent_output_storage() -> AgentOutputStorage:
    """è·å–Agentè¾“å‡ºå­˜å‚¨ç®¡ç†å™¨å®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰"""
    global agent_output_storage
    if agent_output_storage is None:
        agent_output_storage = AgentOutputStorage()
    return agent_output_storage
