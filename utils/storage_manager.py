"""
Jubené¡¹ç›®å­˜å‚¨ç®¡ç†å™¨
åŸºäºä¸‰å±‚å­˜å‚¨æ¶æ„ï¼šå†…å­˜ -> Redis -> PostgreSQL
"""
import asyncio
import json
import uuid
from typing import Optional, Dict, Any, List
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict
from utils.logger import JubenLogger
from utils.database_client import (
    DatabaseErrorHandler,
    test_connection,
    fetch_one,
    fetch_all,
    execute,
)
from utils.redis_client import JubenRedisClient, get_redis_client, test_redis_connection


@dataclass
class ChatMessage:
    """èŠå¤©æ¶ˆæ¯æ•°æ®ç»“æ„"""
    id: Optional[str] = None
    user_id: str = ""
    session_id: str = ""
    message_type: str = ""  # user, assistant, system, error
    content: str = ""
    agent_name: Optional[str] = None
    message_metadata: Dict[str, Any] = None
    created_at: str = ""
    
    def __post_init__(self):
        if self.message_metadata is None:
            self.message_metadata = {}
        if not self.created_at:
            self.created_at = datetime.now().isoformat()


@dataclass
class ContextState:
    """ä¸Šä¸‹æ–‡çŠ¶æ€æ•°æ®ç»“æ„ï¼ˆå¢å¼ºç‰ˆï¼‰"""
    user_id: str = ""
    session_id: str = ""
    agent_name: str = ""
    context_data: Dict[str, Any] = None
    context_type: str = "general"  # general, workflow, multimodal, analysis
    context_version: int = 1  # ä¸Šä¸‹æ–‡ç‰ˆæœ¬å·
    is_active: bool = True  # æ˜¯å¦ä¸ºæ´»è·ƒä¸Šä¸‹æ–‡
    created_at: str = ""
    updated_at: str = ""
    expires_at: Optional[str] = None  # è¿‡æœŸæ—¶é—´
    
    def __post_init__(self):
        if self.context_data is None:
            self.context_data = {}
        if not self.created_at:
            self.created_at = datetime.now().isoformat()
        self.updated_at = datetime.now().isoformat()


@dataclass
class ConversationContext:
    """å¯¹è¯ä¸Šä¸‹æ–‡æ•°æ®ç»“æ„ï¼ˆ ï¼‰"""
    session_id: str
    user_id: str
    thread_id: str
    
    # å¤šè½®å¯¹è¯æ ¸å¿ƒç»„ä»¶
    user_message_queue: List[Dict[str, Any]]  # ç”¨æˆ·æ¶ˆæ¯é˜Ÿåˆ—
    orchestrator_calls: List[Dict[str, Any]]  # orchestratorè°ƒç”¨è®°å½•
    created_notes: List[Dict[str, Any]]  # åˆ›å»ºçš„notes
    
    # ä¸Šä¸‹æ–‡ç®¡ç†
    global_context: Dict[str, Any]  # å…¨å±€ä¸Šä¸‹æ–‡
    agent_contexts: Dict[str, Any]  # å„agentçš„ä¸Šä¸‹æ–‡
    shared_memory: Dict[str, Any]   # å…±äº«å†…å­˜
    conversation_history: List[Dict[str, Any]]  # å¯¹è¯å†å²
    
    # å‹ç¼©å’Œä¼˜åŒ–
    compression_history: List[Dict[str, Any]]  # å‹ç¼©å†å²
    context_summary: Optional[str] = None  # ä¸Šä¸‹æ–‡æ‘˜è¦
    is_compressed: bool = False  # æ˜¯å¦å·²å‹ç¼©
    
    created_at: str = ""
    updated_at: str = ""
    
    def __post_init__(self):
        if not self.created_at:
            self.created_at = datetime.now().isoformat()
        self.updated_at = datetime.now().isoformat()


@dataclass
class Note:
    """Noteæ•°æ®ç»“æ„"""
    id: Optional[str] = None
    user_id: str = ""
    session_id: str = ""
    action: str = ""
    name: str = ""
    title: Optional[str] = None
    cover_title: Optional[str] = None
    content_type: Optional[str] = None
    context: str = ""
    select_status: int = 0
    user_comment: Optional[str] = None
    metadata: Dict[str, Any] = None
    created_at: str = ""
    updated_at: str = ""
    
    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}
        if not self.created_at:
            self.created_at = datetime.now().isoformat()
        self.updated_at = datetime.now().isoformat()


@dataclass
class TokenUsage:
    """Tokenä½¿ç”¨è®°å½•æ•°æ®ç»“æ„"""
    id: Optional[str] = None
    user_id: str = ""
    session_id: str = ""
    agent_name: str = ""
    model_provider: str = ""
    model_name: str = ""
    request_tokens: int = 0
    response_tokens: int = 0
    total_tokens: int = 0
    cost_points: float = 0.0
    request_timestamp: str = ""
    billing_summary: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.billing_summary is None:
            self.billing_summary = {}
        if not self.request_timestamp:
            self.request_timestamp = datetime.now().isoformat()


class JubenStorageManager:
    """Jubené¡¹ç›®å­˜å‚¨ç®¡ç†å™¨ï¼ˆå¢å¼ºç‰ˆï¼‰"""
    
    def __init__(self):
        self.logger = JubenLogger("storage_manager")
        self.redis_client: Optional[JubenRedisClient] = None
        self.db_ready = False
        self.error_handler = DatabaseErrorHandler("storage_manager")
        
        # ç¼“å­˜é…ç½®
        self.cache_ttl = {
            'session': 3600 * 24 * 3,  # 3å¤©
            'context': 3600 * 24,      # 1å¤©
            'messages': 3600 * 12,     # 12å°æ—¶
            'notes': 3600 * 24,        # 1å¤©
            'token_usage': 3600 * 6,   # 6å°æ—¶
            'conversation': 3600 * 24 * 7  # 7å¤©
        }
        
        # å¤šè½®å¯¹è¯é…ç½®
        self.conversation_config = {
            'max_context_length': 8000,  # æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦
            'compression_threshold': 0.8,  # å‹ç¼©é˜ˆå€¼
            'max_messages_per_session': 1000,  # æ¯ä¼šè¯æœ€å¤§æ¶ˆæ¯æ•°
            'context_compression_enabled': True,  # å¯ç”¨ä¸Šä¸‹æ–‡å‹ç¼©
            'auto_summary_enabled': True  # å¯ç”¨è‡ªåŠ¨æ‘˜è¦
        }
        
        self._initialized = False
    
    async def initialize(self):
        """åˆå§‹åŒ–å­˜å‚¨ç®¡ç†å™¨"""
        try:
            self.logger.info("ğŸš€ å¼€å§‹åˆå§‹åŒ–Jubenå­˜å‚¨ç®¡ç†å™¨...")
            
            # åˆå§‹åŒ–Rediså®¢æˆ·ç«¯
            self.redis_client = await get_redis_client('high_priority')
            if self.redis_client:
                self.logger.info("âœ… Rediså®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            else:
                self.logger.warning("âš ï¸ Rediså®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨å†…å­˜æ¨¡å¼")
            
            # æµ‹è¯•è¿æ¥
            redis_ok = await test_redis_connection()
            db_ok = await test_connection()
            
            self.logger.info(f"ğŸ“Š å­˜å‚¨å±‚çŠ¶æ€:")
            self.logger.info(f"  - Redis: {'âœ… æ­£å¸¸' if redis_ok else 'âŒ å¼‚å¸¸'}")
            self.logger.info(f"  - PostgreSQL: {'âœ… æ­£å¸¸' if db_ok else 'âŒ å¼‚å¸¸'}")
            self.db_ready = db_ok
            
            self._initialized = True
            self.logger.info("âœ… Jubenå­˜å‚¨ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            self.logger.error(f"âŒ Jubenå­˜å‚¨ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self._initialized = False
            raise
    
    def ensure_initialized(self):
        """ç¡®ä¿æŒå‚¨ç®¡ç†å™¨å·²åˆå§‹åŒ–"""
        if not self._initialized:
            self.logger.info("ğŸ”„ å­˜å‚¨ç®¡ç†å™¨æœªåˆå§‹åŒ–ï¼Œå¼€å§‹åˆå§‹åŒ–...")
            asyncio.create_task(self.initialize())
    
    # ==================== ç”¨æˆ·ä¼šè¯ç®¡ç† ====================
    
    async def create_user_session(self, user_id: str, session_id: str, metadata: Dict[str, Any] = None) -> bool:
        """åˆ›å»ºç”¨æˆ·ä¼šè¯"""
        try:
            session_data = {
                'user_id': user_id,
                'session_id': session_id,
                'status': 'active',
                'metadata': metadata or {},
                'created_at': datetime.now().isoformat(),
                'updated_at': datetime.now().isoformat(),
                'last_activity_at': datetime.now().isoformat()
            }
            
            # 1. ä¿å­˜åˆ°PostgreSQL
            async def _save_to_db():
                sql = """
                INSERT INTO user_sessions (
                    user_id, session_id, status, metadata, created_at, updated_at, last_activity_at
                ) VALUES ($1, $2, $3, $4, $5, $6, $7)
                ON CONFLICT (user_id, session_id)
                DO UPDATE SET
                    status = EXCLUDED.status,
                    metadata = EXCLUDED.metadata,
                    updated_at = EXCLUDED.updated_at,
                    last_activity_at = EXCLUDED.last_activity_at
                RETURNING user_id
                """
                row = await fetch_one(
                    sql,
                    session_data["user_id"],
                    session_data["session_id"],
                    session_data["status"],
                    session_data["metadata"],
                    session_data["created_at"],
                    session_data["updated_at"],
                    session_data["last_activity_at"],
                )
                return bool(row)
            
            success = await self.error_handler.with_retry(_save_to_db, "åˆ›å»ºç”¨æˆ·ä¼šè¯")
            
            # 2. ç¼“å­˜åˆ°Redis
            if success and self.redis_client:
                cache_key = f"juben:session:{user_id}:{session_id}"
                await self.redis_client.set(cache_key, session_data, expire=self.cache_ttl['session'])
            
            return success
            
        except Exception as e:
            self.logger.error(f"âŒ åˆ›å»ºç”¨æˆ·ä¼šè¯å¤±è´¥: {e}")
            return False
    
    async def get_user_session(self, user_id: str, session_id: str) -> Optional[Dict[str, Any]]:
        """è·å–ç”¨æˆ·ä¼šè¯"""
        try:
            # 1. å°è¯•ä»Redisè·å–
            if self.redis_client:
                cache_key = f"juben:session:{user_id}:{session_id}"
                cached_data = await self.redis_client.get(cache_key)
                if cached_data:
                    return cached_data
            
            # 2. ä»PostgreSQLè·å–
            async def _get_from_db():
                sql = """
                SELECT user_id, session_id, status, metadata, created_at, updated_at, last_activity_at
                FROM user_sessions
                WHERE user_id = $1 AND session_id = $2
                """
                row = await fetch_one(sql, user_id, session_id)
                if row and row.get("metadata"):
                    row["metadata"] = json.loads(row["metadata"]) if isinstance(row["metadata"], str) else row["metadata"]
                return row
            
            session_data = await self.error_handler.with_retry(_get_from_db, "è·å–ç”¨æˆ·ä¼šè¯")
            
            # 3. ç¼“å­˜åˆ°Redis
            if session_data and self.redis_client:
                cache_key = f"juben:session:{user_id}:{session_id}"
                await self.redis_client.set(cache_key, session_data, expire=self.cache_ttl['session'])
            
            return session_data
            
        except Exception as e:
            self.logger.error(f"âŒ è·å–ç”¨æˆ·ä¼šè¯å¤±è´¥: {e}")
            return None
    
    async def update_session_activity(self, user_id: str, session_id: str) -> bool:
        """æ›´æ–°ä¼šè¯æ´»åŠ¨æ—¶é—´"""
        try:
            update_data = {
                'last_activity_at': datetime.now().isoformat(),
                'updated_at': datetime.now().isoformat()
            }
            
            # 1. æ›´æ–°PostgreSQL
            async def _update_db():
                sql = """
                UPDATE user_sessions
                SET last_activity_at = $1, updated_at = $2
                WHERE user_id = $3 AND session_id = $4
                RETURNING user_id
                """
                row = await fetch_one(
                    sql,
                    update_data["last_activity_at"],
                    update_data["updated_at"],
                    user_id,
                    session_id,
                )
                return bool(row)
            
            success = await self.error_handler.with_retry(_update_db, "æ›´æ–°ä¼šè¯æ´»åŠ¨æ—¶é—´")
            
            # 2. æ›´æ–°Redisç¼“å­˜
            if success and self.redis_client:
                cache_key = f"juben:session:{user_id}:{session_id}"
                cached_data = await self.redis_client.get(cache_key)
                if cached_data:
                    cached_data.update(update_data)
                    await self.redis_client.set(cache_key, cached_data, expire=self.cache_ttl['session'])
            
            return success
            
        except Exception as e:
            self.logger.error(f"âŒ æ›´æ–°ä¼šè¯æ´»åŠ¨æ—¶é—´å¤±è´¥: {e}")
            return False
    
    # ==================== å¯¹è¯æ¶ˆæ¯å­˜å‚¨ ====================
    
    async def save_chat_message(self, message: ChatMessage) -> Optional[str]:
        """ä¿å­˜èŠå¤©æ¶ˆæ¯"""
        try:
            message_dict = asdict(message)
            message_dict.pop('id', None)  # ç§»é™¤idï¼Œè®©æ•°æ®åº“è‡ªåŠ¨ç”Ÿæˆ
            
            # 1. ä¿å­˜åˆ°PostgreSQL
            async def _save_to_db():
                sql = """
                INSERT INTO chat_messages (
                    user_id, session_id, message_type, content, agent_name, message_metadata, created_at
                ) VALUES ($1, $2, $3, $4, $5, $6, $7)
                RETURNING id
                """
                row = await fetch_one(
                    sql,
                    message_dict["user_id"],
                    message_dict["session_id"],
                    message_dict["message_type"],
                    message_dict["content"],
                    message_dict.get("agent_name"),
                    message_dict.get("message_metadata") or {},
                    message_dict["created_at"],
                )
                return row["id"] if row else None
            
            message_id = await self.error_handler.with_retry(_save_to_db, "ä¿å­˜èŠå¤©æ¶ˆæ¯")
            
            # 2. ç¼“å­˜åˆ°Redisï¼ˆæœ€è¿‘çš„æ¶ˆæ¯ï¼‰
            if message_id and self.redis_client:
                cache_key = f"juben:messages:{message.user_id}:{message.session_id}"
                message_dict['id'] = message_id
                await self.redis_client.lpush(cache_key, message_dict)
                # åªä¿ç•™æœ€è¿‘100æ¡æ¶ˆæ¯åœ¨ç¼“å­˜ä¸­
                await self.redis_client.lrange(cache_key, 0, 99)  # è§¦å‘æ¸…ç†
            
            return message_id
            
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜èŠå¤©æ¶ˆæ¯å¤±è´¥: {e}")
            return None
    
    async def get_chat_messages(self, user_id: str, session_id: str, limit: int = 50) -> List[Dict[str, Any]]:
        """è·å–èŠå¤©æ¶ˆæ¯"""
        try:
            # 1. å°è¯•ä»Redisè·å–
            if self.redis_client:
                cache_key = f"juben:messages:{user_id}:{session_id}"
                cached_messages = await self.redis_client.lrange(cache_key, 0, limit - 1)
                if cached_messages:
                    return cached_messages
            
            # 2. ä»PostgreSQLè·å–
            async def _get_from_db():
                sql = """
                SELECT id, user_id, session_id, message_type, content, agent_name, message_metadata, created_at
                FROM chat_messages
                WHERE user_id = $1 AND session_id = $2
                ORDER BY created_at DESC
                LIMIT $3
                """
                rows = await fetch_all(sql, user_id, session_id, limit)
                for row in rows:
                    if row.get("message_metadata"):
                        row["message_metadata"] = json.loads(row["message_metadata"]) if isinstance(row["message_metadata"], str) else row["message_metadata"]
                return rows
            
            messages = await self.error_handler.with_retry(_get_from_db, "è·å–èŠå¤©æ¶ˆæ¯")
            
            # 3. ç¼“å­˜åˆ°Redis
            if messages and self.redis_client:
                cache_key = f"juben:messages:{user_id}:{session_id}"
                for message in reversed(messages):  # æŒ‰æ—¶é—´æ­£åºç¼“å­˜
                    await self.redis_client.lpush(cache_key, message)
                # åªä¿ç•™æœ€è¿‘100æ¡æ¶ˆæ¯åœ¨ç¼“å­˜ä¸­
                await self.redis_client.lrange(cache_key, 0, 99)
            
            return messages or []
            
        except Exception as e:
            self.logger.error(f"âŒ è·å–èŠå¤©æ¶ˆæ¯å¤±è´¥: {e}")
            return []
    
    # ==================== ä¸Šä¸‹æ–‡çŠ¶æ€ç®¡ç† ====================
    
    async def save_context_state(self, context: ContextState) -> bool:
        """ä¿å­˜ä¸Šä¸‹æ–‡çŠ¶æ€"""
        try:
            context_dict = asdict(context)
            
            # 1. ä¿å­˜åˆ°PostgreSQL
            async def _save_to_db():
                sql = """
                INSERT INTO context_states (
                    user_id, session_id, agent_name, context_data, context_type, context_version,
                    is_active, created_at, updated_at, expires_at
                ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)
                ON CONFLICT (user_id, session_id, agent_name)
                DO UPDATE SET
                    context_data = EXCLUDED.context_data,
                    context_type = EXCLUDED.context_type,
                    context_version = EXCLUDED.context_version,
                    is_active = EXCLUDED.is_active,
                    updated_at = EXCLUDED.updated_at,
                    expires_at = EXCLUDED.expires_at
                RETURNING user_id
                """
                row = await fetch_one(
                    sql,
                    context_dict["user_id"],
                    context_dict["session_id"],
                    context_dict["agent_name"],
                    context_dict.get("context_data") or {},
                    context_dict.get("context_type"),
                    context_dict.get("context_version"),
                    context_dict.get("is_active"),
                    context_dict.get("created_at"),
                    context_dict.get("updated_at"),
                    context_dict.get("expires_at"),
                )
                return bool(row)
            
            success = await self.error_handler.with_retry(_save_to_db, "ä¿å­˜ä¸Šä¸‹æ–‡çŠ¶æ€")
            
            # 2. ç¼“å­˜åˆ°Redis
            if success and self.redis_client:
                cache_key = f"juben:context:{context.user_id}:{context.session_id}:{context.agent_name}"
                await self.redis_client.set(cache_key, context_dict, expire=self.cache_ttl['context'])
            
            return success
            
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜ä¸Šä¸‹æ–‡çŠ¶æ€å¤±è´¥: {e}")
            return False
    
    async def get_context_state(self, user_id: str, session_id: str, agent_name: str) -> Optional[Dict[str, Any]]:
        """è·å–ä¸Šä¸‹æ–‡çŠ¶æ€"""
        try:
            # 1. å°è¯•ä»Redisè·å–
            if self.redis_client:
                cache_key = f"juben:context:{user_id}:{session_id}:{agent_name}"
                cached_data = await self.redis_client.get(cache_key)
                if cached_data:
                    return cached_data
            
            # 2. ä»PostgreSQLè·å–
            async def _get_from_db():
                sql = """
                SELECT user_id, session_id, agent_name, context_data, context_type, context_version,
                       is_active, created_at, updated_at, expires_at
                FROM context_states
                WHERE user_id = $1 AND session_id = $2 AND agent_name = $3
                """
                row = await fetch_one(sql, user_id, session_id, agent_name)
                if row and row.get("context_data"):
                    row["context_data"] = json.loads(row["context_data"]) if isinstance(row["context_data"], str) else row["context_data"]
                return row
            
            context_data = await self.error_handler.with_retry(_get_from_db, "è·å–ä¸Šä¸‹æ–‡çŠ¶æ€")
            
            # 3. ç¼“å­˜åˆ°Redis
            if context_data and self.redis_client:
                cache_key = f"juben:context:{user_id}:{session_id}:{agent_name}"
                await self.redis_client.set(cache_key, context_data, expire=self.cache_ttl['context'])
            
            return context_data
            
        except Exception as e:
            self.logger.error(f"âŒ è·å–ä¸Šä¸‹æ–‡çŠ¶æ€å¤±è´¥: {e}")
            return None
    
    # ==================== å¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡ç®¡ç† ====================
    
    async def create_conversation_context(
        self, 
        user_id: str, 
        session_id: str, 
        initial_query: str
    ) -> ConversationContext:
        """åˆ›å»ºå¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆ ï¼‰"""
        try:
            # é¦–å…ˆå°è¯•ä»æ•°æ®åº“æ¢å¤ç°æœ‰ä¸Šä¸‹æ–‡
            existing_context = await self._load_conversation_context_from_db(user_id, session_id)
            if existing_context:
                self.logger.info(f"ğŸ”„ æ¢å¤ç°æœ‰å¯¹è¯ä¸Šä¸‹æ–‡: {user_id}:{session_id}")
                # å°†æ–°çš„æŸ¥è¯¢æ·»åŠ åˆ°æ¶ˆæ¯é˜Ÿåˆ—
                existing_context.user_message_queue.append({
                    "content": initial_query,
                    "timestamp": datetime.now().isoformat(),
                    "is_new": True,
                    "message_id": str(uuid.uuid4())
                })
                # åŒæ—¶æ·»åŠ åˆ°å¯¹è¯å†å²
                existing_context.conversation_history.append({
                    "role": "user",
                    "content": initial_query,
                    "timestamp": datetime.now().isoformat()
                })
                # ä¿å­˜æ›´æ–°
                await self._save_conversation_context(existing_context)
                return existing_context
            
            # åˆ›å»ºæ–°å¯¹è¯ä¸Šä¸‹æ–‡
            self.logger.info(f"ğŸ” åˆ›å»ºå…¨æ–°å¯¹è¯ä¸Šä¸‹æ–‡: {user_id}:{session_id}")
            thread_id = str(uuid.uuid4())
            
            conversation_context = ConversationContext(
                session_id=session_id,
                user_id=user_id,
                thread_id=thread_id,
                user_message_queue=[{
                    "content": initial_query,
                    "timestamp": datetime.now().isoformat(),
                    "is_new": True,
                    "message_id": str(uuid.uuid4())
                }],
                orchestrator_calls=[],
                created_notes=[],
                global_context={},
                agent_contexts={},
                shared_memory={},
                conversation_history=[{
                    "role": "user",
                    "content": initial_query,
                    "timestamp": datetime.now().isoformat()
                }],
                compression_history=[],
                context_summary=None,
                is_compressed=False
            )
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            await self._save_conversation_context(conversation_context)
            self.logger.info(f"âœ… å¯¹è¯ä¸Šä¸‹æ–‡åˆ›å»ºå®Œæˆ: {user_id}:{session_id}")
            return conversation_context
            
        except Exception as e:
            self.logger.error(f"âŒ åˆ›å»ºå¯¹è¯ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            raise
    
    async def get_conversation_context(
        self, 
        user_id: str, 
        session_id: str
    ) -> Optional[ConversationContext]:
        """è·å–å¯¹è¯ä¸Šä¸‹æ–‡"""
        try:
            # 1. å°è¯•ä»Redisè·å–
            if self.redis_client:
                cache_key = f"juben:conversation:{user_id}:{session_id}"
                cached_data = await self.redis_client.get(cache_key)
                if cached_data:
                    return ConversationContext(**cached_data)
            
            # 2. ä»æ•°æ®åº“è·å–
            context = await self._load_conversation_context_from_db(user_id, session_id)
            if context:
                # ç¼“å­˜åˆ°Redis
                if self.redis_client:
                    cache_key = f"juben:conversation:{user_id}:{session_id}"
                    await self.redis_client.set(
                        cache_key, 
                        asdict(context), 
                        expire=self.cache_ttl['conversation']
                    )
                return context
            
            return None
            
        except Exception as e:
            self.logger.error(f"âŒ è·å–å¯¹è¯ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            return None
    
    async def update_conversation_context(
        self, 
        user_id: str, 
        session_id: str, 
        updates: Dict[str, Any]
    ) -> bool:
        """æ›´æ–°å¯¹è¯ä¸Šä¸‹æ–‡"""
        try:
            context = await self.get_conversation_context(user_id, session_id)
            if not context:
                self.logger.warning(f"æœªæ‰¾åˆ°å¯¹è¯ä¸Šä¸‹æ–‡: {user_id}:{session_id}")
                return False
            
            # æ›´æ–°å­—æ®µ
            for key, value in updates.items():
                if hasattr(context, key):
                    setattr(context, key, value)
            
            context.updated_at = datetime.now().isoformat()
            
            # ä¿å­˜æ›´æ–°
            await self._save_conversation_context(context)
            self.logger.info(f"âœ… å¯¹è¯ä¸Šä¸‹æ–‡æ›´æ–°å®Œæˆ: {user_id}:{session_id}")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ æ›´æ–°å¯¹è¯ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            return False
    
    async def add_user_message(
        self, 
        user_id: str, 
        session_id: str, 
        message: str, 
        mark_as_new: bool = True
    ) -> bool:
        """æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å¯¹è¯ä¸Šä¸‹æ–‡"""
        try:
            context = await self.get_conversation_context(user_id, session_id)
            if not context:
                self.logger.warning(f"æœªæ‰¾åˆ°å¯¹è¯ä¸Šä¸‹æ–‡: {user_id}:{session_id}")
                return False
            
            # æ·»åŠ åˆ°æ¶ˆæ¯é˜Ÿåˆ—
            context.user_message_queue.append({
                "content": message,
                "timestamp": datetime.now().isoformat(),
                "is_new": mark_as_new,
                "message_id": str(uuid.uuid4())
            })
            
            # æ·»åŠ åˆ°å¯¹è¯å†å²
            context.conversation_history.append({
                "role": "user",
                "content": message,
                "timestamp": datetime.now().isoformat()
            })
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦å‹ç¼©
            if self.conversation_config['context_compression_enabled']:
                await self._check_and_compress_context(context)
            
            # ä¿å­˜æ›´æ–°
            await self._save_conversation_context(context)
            self.logger.info(f"âœ… ç”¨æˆ·æ¶ˆæ¯å·²æ·»åŠ : {user_id}:{session_id}")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ æ·»åŠ ç”¨æˆ·æ¶ˆæ¯å¤±è´¥: {e}")
            return False
    
    async def add_orchestrator_call(
        self, 
        user_id: str, 
        session_id: str, 
        instruction: str
    ) -> bool:
        """æ·»åŠ orchestratorè°ƒç”¨è®°å½•"""
        try:
            context = await self.get_conversation_context(user_id, session_id)
            if not context:
                self.logger.warning(f"æœªæ‰¾åˆ°å¯¹è¯ä¸Šä¸‹æ–‡: {user_id}:{session_id}")
                return False
            
            # æ·»åŠ åˆ°orchestratorè°ƒç”¨è®°å½•
            context.orchestrator_calls.append({
                "instruction": instruction,
                "timestamp": datetime.now().isoformat(),
                "call_id": str(uuid.uuid4())
            })
            
            # ä¿å­˜æ›´æ–°
            await self._save_conversation_context(context)
            self.logger.info(f"âœ… Orchestratorè°ƒç”¨è®°å½•å·²æ·»åŠ : {user_id}:{session_id}")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ æ·»åŠ orchestratorè°ƒç”¨è®°å½•å¤±è´¥: {e}")
            return False
    
    async def add_conversation_message(
        self, 
        user_id: str, 
        session_id: str, 
        role: str, 
        content: str,
        agent_source: Optional[str] = None
    ) -> bool:
        """æ·»åŠ å¯¹è¯æ¶ˆæ¯"""
        try:
            context = await self.get_conversation_context(user_id, session_id)
            if not context:
                self.logger.warning(f"æœªæ‰¾åˆ°å¯¹è¯ä¸Šä¸‹æ–‡: {user_id}:{session_id}")
                return False
            
            # æ·»åŠ åˆ°å¯¹è¯å†å²
            context.conversation_history.append({
                "role": role,
                "content": content,
                "timestamp": datetime.now().isoformat(),
                "agent_source": agent_source
            })
            
            # ä¿å­˜æ›´æ–°
            await self._save_conversation_context(context)
            self.logger.info(f"âœ… å¯¹è¯æ¶ˆæ¯å·²æ·»åŠ : {user_id}:{session_id}")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ æ·»åŠ å¯¹è¯æ¶ˆæ¯å¤±è´¥: {e}")
            return False
    
    async def _load_conversation_context_from_db(
        self, 
        user_id: str, 
        session_id: str
    ) -> Optional[ConversationContext]:
        """ä»æ•°æ®åº“åŠ è½½å¯¹è¯ä¸Šä¸‹æ–‡"""
        try:
            # è·å–æ‰€æœ‰ä¸Šä¸‹æ–‡æ•°æ®
            rows = await fetch_all(
                """
                SELECT user_id, session_id, agent_name, context_data, context_type, context_version,
                       is_active, created_at, updated_at, expires_at
                FROM context_states
                WHERE user_id = $1 AND session_id = $2
                """,
                user_id,
                session_id,
            )
            
            if not rows:
                return None
            
            # é‡æ„å¯¹è¯ä¸Šä¸‹æ–‡
            for row in rows:
                if row.get("context_data"):
                    row["context_data"] = json.loads(row["context_data"]) if isinstance(row["context_data"], str) else row["context_data"]
            contexts_by_action = {ctx.get("agent_name"): ctx for ctx in rows}
            
            # è·å–notes
            created_notes = await fetch_all(
                """
                SELECT id, user_id, session_id, action, name, title, cover_title, content_type, context, select_status, user_comment, metadata, created_at, updated_at
                FROM notes
                WHERE user_id = $1 AND session_id = $2
                ORDER BY created_at DESC
                """,
                user_id,
                session_id,
            )
            for note in created_notes:
                if note.get("metadata"):
                    note["metadata"] = json.loads(note["metadata"]) if isinstance(note["metadata"], str) else note["metadata"]
            
            # è·å–å¯¹è¯å†å²
            conversation_history = []
            messages = await fetch_all(
                """
                SELECT message_type, content, created_at, agent_name
                FROM chat_messages
                WHERE user_id = $1 AND session_id = $2
                ORDER BY created_at
                """,
                user_id,
                session_id,
            )
            for msg in messages:
                conversation_history.append({
                    "role": msg.get('message_type', 'user'),
                    "content": msg.get('content', ''),
                    "timestamp": msg.get('created_at', ''),
                    "agent_source": msg.get('agent_name')
                })
            
            # é‡æ„å¯¹è¯ä¸Šä¸‹æ–‡
            context = ConversationContext(
                session_id=session_id,
                user_id=user_id,
                thread_id=str(uuid.uuid4()),
                user_message_queue=self._extract_user_message_queue(contexts_by_action),
                orchestrator_calls=self._extract_orchestrator_calls(contexts_by_action),
                created_notes=created_notes,
                global_context={},
                agent_contexts=self._rebuild_agent_contexts(contexts_by_action),
                shared_memory={},
                conversation_history=conversation_history,
                compression_history=[],
                context_summary=None,
                is_compressed=False
            )
            
            return context
            
        except Exception as e:
            self.logger.error(f"âŒ ä»æ•°æ®åº“åŠ è½½å¯¹è¯ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            return None
    
    async def _save_conversation_context(self, context: ConversationContext):
        """ä¿å­˜å¯¹è¯ä¸Šä¸‹æ–‡åˆ°æ•°æ®åº“"""
        try:
            
            # ä¿å­˜å„ä¸ªç»„ä»¶çš„ä¸Šä¸‹æ–‡çŠ¶æ€
            for agent_name, agent_context in context.agent_contexts.items():
                context_state = ContextState(
                    user_id=context.user_id,
                    session_id=context.session_id,
                    agent_name=agent_name,
                    context_data=agent_context,
                    context_type="conversation",
                    is_active=True
                )
                await self.save_context_state(context_state)
            
            # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯é˜Ÿåˆ—
            if context.user_message_queue:
                queue_context = ContextState(
                    user_id=context.user_id,
                    session_id=context.session_id,
                    agent_name="user_message_queue",
                    context_data={"queue": context.user_message_queue},
                    context_type="conversation",
                    is_active=True
                )
                await self.save_context_state(queue_context)
            
            # ä¿å­˜orchestratorè°ƒç”¨è®°å½•
            if context.orchestrator_calls:
                orchestrator_context = ContextState(
                    user_id=context.user_id,
                    session_id=context.session_id,
                    agent_name="orchestrator_calls",
                    context_data={"calls": context.orchestrator_calls},
                    context_type="conversation",
                    is_active=True
                )
                await self.save_context_state(orchestrator_context)
            
            # ä¿å­˜notes
            for note_data in context.created_notes:
                note = Note(
                    user_id=context.user_id,
                    session_id=context.session_id,
                    action=note_data.get('action', ''),
                    name=note_data.get('name', ''),
                    title=note_data.get('title', ''),
                    context=note_data.get('context', ''),
                    select_status=note_data.get('select', 0),
                    metadata=note_data.get('metadata', {})
                )
                await self.save_note(note)
            
            self.logger.info(f"âœ… å¯¹è¯ä¸Šä¸‹æ–‡å·²ä¿å­˜: {context.user_id}:{context.session_id}")
            
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜å¯¹è¯ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
    
    def _extract_user_message_queue(self, contexts_by_action: Dict[str, Dict]) -> List[Dict[str, Any]]:
        """æå–ç”¨æˆ·æ¶ˆæ¯é˜Ÿåˆ—"""
        queue_ctx = contexts_by_action.get("user_message_queue", {})
        return queue_ctx.get("context_data", {}).get("queue", [])
    
    def _extract_orchestrator_calls(self, contexts_by_action: Dict[str, Dict]) -> List[Dict[str, Any]]:
        """æå–orchestratorè°ƒç”¨è®°å½•"""
        orchestrator_ctx = contexts_by_action.get("orchestrator_calls", {})
        return orchestrator_ctx.get("context_data", {}).get("calls", [])
    
    def _rebuild_agent_contexts(self, contexts_by_action: Dict[str, Dict]) -> Dict[str, Any]:
        """é‡æ„agentä¸Šä¸‹æ–‡"""
        agent_contexts = {}
        system_actions = {"user_message_queue", "orchestrator_calls"}
        
        for action, ctx in contexts_by_action.items():
            if action not in system_actions:
                agent_contexts[action] = {
                    "timestamp": ctx.get("updated_at", ""),
                    "context_data": ctx.get("context_data", {}),
                    "metadata": ctx.get("metadata", {}),
                    "status": "completed"
                }
        
        return agent_contexts
    
    async def _check_and_compress_context(self, context: ConversationContext):
        """æ£€æŸ¥å¹¶å‹ç¼©ä¸Šä¸‹æ–‡"""
        try:
            # è®¡ç®—å½“å‰ä¸Šä¸‹æ–‡é•¿åº¦
            total_length = 0
            for msg in context.conversation_history:
                total_length += len(str(msg.get('content', '')))
            
            max_length = self.conversation_config['max_context_length']
            compression_threshold = self.conversation_config['compression_threshold']
            
            if total_length >= max_length * compression_threshold:
                self.logger.info(f"ğŸ“Š ä¸Šä¸‹æ–‡é•¿åº¦ {total_length} è¶…è¿‡é˜ˆå€¼ï¼Œå¼€å§‹å‹ç¼©")
                
                # ç”Ÿæˆä¸Šä¸‹æ–‡æ‘˜è¦
                summary = await self._generate_context_summary(context)
                if summary:
                    context.context_summary = summary
                    context.is_compressed = True
                    
                    # è®°å½•å‹ç¼©å†å²
                    context.compression_history.append({
                        "timestamp": datetime.now().isoformat(),
                        "original_length": total_length,
                        "compression_ratio": 0.3,
                        "summary": summary
                    })
                    
                    # ä¿ç•™æœ€è¿‘çš„æ¶ˆæ¯ï¼Œå‹ç¼©å†å²æ¶ˆæ¯
                    recent_messages = context.conversation_history[-10:]  # ä¿ç•™æœ€è¿‘10æ¡
                    context.conversation_history = recent_messages
                    
                    self.logger.info(f"âœ… ä¸Šä¸‹æ–‡å‹ç¼©å®Œæˆï¼Œä¿ç•™ {len(recent_messages)} æ¡æ¶ˆæ¯")
            
        except Exception as e:
            self.logger.error(f"âŒ ä¸Šä¸‹æ–‡å‹ç¼©å¤±è´¥: {e}")
    
    async def _generate_context_summary(self, context: ConversationContext) -> Optional[str]:
        """ç”Ÿæˆä¸Šä¸‹æ–‡æ‘˜è¦"""
        try:
            # è¿™é‡Œå¯ä»¥è°ƒç”¨LLMç”Ÿæˆæ‘˜è¦
            # æš‚æ—¶è¿”å›ç®€å•æ‘˜è¦
            total_messages = len(context.conversation_history)
            user_messages = len([msg for msg in context.conversation_history if msg.get('role') == 'user'])
            assistant_messages = len([msg for msg in context.conversation_history if msg.get('role') == 'assistant'])
            
            summary = f"""
å¯¹è¯æ‘˜è¦ï¼š
- æ€»æ¶ˆæ¯æ•°: {total_messages}
- ç”¨æˆ·æ¶ˆæ¯: {user_messages}
- åŠ©æ‰‹æ¶ˆæ¯: {assistant_messages}
- åˆ›å»ºæ—¶é—´: {context.created_at}
- æœ€åæ›´æ–°: {context.updated_at}
"""
            return summary
            
        except Exception as e:
            self.logger.error(f"âŒ ç”Ÿæˆä¸Šä¸‹æ–‡æ‘˜è¦å¤±è´¥: {e}")
            return None

    # ==================== Notesç³»ç»Ÿ ====================
    
    async def save_note(self, note: Note) -> Optional[str]:
        """ä¿å­˜Note"""
        try:
            note_dict = asdict(note)
            note_dict.pop('id', None)  # ç§»é™¤idï¼Œè®©æ•°æ®åº“è‡ªåŠ¨ç”Ÿæˆ
            
            # 1. ä¿å­˜åˆ°PostgreSQL
            async def _save_to_db():
                sql = """
                INSERT INTO notes (
                    user_id, session_id, action, name, title, cover_title, content_type, context,
                    select_status, user_comment, metadata, created_at, updated_at
                ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13)
                ON CONFLICT (user_id, session_id, action, name)
                DO UPDATE SET
                    title = EXCLUDED.title,
                    cover_title = EXCLUDED.cover_title,
                    content_type = EXCLUDED.content_type,
                    context = EXCLUDED.context,
                    select_status = EXCLUDED.select_status,
                    user_comment = EXCLUDED.user_comment,
                    metadata = EXCLUDED.metadata,
                    updated_at = EXCLUDED.updated_at
                RETURNING id
                """
                row = await fetch_one(
                    sql,
                    note_dict["user_id"],
                    note_dict["session_id"],
                    note_dict["action"],
                    note_dict["name"],
                    note_dict.get("title"),
                    note_dict.get("cover_title"),
                    note_dict.get("content_type"),
                    note_dict.get("context"),
                    note_dict.get("select_status", 0),
                    note_dict.get("user_comment"),
                    note_dict.get("metadata") or {},
                    note_dict["created_at"],
                    note_dict["updated_at"],
                )
                return row["id"] if row else None
            
            note_id = await self.error_handler.with_retry(_save_to_db, "ä¿å­˜Note")
            
            # 2. ç¼“å­˜åˆ°Redis
            if note_id and self.redis_client:
                cache_key = f"juben:notes:{note.user_id}:{note.session_id}"
                note_dict['id'] = note_id
                await self.redis_client.lpush(cache_key, note_dict)
            
            return note_id
            
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜Noteå¤±è´¥: {e}")
            return None
    
    async def get_notes(self, user_id: str, session_id: str, action: Optional[str] = None) -> List[Dict[str, Any]]:
        """è·å–Notes"""
        try:
            # 1. å°è¯•ä»Redisè·å–
            if self.redis_client:
                cache_key = f"juben:notes:{user_id}:{session_id}"
                cached_notes = await self.redis_client.lrange(cache_key, 0, -1)
                if cached_notes:
                    if action:
                        return [note for note in cached_notes if note.get('action') == action]
                    return cached_notes
            
            # 2. ä»PostgreSQLè·å–
            async def _get_from_db():
                if action:
                    sql = """
                    SELECT id, user_id, session_id, action, name, title, cover_title, content_type, context, select_status, user_comment, metadata, created_at, updated_at
                    FROM notes
                    WHERE user_id = $1 AND session_id = $2 AND action = $3
                    ORDER BY created_at DESC
                    """
                    rows = await fetch_all(sql, user_id, session_id, action)
                else:
                    sql = """
                    SELECT id, user_id, session_id, action, name, title, cover_title, content_type, context, select_status, user_comment, metadata, created_at, updated_at
                    FROM notes
                    WHERE user_id = $1 AND session_id = $2
                    ORDER BY created_at DESC
                    """
                    rows = await fetch_all(sql, user_id, session_id)
                for row in rows:
                    if row.get("metadata"):
                        row["metadata"] = json.loads(row["metadata"]) if isinstance(row["metadata"], str) else row["metadata"]
                return rows
            
            notes = await self.error_handler.with_retry(_get_from_db, "è·å–Notes")
            
            # 3. ç¼“å­˜åˆ°Redis
            if notes and self.redis_client:
                cache_key = f"juben:notes:{user_id}:{session_id}"
                for note in reversed(notes):
                    await self.redis_client.lpush(cache_key, note)
            
            return notes or []

        except Exception as e:
            self.logger.error(f"âŒ è·å–Noteså¤±è´¥: {e}")
            return []

    # ==================== Agentè¾“å‡ºNoteä¸“ç”¨æ–¹æ³•ï¼ˆ====================

    async def save_agent_output_note(
        self,
        user_id: str,
        session_id: str,
        action: str,
        name: str,
        context: str,
        title: Optional[str] = None,
        cover_title: Optional[str] = None,
        select_status: int = 0,
        metadata: Optional[Dict[str, Any]] = None
    ) -> Optional[str]:
        """
        ä¿å­˜Agentè¾“å‡ºNoteï¼ˆä¸“ç”¨æ–¹æ³•ï¼‰

        Args:
            user_id: ç”¨æˆ·ID
            session_id: ä¼šè¯ID
            action: AgentåŠ¨ä½œç±»å‹ï¼ˆå¦‚character_profile_generatorï¼‰
            name: Noteåç§°ï¼ˆå”¯ä¸€æ ‡è¯†ï¼Œå¦‚character1, plot1ç­‰ï¼‰
            context: Noteå†…å®¹
            title: å¯é€‰æ ‡é¢˜
            cover_title: å¯é€‰å°é¢æ ‡é¢˜
            select_status: é€‰æ‹©çŠ¶æ€ï¼ˆ0æœªé€‰æ‹©ï¼Œ1å·²é€‰æ‹©ï¼‰
            metadata: å…ƒæ•°æ®

        Returns:
            str: Note ID
        """
        try:
            note = Note(
                user_id=user_id,
                session_id=session_id,
                action=action,
                name=name,
                title=title,
                cover_title=cover_title,
                context=context,
                select_status=select_status,
                metadata=metadata or {}
            )
            return await self.save_note(note)
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜Agentè¾“å‡ºNoteå¤±è´¥: {e}")
            return None

    async def get_notes_by_action(self, user_id: str, session_id: str, action: str) -> List[Dict[str, Any]]:
        """æŒ‰actionç±»å‹è·å–Notes"""
        return await self.get_notes(user_id, session_id, action)

    async def get_selected_notes(self, user_id: str, session_id: str) -> List[Dict[str, Any]]:
        """è·å–å·²é€‰æ‹©çš„Notes"""
        try:
            async def _get_selected():
                rows = await fetch_all(
                    """
                    SELECT id, user_id, session_id, action, name, title, cover_title, content_type, context, select_status, user_comment, metadata, created_at, updated_at
                    FROM notes
                    WHERE user_id = $1 AND session_id = $2 AND select_status = 1
                    ORDER BY created_at DESC
                    """,
                    user_id,
                    session_id,
                )
                for row in rows:
                    if row.get("metadata"):
                        row["metadata"] = json.loads(row["metadata"]) if isinstance(row["metadata"], str) else row["metadata"]
                return rows

            selected_notes = await self.error_handler.with_retry(_get_selected, "è·å–å·²é€‰æ‹©Notes")
            return selected_notes or []
        except Exception as e:
            self.logger.error(f"âŒ è·å–å·²é€‰æ‹©Noteså¤±è´¥: {e}")
            return []

    async def batch_update_note_selection(
        self,
        user_id: str,
        session_id: str,
        selections: List[Dict[str, Any]]
    ) -> bool:
        """
        æ‰¹é‡æ›´æ–°Noteé€‰æ‹©çŠ¶æ€

        Args:
            user_id: ç”¨æˆ·ID
            session_id: ä¼šè¯ID
            selections: é€‰æ‹©åˆ—è¡¨ï¼Œæ ¼å¼: [{'action': 'character_profile_generator', 'name': 'character1', 'selected': True, 'user_comment': '...'}]
        """
        try:
            for selection in selections:
                action = selection.get('action')
                name = selection.get('name')
                selected = selection.get('selected', False)
                user_comment = selection.get('user_comment')

                # æ„å»ºæ›´æ–°æ•°æ®
                update_data = {'select_status': 1 if selected else 0}
                if user_comment:
                    update_data['user_comment'] = user_comment

                # æ‰§è¡Œæ›´æ–°
                async def _update_selection():
                    if "user_comment" in update_data:
                        sql = """
                        UPDATE notes
                        SET select_status = $1, user_comment = $2, updated_at = $3
                        WHERE user_id = $4 AND session_id = $5 AND action = $6 AND name = $7
                        RETURNING id
                        """
                        row = await fetch_one(
                            sql,
                            update_data["select_status"],
                            update_data["user_comment"],
                            datetime.now().isoformat(),
                            user_id,
                            session_id,
                            action,
                            name,
                        )
                    else:
                        sql = """
                        UPDATE notes
                        SET select_status = $1, updated_at = $2
                        WHERE user_id = $3 AND session_id = $4 AND action = $5 AND name = $6
                        RETURNING id
                        """
                        row = await fetch_one(
                            sql,
                            update_data["select_status"],
                            datetime.now().isoformat(),
                            user_id,
                            session_id,
                            action,
                            name,
                        )
                    return bool(row)

                await self.error_handler.with_retry(_update_selection, f"æ›´æ–°Noteé€‰æ‹©çŠ¶æ€: {action}:{name}")

            # æ¸…é™¤ç›¸å…³Redisç¼“å­˜
            if self.redis_client:
                cache_key = f"juben:notes:{user_id}:{session_id}"
                await self.redis_client.delete(cache_key)

            return True
        except Exception as e:
            self.logger.error(f"âŒ æ‰¹é‡æ›´æ–°Noteé€‰æ‹©çŠ¶æ€å¤±è´¥: {e}")
            return False

    async def export_notes(
        self,
        user_id: str,
        session_id: str,
        export_format: str = 'txt',
        content_types: Optional[List[str]] = None,
        include_user_comments: bool = True
    ) -> Dict[str, Any]:
        """
        å¯¼å‡ºNotes

        Args:
            user_id: ç”¨æˆ·ID
            session_id: ä¼šè¯ID
            export_format: å¯¼å‡ºæ ¼å¼ï¼ˆtxt, json, mdï¼‰
            content_types: è¦å¯¼å‡ºçš„å†…å®¹ç±»å‹åˆ—è¡¨
            include_user_comments: æ˜¯å¦åŒ…å«ç”¨æˆ·è¯„è®º

        Returns:
            Dict: å¯¼å‡ºç»“æœ
        """
        try:
            # è·å–Notes
            async def _get_all_notes():
                rows = await fetch_all(
                    """
                    SELECT id, user_id, session_id, action, name, title, cover_title, content_type, context, select_status, user_comment, metadata, created_at, updated_at
                    FROM notes
                    WHERE user_id = $1 AND session_id = $2
                    ORDER BY created_at DESC
                    """,
                    user_id,
                    session_id,
                )
                for row in rows:
                    if row.get("metadata"):
                        row["metadata"] = json.loads(row["metadata"]) if isinstance(row["metadata"], str) else row["metadata"]
                if content_types:
                    return [n for n in rows if n.get("metadata", {}).get("content_type") in content_types]
                return rows

            notes = await self.error_handler.with_retry(_get_all_notes, "è·å–Notesç”¨äºå¯¼å‡º")

            if not notes:
                return {'exported_data': '', 'total_items': 0, 'content_summary': {}}

            # æŒ‰actionåˆ†ç»„ç»Ÿè®¡
            content_summary = {}
            for note in notes:
                action = note.get('action', 'unknown')
                content_summary[action] = content_summary.get(action, 0) + 1

            # æ ¼å¼åŒ–å¯¼å‡º
            if export_format == 'json':
                exported_data = json.dumps(notes, ensure_ascii=False, indent=2)
            elif export_format == 'md':
                exported_data = self._format_notes_as_markdown(notes, include_user_comments)
            else:  # txt
                exported_data = self._format_notes_as_text(notes, include_user_comments)

            return {
                'exported_data': exported_data,
                'total_items': len(notes),
                'content_summary': content_summary
            }
        except Exception as e:
            self.logger.error(f"âŒ å¯¼å‡ºNoteså¤±è´¥: {e}")
            return {'exported_data': '', 'total_items': 0, 'content_summary': {}}

    def _format_notes_as_text(self, notes: List[Dict], include_comments: bool) -> str:
        """æ ¼å¼åŒ–Notesä¸ºçº¯æ–‡æœ¬"""
        lines = []
        lines.append(f"å‰§æœ¬åˆ›ä½œNoteså¯¼å‡º - å…±{len(notes)}é¡¹")
        lines.append("=" * 60)

        for note in notes:
            lines.append(f"\n[{note.get('action', 'unknown')}] {note.get('title') or note.get('name')}")
            lines.append("-" * 40)
            lines.append(note.get('context', ''))

            if include_comments and note.get('user_comment'):
                lines.append(f"\nç”¨æˆ·è¯„è®º: {note.get('user_comment')}")

            lines.append("")

        return "\n".join(lines)

    def _format_notes_as_markdown(self, notes: List[Dict], include_comments: bool) -> str:
        """æ ¼å¼åŒ–Notesä¸ºMarkdown"""
        lines = []
        lines.append(f"# å‰§æœ¬åˆ›ä½œNoteså¯¼å‡º")
        lines.append(f"\nå…± **{len(notes)}** é¡¹\n")

        for note in notes:
            title = note.get('title') or note.get('name', 'æœªå‘½å')
            lines.append(f"## {note.get('action', 'unknown')}: {title}")
            lines.append(f"\n{note.get('context', '')}\n")

            if include_comments and note.get('user_comment'):
                lines.append(f"**ç”¨æˆ·è¯„è®º**: {note.get('user_comment')}\n")

        return "\n".join(lines)

    # ==================== Tokenä½¿ç”¨ç»Ÿè®¡ ====================
    
    async def save_token_usage(self, token_usage: TokenUsage) -> Optional[str]:
        """ä¿å­˜Tokenä½¿ç”¨è®°å½•"""
        try:
            token_dict = asdict(token_usage)
            token_dict.pop('id', None)  # ç§»é™¤idï¼Œè®©æ•°æ®åº“è‡ªåŠ¨ç”Ÿæˆ
            
            # 1. ä¿å­˜åˆ°PostgreSQL
            async def _save_to_db():
                sql = """
                INSERT INTO token_usage (
                    user_id, session_id, agent_name, model_provider, model_name,
                    request_tokens, response_tokens, total_tokens, cost_points,
                    request_timestamp, billing_summary
                ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11)
                RETURNING id
                """
                row = await fetch_one(
                    sql,
                    token_dict["user_id"],
                    token_dict["session_id"],
                    token_dict.get("agent_name"),
                    token_dict.get("model_provider"),
                    token_dict.get("model_name"),
                    token_dict.get("request_tokens", 0),
                    token_dict.get("response_tokens", 0),
                    token_dict.get("total_tokens", 0),
                    token_dict.get("cost_points", 0.0),
                    token_dict.get("request_timestamp"),
                    token_dict.get("billing_summary") or {},
                )
                return row["id"] if row else None
            
            usage_id = await self.error_handler.with_retry(_save_to_db, "ä¿å­˜Tokenä½¿ç”¨è®°å½•")
            
            # 2. ç¼“å­˜åˆ°Redisï¼ˆç”¨äºå®æ—¶ç»Ÿè®¡ï¼‰
            if usage_id and self.redis_client:
                cache_key = f"juben:token_usage:{token_usage.user_id}:{token_usage.session_id}"
                token_dict['id'] = usage_id
                await self.redis_client.lpush(cache_key, token_dict)
            
            return usage_id
            
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜Tokenä½¿ç”¨è®°å½•å¤±è´¥: {e}")
            return None
    
    async def get_token_usage_summary(self, user_id: str, session_id: str) -> Dict[str, Any]:
        """è·å–Tokenä½¿ç”¨æ‘˜è¦"""
        try:
            # 1. å°è¯•ä»Redisè·å–
            if self.redis_client:
                cache_key = f"juben:token_usage:{user_id}:{session_id}"
                cached_usage = await self.redis_client.lrange(cache_key, 0, -1)
                if cached_usage:
                    total_tokens = sum(usage.get('total_tokens', 0) for usage in cached_usage)
                    total_cost = sum(usage.get('cost_points', 0) for usage in cached_usage)
                    return {
                        'total_requests': len(cached_usage),
                        'total_tokens': total_tokens,
                        'total_cost_points': total_cost,
                        'avg_tokens_per_request': total_tokens / len(cached_usage) if cached_usage else 0
                    }
            
            # 2. ä»PostgreSQLè·å–
            async def _get_from_db():
                rows = await fetch_all(
                    """
                    SELECT id, user_id, session_id, agent_name, model_provider, model_name,
                           request_tokens, response_tokens, total_tokens, cost_points,
                           request_timestamp, billing_summary
                    FROM token_usage
                    WHERE user_id = $1 AND session_id = $2
                    """,
                    user_id,
                    session_id,
                )
                for row in rows:
                    if row.get("billing_summary"):
                        row["billing_summary"] = json.loads(row["billing_summary"]) if isinstance(row["billing_summary"], str) else row["billing_summary"]
                return rows
            
            usage_records = await self.error_handler.with_retry(_get_from_db, "è·å–Tokenä½¿ç”¨æ‘˜è¦")
            
            if usage_records:
                total_tokens = sum(record.get('total_tokens', 0) for record in usage_records)
                total_cost = sum(record.get('cost_points', 0) for record in usage_records)
                return {
                    'total_requests': len(usage_records),
                    'total_tokens': total_tokens,
                    'total_cost_points': total_cost,
                    'avg_tokens_per_request': total_tokens / len(usage_records)
                }
            
            return {
                'total_requests': 0,
                'total_tokens': 0,
                'total_cost_points': 0.0,
                'avg_tokens_per_request': 0
            }
            
        except Exception as e:
            self.logger.error(f"âŒ è·å–Tokenä½¿ç”¨æ‘˜è¦å¤±è´¥: {e}")
            return {
                'total_requests': 0,
                'total_tokens': 0,
                'total_cost_points': 0.0,
                'avg_tokens_per_request': 0
            }
    
    # ==================== æµå¼äº‹ä»¶å­˜å‚¨ ====================
    
    async def save_stream_event(self, user_id: str, session_id: str, event_type: str, 
                               content_type: Optional[str], agent_source: str, 
                               event_data: Any, event_metadata: Dict[str, Any] = None) -> Optional[str]:
        """ä¿å­˜æµå¼äº‹ä»¶"""
        try:
            event_dict = {
                'user_id': user_id,
                'session_id': session_id,
                'event_type': event_type,
                'content_type': content_type,
                'agent_source': agent_source,
                'event_data': event_data,
                'event_metadata': event_metadata or {},
                'is_replayed': False,
                'created_at': datetime.now().isoformat()
            }
            
            # 1. ä¿å­˜åˆ°PostgreSQL
            async def _save_to_db():
                sql = """
                INSERT INTO stream_events (
                    user_id, session_id, event_type, content_type, agent_source,
                    event_data, event_metadata, is_replayed, created_at
                ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)
                RETURNING id
                """
                row = await fetch_one(
                    sql,
                    event_dict["user_id"],
                    event_dict["session_id"],
                    event_dict["event_type"],
                    event_dict.get("content_type"),
                    event_dict.get("agent_source"),
                    event_dict.get("event_data"),
                    event_dict.get("event_metadata") or {},
                    event_dict.get("is_replayed", False),
                    event_dict.get("created_at"),
                )
                return row["id"] if row else None
            
            event_id = await self.error_handler.with_retry(_save_to_db, "ä¿å­˜æµå¼äº‹ä»¶")
            
            # 2. ç¼“å­˜åˆ°Redisï¼ˆæœ€è¿‘çš„äº‹ä»¶ï¼‰
            if event_id and self.redis_client:
                cache_key = f"juben:stream_events:{user_id}:{session_id}"
                event_dict['id'] = event_id
                await self.redis_client.lpush(cache_key, event_dict)
                # åªä¿ç•™æœ€è¿‘50ä¸ªäº‹ä»¶åœ¨ç¼“å­˜ä¸­
                await self.redis_client.lrange(cache_key, 0, 49)
            
            return event_id
            
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜æµå¼äº‹ä»¶å¤±è´¥: {e}")
            return None
    
    async def get_stream_events(self, user_id: str, session_id: str, limit: int = 50) -> List[Dict[str, Any]]:
        """è·å–æµå¼äº‹ä»¶"""
        try:
            # 1. å°è¯•ä»Redisè·å–
            if self.redis_client:
                cache_key = f"juben:stream_events:{user_id}:{session_id}"
                cached_events = await self.redis_client.lrange(cache_key, 0, limit - 1)
                if cached_events:
                    return cached_events
            
            # 2. ä»PostgreSQLè·å–
            async def _get_from_db():
                rows = await fetch_all(
                    """
                    SELECT id, user_id, session_id, event_type, content_type, agent_source,
                           event_data, event_metadata, is_replayed, created_at
                    FROM stream_events
                    WHERE user_id = $1 AND session_id = $2
                    ORDER BY created_at DESC
                    LIMIT $3
                    """,
                    user_id,
                    session_id,
                    limit,
                )
                for row in rows:
                    if row.get("event_data"):
                        row["event_data"] = json.loads(row["event_data"]) if isinstance(row["event_data"], str) else row["event_data"]
                    if row.get("event_metadata"):
                        row["event_metadata"] = json.loads(row["event_metadata"]) if isinstance(row["event_metadata"], str) else row["event_metadata"]
                return rows
            
            events = await self.error_handler.with_retry(_get_from_db, "è·å–æµå¼äº‹ä»¶")
            
            # 3. ç¼“å­˜åˆ°Redis
            if events and self.redis_client:
                cache_key = f"juben:stream_events:{user_id}:{session_id}"
                for event in reversed(events):
                    await self.redis_client.lpush(cache_key, event)
                # åªä¿ç•™æœ€è¿‘50ä¸ªäº‹ä»¶åœ¨ç¼“å­˜ä¸­
                await self.redis_client.lrange(cache_key, 0, 49)
            
            return events or []
            
        except Exception as e:
            self.logger.error(f"âŒ è·å–æµå¼äº‹ä»¶å¤±è´¥: {e}")
            return []
    
    # ==================== æ¸…ç†æ–¹æ³• ====================
    
    async def cleanup_expired_cache(self):
        """æ¸…ç†è¿‡æœŸçš„ç¼“å­˜æ•°æ®"""
        try:
            if not self.redis_client:
                return
            
            # è·å–æ‰€æœ‰ç¼“å­˜é”®
            # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„Rediså®¢æˆ·ç«¯APIè°ƒæ•´
            # åœ¨å®é™…å®ç°ä¸­ï¼Œå¯èƒ½éœ€è¦ä½¿ç”¨SCANå‘½ä»¤æ¥éå†é”®
            
            self.logger.info("ğŸ§¹ ç¼“å­˜æ¸…ç†å®Œæˆ")
            
        except Exception as e:
            self.logger.error(f"âŒ æ¸…ç†è¿‡æœŸç¼“å­˜å¤±è´¥: {e}")
    
    async def close(self):
        """å…³é—­å­˜å‚¨ç®¡ç†å™¨"""
        try:
            if self.redis_client:
                await self.redis_client.close()
            
            self.logger.info("âœ… å­˜å‚¨ç®¡ç†å™¨å·²å…³é—­")
            
        except Exception as e:
            self.logger.error(f"âŒ å…³é—­å­˜å‚¨ç®¡ç†å™¨å¤±è´¥: {e}")


# å…¨å±€å­˜å‚¨ç®¡ç†å™¨å®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
storage_manager = None


async def init_storage() -> JubenStorageManager:
    """åˆå§‹åŒ–å­˜å‚¨ç®¡ç†å™¨ - ä¾¿æ·å‡½æ•°"""
    global storage_manager
    if storage_manager is None:
        storage_manager = JubenStorageManager()
    if not storage_manager._initialized:
        await storage_manager.initialize()
    return storage_manager


def get_storage() -> JubenStorageManager:
    """è·å–å­˜å‚¨ç®¡ç†å™¨å®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰"""
    global storage_manager
    if storage_manager is None:
        storage_manager = JubenStorageManager()
    return storage_manager
