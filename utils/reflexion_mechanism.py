"""
Reflexionåæ€æœºåˆ¶ - ä»é”™è¯¯ä¸­å­¦ä¹ ï¼Œæç‚¼è§„åˆ™
åŸºäºäº‹ä»¶é©±åŠ¨çš„åæ€å­¦ä¹ ç³»ç»Ÿ
"""
import os
import json
import asyncio
import logging
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Union, Tuple
from dataclasses import dataclass, asdict
from pathlib import Path
import hashlib
import uuid

try:
    from ..config.settings import JubenSettings
    from ..utils.logger import JubenLogger
    from ..utils.storage_manager import JubenStorageManager, Note
    from ..utils.llm_client import JubenLLMClient
    from ..utils.vector_store import VectorStore
except ImportError:
    import sys
    from pathlib import Path
    sys.path.insert(0, str(Path(__file__).parent.parent))
    
    from config.settings import JubenSettings
    from utils.logger import JubenLogger
    from utils.storage_manager import JubenStorageManager, Note
    from utils.llm_client import JubenLLMClient
    from utils.vector_store import VectorStore


@dataclass
class FailureEvent:
    """å¤±è´¥äº‹ä»¶"""
    id: str
    action: str  # æ‰§è¡Œçš„åŠ¨ä½œ
    expected_result: str  # æœŸæœ›ç»“æœ
    actual_result: str  # å®é™…ç»“æœ
    failure_reason: str  # å¤±è´¥åŸå› 
    context: Dict[str, Any]  # ä¸Šä¸‹æ–‡ä¿¡æ¯
    timestamp: str
    severity: str  # low, medium, high
    user_id: str
    session_id: str
    agent_name: str


@dataclass
class ReflectionRule:
    """åæ€è§„åˆ™"""
    id: str
    rule_name: str
    rule_description: str
    trigger_conditions: List[str]  # è§¦å‘æ¡ä»¶
    prevention_strategy: str  # é¢„é˜²ç­–ç•¥
    success_examples: List[str]  # æˆåŠŸæ¡ˆä¾‹
    failure_examples: List[str]  # å¤±è´¥æ¡ˆä¾‹
    confidence_score: float  # 0-1
    usage_count: int
    created_at: str
    updated_at: str
    tags: List[str]
    metadata: Dict[str, Any]


@dataclass
class MetaPrompt:
    """å…ƒæç¤º"""
    id: str
    prompt_type: str  # failure_analysis, rule_generation, strategy_refinement
    original_prompt: str
    enhanced_prompt: str
    context: Dict[str, Any]
    effectiveness_score: float  # 0-1
    created_at: str
    updated_at: str


class ReflexionMechanism:
    """Reflexionåæ€æœºåˆ¶"""
    
    def __init__(self, model_provider: str = "zhipu"):
        """
        åˆå§‹åŒ–åæ€æœºåˆ¶
        
        Args:
            model_provider: æ¨¡å‹æä¾›å•†
        """
        self.config = JubenSettings()
        self.logger = JubenLogger("ReflexionMechanism", level=self.config.log_level)
        self.storage_manager = JubenStorageManager()
        self.llm_client = JubenLLMClient(model_provider)
        self.vector_store = VectorStore()
        
        # åæ€çŠ¶æ€
        self.failure_events: Dict[str, FailureEvent] = {}
        self.reflection_rules: Dict[str, ReflectionRule] = {}
        self.meta_prompts: Dict[str, MetaPrompt] = {}
        
        # åæ€é…ç½®
        self.reflection_config = {
            "auto_reflection": True,
            "failure_threshold": 3,  # 3æ¬¡å¤±è´¥åè§¦å‘åæ€
            "rule_confidence_threshold": 0.7,  # è§„åˆ™ç½®ä¿¡åº¦é˜ˆå€¼
            "meta_prompt_effectiveness_threshold": 0.8,  # å…ƒæç¤ºæœ‰æ•ˆæ€§é˜ˆå€¼
            "max_rules_per_category": 50,  # æ¯ç±»åˆ«æœ€å¤§è§„åˆ™æ•°
            "reflection_interval_hours": 24  # åæ€é—´éš”ï¼ˆå°æ—¶ï¼‰
        }
        
        self.logger.info("Reflexionåæ€æœºåˆ¶åˆå§‹åŒ–å®Œæˆ")
    
    async def initialize(self):
        """åˆå§‹åŒ–åæ€æœºåˆ¶"""
        try:
            await self.storage_manager.initialize()
            await self.vector_store.initialize()
            self.logger.info("âœ… Reflexionåæ€æœºåˆ¶åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            self.logger.error(f"âŒ Reflexionåæ€æœºåˆ¶åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    async def detect_failure(
        self,
        action: str,
        expected_result: str,
        actual_result: str,
        context: Dict[str, Any],
        user_id: str,
        session_id: str,
        agent_name: str
    ) -> Optional[FailureEvent]:
        """
        æ£€æµ‹å¤±è´¥äº‹ä»¶
        
        Args:
            action: æ‰§è¡Œçš„åŠ¨ä½œ
            expected_result: æœŸæœ›ç»“æœ
            actual_result: å®é™…ç»“æœ
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            user_id: ç”¨æˆ·ID
            session_id: ä¼šè¯ID
            agent_name: Agentåç§°
            
        Returns:
            å¤±è´¥äº‹ä»¶å¯¹è±¡ï¼ˆå¦‚æœæ£€æµ‹åˆ°å¤±è´¥ï¼‰
        """
        try:
            # åˆ†æç»“æœå·®å¼‚
            failure_analysis = await self._analyze_failure(
                action, expected_result, actual_result, context
            )
            
            if not failure_analysis['is_failure']:
                return None
            
            # åˆ›å»ºå¤±è´¥äº‹ä»¶
            failure_event = FailureEvent(
                id=str(uuid.uuid4()),
                action=action,
                expected_result=expected_result,
                actual_result=actual_result,
                failure_reason=failure_analysis['reason'],
                context=context,
                timestamp=datetime.now().isoformat(),
                severity=failure_analysis['severity'],
                user_id=user_id,
                session_id=session_id,
                agent_name=agent_name
            )
            
            # å­˜å‚¨å¤±è´¥äº‹ä»¶
            self.failure_events[failure_event.id] = failure_event
            
            # è§¦å‘åæ€æµç¨‹
            await self._trigger_reflection(failure_event)
            
            self.logger.info(f"ğŸ” æ£€æµ‹åˆ°å¤±è´¥äº‹ä»¶: {failure_event.id}")
            return failure_event
            
        except Exception as e:
            self.logger.error(f"å¤±è´¥æ£€æµ‹å¤±è´¥: {e}")
            return None
    
    async def _analyze_failure(
        self,
        action: str,
        expected_result: str,
        actual_result: str,
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """åˆ†æå¤±è´¥åŸå› """
        try:
            # æ„å»ºå¤±è´¥åˆ†ææç¤ºè¯
            prompt = self._build_failure_analysis_prompt(
                action, expected_result, actual_result, context
            )
            
            # è°ƒç”¨LLMåˆ†æ
            response = await self.llm_client.generate_response(
                prompt=prompt,
                max_tokens=1000,
                temperature=0.3
            )
            
            if response and response.get('content'):
                # è§£æåˆ†æç»“æœ
                return self._parse_failure_analysis(response['content'])
            else:
                # ä½¿ç”¨ç®€å•åˆ†æ
                return self._simple_failure_analysis(
                    action, expected_result, actual_result
                )
                
        except Exception as e:
            self.logger.error(f"å¤±è´¥åˆ†æå¤±è´¥: {e}")
            return {
                'is_failure': True,
                'reason': f'åˆ†æå¤±è´¥: {str(e)}',
                'severity': 'medium'
            }
    
    def _build_failure_analysis_prompt(
        self,
        action: str,
        expected_result: str,
        actual_result: str,
        context: Dict[str, Any]
    ) -> str:
        """æ„å»ºå¤±è´¥åˆ†ææç¤ºè¯"""
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¤±è´¥åˆ†æä¸“å®¶ï¼Œéœ€è¦åˆ†æAIç³»ç»Ÿçš„å¤±è´¥æƒ…å†µå¹¶ç¡®å®šå¤±è´¥åŸå› ã€‚

## å¤±è´¥ä¿¡æ¯
- **æ‰§è¡ŒåŠ¨ä½œ**: {action}
- **æœŸæœ›ç»“æœ**: {expected_result}
- **å®é™…ç»“æœ**: {actual_result}
- **ä¸Šä¸‹æ–‡**: {json.dumps(context, ensure_ascii=False, indent=2)}

## åˆ†æä»»åŠ¡
è¯·åˆ†æä»¥ä¸Šæƒ…å†µæ˜¯å¦æ„æˆå¤±è´¥ï¼Œå¹¶ç¡®å®šï¼š

1. **æ˜¯å¦å¤±è´¥**: åˆ¤æ–­å®é™…ç»“æœæ˜¯å¦ä¸æœŸæœ›ç»“æœå­˜åœ¨æ˜¾è‘—å·®å¼‚
2. **å¤±è´¥åŸå› **: åˆ†æå¯¼è‡´å¤±è´¥çš„æ ¹æœ¬åŸå› 
3. **ä¸¥é‡ç¨‹åº¦**: è¯„ä¼°å¤±è´¥çš„ä¸¥é‡ç¨‹åº¦ï¼ˆlow/medium/highï¼‰

## è¾“å‡ºæ ¼å¼
è¯·æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼š

```json
{{
    "is_failure": true/false,
    "reason": "å¤±è´¥åŸå› åˆ†æ",
    "severity": "low/medium/high",
    "suggestions": ["æ”¹è¿›å»ºè®®1", "æ”¹è¿›å»ºè®®2"],
    "prevention_strategies": ["é¢„é˜²ç­–ç•¥1", "é¢„é˜²ç­–ç•¥2"]
}}
```

è¯·ç¡®ä¿åˆ†æå‡†ç¡®ã€æ·±å…¥ï¼Œå¹¶æä¾›æœ‰ä»·å€¼çš„æ”¹è¿›å»ºè®®ã€‚
"""
        
        return prompt
    
    def _parse_failure_analysis(self, llm_response: str) -> Dict[str, Any]:
        """è§£æå¤±è´¥åˆ†æç»“æœ"""
        try:
            # å°è¯•ä»å“åº”ä¸­æå–JSON
            import re
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', llm_response, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
                return json.loads(json_str)
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°JSONï¼Œä½¿ç”¨ç®€å•è§£æ
                return self._simple_parse_failure_analysis(llm_response)
        except Exception as e:
            self.logger.error(f"è§£æå¤±è´¥åˆ†æç»“æœå¤±è´¥: {e}")
            return self._simple_parse_failure_analysis(llm_response)
    
    def _simple_parse_failure_analysis(self, response: str) -> Dict[str, Any]:
        """ç®€å•è§£æå¤±è´¥åˆ†æç»“æœ"""
        # åŸºäºå…³é”®è¯çš„ç®€å•åˆ†æ
        if "å¤±è´¥" in response or "é”™è¯¯" in response or "ä¸æ­£ç¡®" in response:
            return {
                'is_failure': True,
                'reason': response[:200],
                'severity': 'medium',
                'suggestions': ['æ£€æŸ¥è¾“å…¥å‚æ•°', 'ä¼˜åŒ–å¤„ç†é€»è¾‘'],
                'prevention_strategies': ['å¢åŠ éªŒè¯', 'æ”¹è¿›é”™è¯¯å¤„ç†']
            }
        else:
            return {
                'is_failure': False,
                'reason': 'ç»“æœç¬¦åˆé¢„æœŸ',
                'severity': 'low',
                'suggestions': [],
                'prevention_strategies': []
            }
    
    def _simple_failure_analysis(
        self,
        action: str,
        expected_result: str,
        actual_result: str
    ) -> Dict[str, Any]:
        """ç®€å•å¤±è´¥åˆ†æï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        # ç®€å•çš„å­—ç¬¦ä¸²æ¯”è¾ƒ
        if expected_result.lower() != actual_result.lower():
            return {
                'is_failure': True,
                'reason': f'æœŸæœ›ç»“æœä¸å®é™…ç»“æœä¸åŒ¹é…',
                'severity': 'medium',
                'suggestions': ['æ£€æŸ¥ç»“æœå¤„ç†é€»è¾‘'],
                'prevention_strategies': ['å¢åŠ ç»“æœéªŒè¯']
            }
        else:
            return {
                'is_failure': False,
                'reason': 'ç»“æœåŒ¹é…',
                'severity': 'low',
                'suggestions': [],
                'prevention_strategies': []
            }
    
    async def _trigger_reflection(self, failure_event: FailureEvent):
        """è§¦å‘åæ€æµç¨‹"""
        try:
            self.logger.info(f"ğŸ”„ è§¦å‘åæ€æµç¨‹: {failure_event.id}")
            
            # 1. ç”Ÿæˆå…ƒæç¤º
            meta_prompt = await self._generate_meta_prompt(failure_event)
            if meta_prompt:
                self.meta_prompts[meta_prompt.id] = meta_prompt
                self.logger.info(f"ğŸ“ ç”Ÿæˆå…ƒæç¤º: {meta_prompt.id}")
            
            # 2. ç”Ÿæˆåæ€è§„åˆ™
            reflection_rule = await self._generate_reflection_rule(failure_event, meta_prompt)
            if reflection_rule:
                self.reflection_rules[reflection_rule.id] = reflection_rule
                self.logger.info(f"ğŸ“‹ ç”Ÿæˆåæ€è§„åˆ™: {reflection_rule.id}")
            
            # 3. å­˜å‚¨åˆ°æŒä¹…åŒ–å­˜å‚¨
            await self._store_reflection_data(failure_event, meta_prompt, reflection_rule)
            
            self.logger.info(f"âœ… åæ€æµç¨‹å®Œæˆ: {failure_event.id}")
            
        except Exception as e:
            self.logger.error(f"åæ€æµç¨‹å¤±è´¥: {e}")
    
    async def _generate_meta_prompt(self, failure_event: FailureEvent) -> Optional[MetaPrompt]:
        """ç”Ÿæˆå…ƒæç¤º"""
        try:
            # æ„å»ºå…ƒæç¤ºç”Ÿæˆæç¤ºè¯
            prompt = self._build_meta_prompt_generation_prompt(failure_event)
            
            # è°ƒç”¨LLMç”Ÿæˆå…ƒæç¤º
            response = await self.llm_client.generate_response(
                prompt=prompt,
                max_tokens=1500,
                temperature=0.5
            )
            
            if response and response.get('content'):
                # è§£æç”Ÿæˆçš„å…ƒæç¤º
                meta_prompt_data = self._parse_meta_prompt_response(response['content'])
                
                meta_prompt = MetaPrompt(
                    id=str(uuid.uuid4()),
                    prompt_type="failure_analysis",
                    original_prompt=failure_event.action,
                    enhanced_prompt=meta_prompt_data['enhanced_prompt'],
                    context={
                        'failure_event_id': failure_event.id,
                        'action': failure_event.action,
                        'failure_reason': failure_event.failure_reason
                    },
                    effectiveness_score=0.5,  # åˆå§‹åˆ†æ•°
                    created_at=datetime.now().isoformat(),
                    updated_at=datetime.now().isoformat()
                )
                
                return meta_prompt
                
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆå…ƒæç¤ºå¤±è´¥: {e}")
            return None
    
    def _build_meta_prompt_generation_prompt(self, failure_event: FailureEvent) -> str:
        """æ„å»ºå…ƒæç¤ºç”Ÿæˆæç¤ºè¯"""
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å…ƒæç¤ºç”Ÿæˆä¸“å®¶ï¼Œéœ€è¦ä»å¤±è´¥äº‹ä»¶ä¸­ç”Ÿæˆå¯å¤ç”¨çš„å…ƒæç¤ºã€‚

## å¤±è´¥äº‹ä»¶ä¿¡æ¯
- **åŠ¨ä½œ**: {failure_event.action}
- **æœŸæœ›ç»“æœ**: {failure_event.expected_result}
- **å®é™…ç»“æœ**: {failure_event.actual_result}
- **å¤±è´¥åŸå› **: {failure_event.failure_reason}
- **ä¸¥é‡ç¨‹åº¦**: {failure_event.severity}
- **ä¸Šä¸‹æ–‡**: {json.dumps(failure_event.context, ensure_ascii=False, indent=2)}

## ä»»åŠ¡è¦æ±‚
åŸºäºä»¥ä¸Šå¤±è´¥äº‹ä»¶ï¼Œç”Ÿæˆä¸€ä¸ªå¯å¤ç”¨çš„å…ƒæç¤ºï¼Œç”¨äºï¼š
1. **é¢„é˜²ç±»ä¼¼å¤±è´¥**: æä¾›é¢„é˜²ç­–ç•¥
2. **æ”¹è¿›å¤„ç†é€»è¾‘**: ä¼˜åŒ–æ‰§è¡Œæµç¨‹
3. **å¢å¼ºé”™è¯¯å¤„ç†**: æé«˜ç³»ç»Ÿé²æ£’æ€§

## è¾“å‡ºæ ¼å¼
è¯·æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼š

```json
{{
    "enhanced_prompt": "å¢å¼ºåçš„æç¤ºè¯å†…å®¹",
    "prevention_strategies": ["é¢„é˜²ç­–ç•¥1", "é¢„é˜²ç­–ç•¥2"],
    "improvement_suggestions": ["æ”¹è¿›å»ºè®®1", "æ”¹è¿›å»ºè®®2"],
    "error_handling_enhancements": ["é”™è¯¯å¤„ç†å¢å¼º1", "é”™è¯¯å¤„ç†å¢å¼º2"]
}}
```

è¯·ç¡®ä¿ç”Ÿæˆçš„å…ƒæç¤ºå…·æœ‰é€šç”¨æ€§ã€å¯æ“ä½œæ€§å’Œæœ‰æ•ˆæ€§ã€‚
"""
        
        return prompt
    
    def _parse_meta_prompt_response(self, llm_response: str) -> Dict[str, Any]:
        """è§£æå…ƒæç¤ºå“åº”"""
        try:
            import re
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', llm_response, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
                return json.loads(json_str)
            else:
                return {
                    'enhanced_prompt': llm_response,
                    'prevention_strategies': ['å¢åŠ éªŒè¯', 'æ”¹è¿›é”™è¯¯å¤„ç†'],
                    'improvement_suggestions': ['ä¼˜åŒ–é€»è¾‘', 'å¢å¼ºé²æ£’æ€§'],
                    'error_handling_enhancements': ['æ·»åŠ å¼‚å¸¸å¤„ç†', 'å¢åŠ é‡è¯•æœºåˆ¶']
                }
        except Exception as e:
            self.logger.error(f"è§£æå…ƒæç¤ºå“åº”å¤±è´¥: {e}")
            return {
                'enhanced_prompt': llm_response,
                'prevention_strategies': [],
                'improvement_suggestions': [],
                'error_handling_enhancements': []
            }
    
    async def _generate_reflection_rule(
        self, 
        failure_event: FailureEvent, 
        meta_prompt: Optional[MetaPrompt]
    ) -> Optional[ReflectionRule]:
        """ç”Ÿæˆåæ€è§„åˆ™"""
        try:
            # æ„å»ºè§„åˆ™ç”Ÿæˆæç¤ºè¯
            prompt = self._build_rule_generation_prompt(failure_event, meta_prompt)
            
            # è°ƒç”¨LLMç”Ÿæˆè§„åˆ™
            response = await self.llm_client.generate_response(
                prompt=prompt,
                max_tokens=2000,
                temperature=0.4
            )
            
            if response and response.get('content'):
                # è§£æç”Ÿæˆçš„è§„åˆ™
                rule_data = self._parse_rule_response(response['content'])
                
                reflection_rule = ReflectionRule(
                    id=str(uuid.uuid4()),
                    rule_name=rule_data['rule_name'],
                    rule_description=rule_data['rule_description'],
                    trigger_conditions=rule_data['trigger_conditions'],
                    prevention_strategy=rule_data['prevention_strategy'],
                    success_examples=rule_data['success_examples'],
                    failure_examples=[failure_event.action],
                    confidence_score=0.7,  # åˆå§‹ç½®ä¿¡åº¦
                    usage_count=0,
                    created_at=datetime.now().isoformat(),
                    updated_at=datetime.now().isoformat(),
                    tags=['reflexion', 'auto_generated'],
                    metadata={
                        'failure_event_id': failure_event.id,
                        'meta_prompt_id': meta_prompt.id if meta_prompt else None,
                        'generation_method': 'llm_generated'
                    }
                )
                
                return reflection_rule
                
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆåæ€è§„åˆ™å¤±è´¥: {e}")
            return None
    
    def _build_rule_generation_prompt(
        self, 
        failure_event: FailureEvent, 
        meta_prompt: Optional[MetaPrompt]
    ) -> str:
        """æ„å»ºè§„åˆ™ç”Ÿæˆæç¤ºè¯"""
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§„åˆ™ç”Ÿæˆä¸“å®¶ï¼Œéœ€è¦ä»å¤±è´¥äº‹ä»¶ä¸­æç‚¼å¯å¤ç”¨çš„è§„åˆ™ã€‚

## å¤±è´¥äº‹ä»¶ä¿¡æ¯
- **åŠ¨ä½œ**: {failure_event.action}
- **æœŸæœ›ç»“æœ**: {failure_event.expected_result}
- **å®é™…ç»“æœ**: {failure_event.actual_result}
- **å¤±è´¥åŸå› **: {failure_event.failure_reason}
- **ä¸¥é‡ç¨‹åº¦**: {failure_event.severity}

## å…ƒæç¤ºä¿¡æ¯
{f"å¢å¼ºæç¤º: {meta_prompt.enhanced_prompt}" if meta_prompt else "æ— å…ƒæç¤º"}

## ä»»åŠ¡è¦æ±‚
åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œç”Ÿæˆä¸€ä¸ªå¯å¤ç”¨çš„åæ€è§„åˆ™ï¼ŒåŒ…æ‹¬ï¼š

1. **è§„åˆ™åç§°**: ç®€æ´æ˜äº†çš„è§„åˆ™åç§°
2. **è§„åˆ™æè¿°**: è¯¦ç»†çš„è§„åˆ™æè¿°
3. **è§¦å‘æ¡ä»¶**: ä»€ä¹ˆæƒ…å†µä¸‹åº”ç”¨æ­¤è§„åˆ™
4. **é¢„é˜²ç­–ç•¥**: å¦‚ä½•é¢„é˜²ç±»ä¼¼å¤±è´¥
5. **æˆåŠŸæ¡ˆä¾‹**: è§„åˆ™åº”ç”¨çš„æˆåŠŸç¤ºä¾‹
6. **å¤±è´¥æ¡ˆä¾‹**: è§„åˆ™åº”ç”¨çš„å¤±è´¥ç¤ºä¾‹

## è¾“å‡ºæ ¼å¼
è¯·æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼š

```json
{{
    "rule_name": "è§„åˆ™åç§°",
    "rule_description": "è§„åˆ™è¯¦ç»†æè¿°",
    "trigger_conditions": ["è§¦å‘æ¡ä»¶1", "è§¦å‘æ¡ä»¶2"],
    "prevention_strategy": "é¢„é˜²ç­–ç•¥æè¿°",
    "success_examples": ["æˆåŠŸæ¡ˆä¾‹1", "æˆåŠŸæ¡ˆä¾‹2"],
    "failure_examples": ["å¤±è´¥æ¡ˆä¾‹1", "å¤±è´¥æ¡ˆä¾‹2"]
}}
```

è¯·ç¡®ä¿è§„åˆ™å…·æœ‰é€šç”¨æ€§ã€å¯æ“ä½œæ€§å’Œæœ‰æ•ˆæ€§ã€‚
"""
        
        return prompt
    
    def _parse_rule_response(self, llm_response: str) -> Dict[str, Any]:
        """è§£æè§„åˆ™å“åº”"""
        try:
            import re
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', llm_response, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
                return json.loads(json_str)
            else:
                return {
                    'rule_name': 'é€šç”¨å¤±è´¥é¢„é˜²è§„åˆ™',
                    'rule_description': 'åŸºäºå¤±è´¥äº‹ä»¶ç”Ÿæˆçš„é¢„é˜²è§„åˆ™',
                    'trigger_conditions': ['æ£€æµ‹åˆ°å¤±è´¥'],
                    'prevention_strategy': 'å¢åŠ éªŒè¯å’Œé”™è¯¯å¤„ç†',
                    'success_examples': ['æˆåŠŸæ¡ˆä¾‹'],
                    'failure_examples': ['å¤±è´¥æ¡ˆä¾‹']
                }
        except Exception as e:
            self.logger.error(f"è§£æè§„åˆ™å“åº”å¤±è´¥: {e}")
            return {
                'rule_name': 'é»˜è®¤è§„åˆ™',
                'rule_description': 'é»˜è®¤è§„åˆ™æè¿°',
                'trigger_conditions': ['é»˜è®¤æ¡ä»¶'],
                'prevention_strategy': 'é»˜è®¤ç­–ç•¥',
                'success_examples': [],
                'failure_examples': []
            }
    
    async def _store_reflection_data(
        self,
        failure_event: FailureEvent,
        meta_prompt: Optional[MetaPrompt],
        reflection_rule: Optional[ReflectionRule]
    ):
        """å­˜å‚¨åæ€æ•°æ®"""
        try:
            # å­˜å‚¨å¤±è´¥äº‹ä»¶
            note = Note(
                id=failure_event.id,
                user_id=failure_event.user_id,
                title=f"å¤±è´¥äº‹ä»¶_{failure_event.action}",
                content=json.dumps(asdict(failure_event), ensure_ascii=False, indent=2),
                note_type="failure_event",
                tags=['reflexion', 'failure'],
                metadata={
                    'action': failure_event.action,
                    'severity': failure_event.severity,
                    'timestamp': failure_event.timestamp
                }
            )
            await self.storage_manager.save_note(note)
            
            # å­˜å‚¨å…ƒæç¤º
            if meta_prompt:
                meta_note = Note(
                    id=meta_prompt.id,
                    user_id=failure_event.user_id,
                    title=f"å…ƒæç¤º_{meta_prompt.prompt_type}",
                    content=meta_prompt.enhanced_prompt,
                    note_type="meta_prompt",
                    tags=['reflexion', 'meta_prompt'],
                    metadata={
                        'prompt_type': meta_prompt.prompt_type,
                        'effectiveness_score': meta_prompt.effectiveness_score,
                        'failure_event_id': failure_event.id
                    }
                )
                await self.storage_manager.save_note(meta_note)
            
            # å­˜å‚¨åæ€è§„åˆ™
            if reflection_rule:
                rule_note = Note(
                    id=reflection_rule.id,
                    user_id=failure_event.user_id,
                    title=f"åæ€è§„åˆ™_{reflection_rule.rule_name}",
                    content=reflection_rule.rule_description,
                    note_type="reflection_rule",
                    tags=['reflexion', 'rule'],
                    metadata={
                        'rule_name': reflection_rule.rule_name,
                        'confidence_score': reflection_rule.confidence_score,
                        'usage_count': reflection_rule.usage_count,
                        'failure_event_id': failure_event.id
                    }
                )
                await self.storage_manager.save_note(rule_note)
            
            self.logger.info("ğŸ’¾ åæ€æ•°æ®å·²å­˜å‚¨")
            
        except Exception as e:
            self.logger.error(f"å­˜å‚¨åæ€æ•°æ®å¤±è´¥: {e}")
    
    async def get_applicable_rules(
        self, 
        action: str, 
        context: Dict[str, Any]
    ) -> List[ReflectionRule]:
        """è·å–é€‚ç”¨çš„åæ€è§„åˆ™"""
        try:
            applicable_rules = []
            
            for rule in self.reflection_rules.values():
                # æ£€æŸ¥è§¦å‘æ¡ä»¶
                if self._check_rule_conditions(rule, action, context):
                    applicable_rules.append(rule)
            
            # æŒ‰ç½®ä¿¡åº¦æ’åº
            applicable_rules.sort(key=lambda x: x.confidence_score, reverse=True)
            
            self.logger.info(f"ğŸ” æ‰¾åˆ° {len(applicable_rules)} ä¸ªé€‚ç”¨è§„åˆ™")
            return applicable_rules
            
        except Exception as e:
            self.logger.error(f"è·å–é€‚ç”¨è§„åˆ™å¤±è´¥: {e}")
            return []
    
    def _check_rule_conditions(
        self, 
        rule: ReflectionRule, 
        action: str, 
        context: Dict[str, Any]
    ) -> bool:
        """æ£€æŸ¥è§„åˆ™æ¡ä»¶"""
        try:
            for condition in rule.trigger_conditions:
                if condition.lower() in action.lower():
                    return True
                if condition.lower() in str(context).lower():
                    return True
            return False
        except Exception as e:
            self.logger.error(f"æ£€æŸ¥è§„åˆ™æ¡ä»¶å¤±è´¥: {e}")
            return False
    
    async def get_reflection_summary(self, user_id: str) -> Dict[str, Any]:
        """è·å–åæ€æ‘˜è¦"""
        try:
            # ç»Ÿè®¡å¤±è´¥äº‹ä»¶
            user_failures = [
                event for event in self.failure_events.values()
                if event.user_id == user_id
            ]
            
            # ç»Ÿè®¡åæ€è§„åˆ™
            user_rules = [
                rule for rule in self.reflection_rules.values()
                if rule.metadata.get('user_id') == user_id
            ]
            
            # ç»Ÿè®¡å…ƒæç¤º
            user_meta_prompts = [
                prompt for prompt in self.meta_prompts.values()
                if prompt.context.get('failure_event_id') in [f.id for f in user_failures]
            ]
            
            summary = {
                "user_id": user_id,
                "total_failures": len(user_failures),
                "total_rules": len(user_rules),
                "total_meta_prompts": len(user_meta_prompts),
                "failure_severity_distribution": {},
                "rule_confidence_distribution": {},
                "recent_failures": [],
                "top_rules": [],
                "created_at": datetime.now().isoformat()
            }
            
            # ç»Ÿè®¡å¤±è´¥ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ
            for failure in user_failures:
                severity = failure.severity
                summary["failure_severity_distribution"][severity] = \
                    summary["failure_severity_distribution"].get(severity, 0) + 1
            
            # ç»Ÿè®¡è§„åˆ™ç½®ä¿¡åº¦åˆ†å¸ƒ
            for rule in user_rules:
                confidence_range = f"{int(rule.confidence_score * 10) * 10}%"
                summary["rule_confidence_distribution"][confidence_range] = \
                    summary["rule_confidence_distribution"].get(confidence_range, 0) + 1
            
            # æœ€è¿‘å¤±è´¥äº‹ä»¶
            recent_failures = sorted(
                user_failures, 
                key=lambda x: x.timestamp, 
                reverse=True
            )[:5]
            summary["recent_failures"] = [
                {
                    "id": f.id,
                    "action": f.action,
                    "severity": f.severity,
                    "timestamp": f.timestamp
                }
                for f in recent_failures
            ]
            
            # çƒ­é—¨è§„åˆ™
            top_rules = sorted(
                user_rules,
                key=lambda x: (x.confidence_score, x.usage_count),
                reverse=True
            )[:5]
            summary["top_rules"] = [
                {
                    "id": r.id,
                    "name": r.rule_name,
                    "confidence": r.confidence_score,
                    "usage_count": r.usage_count
                }
                for r in top_rules
            ]
            
            return summary
            
        except Exception as e:
            self.logger.error(f"è·å–åæ€æ‘˜è¦å¤±è´¥: {e}")
            return {"error": str(e)}


# å…¨å±€åæ€æœºåˆ¶å®ä¾‹
_global_reflexion = None

def get_reflexion_mechanism() -> ReflexionMechanism:
    """è·å–å…¨å±€åæ€æœºåˆ¶"""
    global _global_reflexion
    if _global_reflexion is None:
        _global_reflexion = ReflexionMechanism()
    return _global_reflexion


async def detect_failure(
    action: str,
    expected_result: str,
    actual_result: str,
    context: Dict[str, Any],
    user_id: str,
    session_id: str,
    agent_name: str
) -> Optional[FailureEvent]:
    """æ£€æµ‹å¤±è´¥ï¼ˆä¾¿æ·å‡½æ•°ï¼‰"""
    mechanism = get_reflexion_mechanism()
    await mechanism.initialize()
    return await mechanism.detect_failure(
        action, expected_result, actual_result, context, user_id, session_id, agent_name
    )


def main():
    """ä¸»å‡½æ•° - ç”¨äºæµ‹è¯•å’Œæ¼”ç¤º"""
    import sys
    
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # åˆ›å»ºåæ€æœºåˆ¶
    mechanism = ReflexionMechanism()
    
    # æ¨¡æ‹Ÿå¤±è´¥æ£€æµ‹æµ‹è¯•
    logger.info("Reflexionåæ€æœºåˆ¶æµ‹è¯•å®Œæˆ")
    return True


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
